{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choice Reasoning - LLM驱动的多选项推理实验\n",
    "\n",
    "本notebook实现了一个完全由LLM驱动的推理流程：\n",
    "1. 对每个选项（more/less/no_effect）分别调用LLM进行独立思考\n",
    "2. LLM为每个选项提供支持理由和置信度\n",
    "3. 结合build_causal_chain、反思机制和meta分析\n",
    "4. 最终由LLM综合所有选项的分析做出决策"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Modules loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import os, json, random\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "import importlib\n",
    "import ollama\n",
    "\n",
    "import question_parser, ego_expansion_builder\n",
    "importlib.reload(question_parser)\n",
    "importlib.reload(ego_expansion_builder)\n",
    "from question_parser import QuestionParser\n",
    "from ego_expansion_builder import EgoExpansionCausalBuilder\n",
    "\n",
    "print('✓ Modules loaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  - Samples: 5\n",
      "  - Print Details: True\n",
      "  - Confidence Threshold: 0.3\n",
      "  - Model: gemma2:27b\n"
     ]
    }
   ],
   "source": [
    "# ========== 用户可配置参数 ==========\n",
    "\n",
    "# 数据量选择\n",
    "NUM_SAMPLES = 5  # 可以修改这个值来选择测试的数据量\n",
    "\n",
    "# 是否打印详细信息\n",
    "PRINT_DETAILS = True  # True: 打印所有推理细节, False: 只打印最终结果\n",
    "\n",
    "# 置信度阈值 - 只使用高于此值的因果关系\n",
    "CONFIDENCE_THRESHOLD = 0.3  # 可以调整（0.0-1.0），越高越严格\n",
    "\n",
    "# 模型配置\n",
    "MODEL = 'gemma2:27b'\n",
    "MAX_EXPANSION_DEPTH = 2\n",
    "MAX_NEIGHBORS_PER_SEED = 5\n",
    "MAX_RELATIONS_PER_ENTITY = 5\n",
    "\n",
    "print(f'Configuration:')\n",
    "print(f'  - Samples: {NUM_SAMPLES}')\n",
    "print(f'  - Print Details: {PRINT_DETAILS}')\n",
    "print(f'  - Confidence Threshold: {CONFIDENCE_THRESHOLD}')\n",
    "print(f'  - Model: {MODEL}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化组件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Parser and Builder initialized\n"
     ]
    }
   ],
   "source": [
    "# 初始化Parser和Builder（根据PRINT_DETAILS决定是否显示详细日志）\n",
    "PARSER = QuestionParser(model_name=MODEL, verbose=PRINT_DETAILS)\n",
    "BUILDER = EgoExpansionCausalBuilder(\n",
    "    model_name=MODEL,\n",
    "    max_neighbors_per_seed=MAX_NEIGHBORS_PER_SEED,\n",
    "    max_expansion_depth=MAX_EXPANSION_DEPTH,\n",
    "    max_relations_per_entity=MAX_RELATIONS_PER_ENTITY,\n",
    "    verbose=PRINT_DETAILS,\n",
    ")\n",
    "\n",
    "print('✓ Parser and Builder initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 5 samples\n"
     ]
    }
   ],
   "source": [
    "def load_wiqa_local(path='wiqa_train_data.json', limit=10, seed=42):\n",
    "    \"\"\"加载本地WIQA数据集\"\"\"\n",
    "    items = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            try:\n",
    "                obj = json.loads(line)\n",
    "            except Exception:\n",
    "                continue\n",
    "            q = obj.get('question_stem') or obj.get('question') or ''\n",
    "            lbl = (obj.get('answer_label') or obj.get('label') or '').strip().lower()\n",
    "            if q and lbl:\n",
    "                items.append({'question': q, 'gold': lbl})\n",
    "    random.Random(seed).shuffle(items)\n",
    "    return items[:limit]\n",
    "\n",
    "SAMPLES = load_wiqa_local(limit=NUM_SAMPLES)\n",
    "print(f'✓ Loaded {len(SAMPLES)} samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 核心推理函数\n",
    "\n",
    "### 1. 识别观察对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Observable outcome identification function defined\n"
     ]
    }
   ],
   "source": [
    "def identify_observable_outcome(\n",
    "    question: str,\n",
    "    question_structure: Dict[str, Any],\n",
    "    model: str\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    识别问题中的观察对象/可测量结果\n",
    "    \n",
    "    Args:\n",
    "        question: 原始问题\n",
    "        question_structure: 问题结构解析结果\n",
    "        model: LLM模型\n",
    "    \n",
    "    Returns:\n",
    "        观察对象的识别结果\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"You are a causal reasoning expert. Your task is to identify the SPECIFIC OBSERVABLE OUTCOME being asked about in this question.\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "QUESTION STRUCTURE:\n",
    "- Intervention/Change: {question_structure.get('intervention', 'N/A')}\n",
    "- Target Phrase: {question_structure.get('target_phrase', 'N/A')}\n",
    "- Target Direction: {question_structure.get('target_direction', 'N/A')}\n",
    "- Question Type: {question_structure.get('question_type', 'N/A')}\n",
    "\n",
    "TASK:\n",
    "Clarify what SPECIFIC, MEASURABLE outcome or behavior is being asked about.\n",
    "\n",
    "Examples:\n",
    "- \"How will it affect MORE vegetables\" → What does \"MORE vegetables\" specifically mean?\n",
    "  * Eating more vegetables?\n",
    "  * Growing more vegetables?\n",
    "  * Buying more vegetables?\n",
    "  * Having more vegetables available in stores?\n",
    "  \n",
    "- \"How will it affect LESS water\" → What does \"LESS water\" mean?\n",
    "  * Using less water?\n",
    "  * Having less water available?\n",
    "  * Less rainfall?\n",
    "  * Less water consumption?\n",
    "\n",
    "IMPORTANT GUIDELINES:\n",
    "1. Choose the MOST PLAUSIBLE interpretation based on the intervention context\n",
    "2. The outcome should be OBSERVABLE and MEASURABLE\n",
    "3. Consider what makes sense given the domain and intervention\n",
    "4. Be specific and concrete\n",
    "\n",
    "Return in JSON format:\n",
    "{{\n",
    "  \"observable_outcome\": \"Specific description of what is being measured/observed\",\n",
    "  \"reasoning\": \"Why this interpretation makes most sense given the intervention (2-3 sentences)\",\n",
    "  \"alternative_interpretations\": [\"other possible interpretation 1\", \"other possible interpretation 2\"]\n",
    "}}\n",
    "\n",
    "Return ONLY JSON, nothing else.\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = ollama.generate(model=model, prompt=prompt)\n",
    "        llm_response = response.get(\"response\", \"\").strip()\n",
    "        \n",
    "        import re\n",
    "        json_match = re.search(r\"\\{[^}]+\\}\", llm_response, re.DOTALL)\n",
    "        if json_match:\n",
    "            result = json.loads(json_match.group())\n",
    "        else:\n",
    "            result = {\n",
    "                \"observable_outcome\": question_structure.get('target_phrase', 'unclear'),\n",
    "                \"reasoning\": \"Could not parse response\",\n",
    "                \"alternative_interpretations\": []\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"observable_outcome\": result.get(\"observable_outcome\", \"unclear\"),\n",
    "            \"reasoning\": result.get(\"reasoning\", \"\"),\n",
    "            \"alternative_interpretations\": result.get(\"alternative_interpretations\", []),\n",
    "            \"raw_response\": llm_response\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"observable_outcome\": question_structure.get('target_phrase', 'error'),\n",
    "            \"reasoning\": f\"Error: {str(e)}\",\n",
    "            \"alternative_interpretations\": [],\n",
    "            \"raw_response\": \"\"\n",
    "        }\n",
    "\n",
    "print('✓ Observable outcome identification function defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 构建因果链路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. 对每个choice进行正向推理和反事实推理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 综合评估并做出最终决策"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Forward and counterfactual reasoning functions defined\n"
     ]
    }
   ],
   "source": [
    "def forward_reasoning(\n",
    "    question: str,\n",
    "    choice: str,\n",
    "    observable_outcome: str,\n",
    "    causal_chains_text: str,\n",
    "    question_structure: Dict[str, Any],\n",
    "    model: str\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    正向推理：假设这个choice是正确的，寻找支持证据\n",
    "    \n",
    "    Args:\n",
    "        question: 原始问题\n",
    "        choice: 当前选项\n",
    "        observable_outcome: 已识别的观察对象\n",
    "        causal_chains_text: 因果链的文本描述\n",
    "        question_structure: 问题结构\n",
    "        model: LLM模型\n",
    "    \n",
    "    Returns:\n",
    "        正向推理结果\n",
    "    \"\"\"\n",
    "    choice_desc = {\n",
    "        \"more\": \"MORE (increase/greater)\",\n",
    "        \"less\": \"LESS (decrease/fewer)\",\n",
    "        \"no_effect\": \"NO EFFECT (no change)\"\n",
    "    }\n",
    "    \n",
    "    prompt = f\"\"\"You are a causal reasoning expert. Perform FORWARD REASONING to evaluate if \"{choice}\" could be the correct answer.\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "OBSERVABLE OUTCOME (what we are measuring):\n",
    "{observable_outcome}\n",
    "\n",
    "QUESTION STRUCTURE:\n",
    "- Intervention: {question_structure.get('intervention', 'N/A')}\n",
    "- Target: {question_structure.get('target_phrase', 'N/A')}\n",
    "- Question Type: {question_structure.get('question_type', 'N/A')}\n",
    "\n",
    "AVAILABLE CAUSAL CHAINS:\n",
    "{causal_chains_text}\n",
    "\n",
    "EVALUATING CHOICE: {choice_desc[choice]}\n",
    "\n",
    "TASK - FORWARD REASONING:\n",
    "Assume \"{choice}\" IS the correct answer. Find evidence that SUPPORTS this choice.\n",
    "\n",
    "1. Look for causal chains that connect the intervention to the observable outcome\n",
    "2. Evaluate if these chains support the \"{choice}\" outcome\n",
    "3. Consider the strength and directness of the causal path\n",
    "4. Assess your confidence that \"{choice}\" is correct based on the evidence\n",
    "\n",
    "CRITICAL REQUIREMENTS:\n",
    "- ONLY use the causal chains provided above\n",
    "- REJECT indirect/weak causal chains (more than 2 hops or involving uncertain steps)\n",
    "- AVOID speculative reasoning without evidence\n",
    "- For \"no_effect\": HIGH confidence only if there's clearly NO plausible causal path\n",
    "\n",
    "IMPORTANT FOR META-LEVEL QUESTIONS:\n",
    "- If asking about \"MORE X\" or \"LESS X\", you're reasoning about the PHENOMENON, not the entity\n",
    "- Example: \"LESS rabbits\" means the phenomenon of \"having fewer rabbits\"\n",
    "  * If intervention causes rabbits to decrease → \"LESS rabbits\" phenomenon INCREASES → answer: MORE\n",
    "\n",
    "Return in JSON format:\n",
    "{{\n",
    "  \"confidence\": 0.0-1.0 (How confident that \"{choice}\" is CORRECT),\n",
    "  \"supporting_evidence\": [\"evidence 1\", \"evidence 2\", ...],\n",
    "  \"causal_path\": \"Description of the causal path from intervention to outcome\",\n",
    "  \"path_strength\": \"strong|moderate|weak|none\",\n",
    "  \"rationale\": \"Explain your reasoning (3-5 sentences)\"\n",
    "}}\n",
    "\n",
    "Return ONLY JSON, nothing else.\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = ollama.generate(model=model, prompt=prompt)\n",
    "        llm_response = response.get(\"response\", \"\").strip()\n",
    "        \n",
    "        import re\n",
    "        json_match = re.search(r\"\\{[^}]+\\}\", llm_response, re.DOTALL)\n",
    "        if json_match:\n",
    "            result = json.loads(json_match.group())\n",
    "        else:\n",
    "            result = {\n",
    "                \"confidence\": 0.0,\n",
    "                \"supporting_evidence\": [],\n",
    "                \"causal_path\": \"Could not parse\",\n",
    "                \"path_strength\": \"none\",\n",
    "                \"rationale\": llm_response\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"confidence\": result.get(\"confidence\", 0.0),\n",
    "            \"supporting_evidence\": result.get(\"supporting_evidence\", []),\n",
    "            \"causal_path\": result.get(\"causal_path\", \"\"),\n",
    "            \"path_strength\": result.get(\"path_strength\", \"unknown\"),\n",
    "            \"rationale\": result.get(\"rationale\", \"\"),\n",
    "            \"raw_response\": llm_response\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"confidence\": 0.0,\n",
    "            \"supporting_evidence\": [],\n",
    "            \"causal_path\": \"\",\n",
    "            \"path_strength\": \"error\",\n",
    "            \"rationale\": f\"Error: {str(e)}\",\n",
    "            \"raw_response\": \"\"\n",
    "        }\n",
    "\n",
    "\n",
    "def counterfactual_reasoning(\n",
    "    question: str,\n",
    "    choice: str,\n",
    "    observable_outcome: str,\n",
    "    causal_chains_text: str,\n",
    "    question_structure: Dict[str, Any],\n",
    "    model: str\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    反事实推理：测试如果干预没有发生，结果会如何\n",
    "    \n",
    "    Args:\n",
    "        question: 原始问题\n",
    "        choice: 当前选项\n",
    "        observable_outcome: 已识别的观察对象\n",
    "        causal_chains_text: 因果链的文本描述\n",
    "        question_structure: 问题结构\n",
    "        model: LLM模型\n",
    "    \n",
    "    Returns:\n",
    "        反事实推理结果\n",
    "    \"\"\"\n",
    "    choice_desc = {\n",
    "        \"more\": \"MORE (increase/greater)\",\n",
    "        \"less\": \"LESS (decrease/fewer)\",\n",
    "        \"no_effect\": \"NO EFFECT (no change)\"\n",
    "    }\n",
    "    \n",
    "    prompt = f\"\"\"You are a causal reasoning expert. Perform COUNTERFACTUAL REASONING to test if \"{choice}\" is the correct answer.\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "OBSERVABLE OUTCOME (what we are measuring):\n",
    "{observable_outcome}\n",
    "\n",
    "QUESTION STRUCTURE:\n",
    "- Intervention: {question_structure.get('intervention', 'N/A')}\n",
    "- Target: {question_structure.get('target_phrase', 'N/A')}\n",
    "\n",
    "AVAILABLE CAUSAL CHAINS:\n",
    "{causal_chains_text}\n",
    "\n",
    "EVALUATING CHOICE: {choice_desc[choice]}\n",
    "\n",
    "TASK - COUNTERFACTUAL REASONING:\n",
    "Test the causal relationship by considering the COUNTERFACTUAL scenario.\n",
    "\n",
    "COUNTERFACTUAL TEST:\n",
    "Ask: \"If the intervention ({question_structure.get('intervention')}) did NOT happen, would the outcome ({observable_outcome}) still change?\"\n",
    "\n",
    "For \"{choice}\" to be correct:\n",
    "- If choice is \"more\" or \"less\": The intervention MUST cause the outcome to change\n",
    "  * Counterfactual: No intervention → outcome should NOT change (or change differently)\n",
    "  * Test PASSES if: intervention is NECESSARY for the outcome change\n",
    "  \n",
    "- If choice is \"no_effect\": The intervention should NOT affect the outcome\n",
    "  * Counterfactual: No intervention → outcome stays the same\n",
    "  * Test PASSES if: removing intervention doesn't change anything\n",
    "\n",
    "EVALUATION CRITERIA:\n",
    "1. Is there a necessary causal link between intervention and outcome?\n",
    "2. Could the outcome occur without the intervention?\n",
    "3. Does removing the intervention eliminate or significantly change the outcome?\n",
    "\n",
    "Return in JSON format:\n",
    "{{\n",
    "  \"test_result\": \"pass|fail|unclear\",\n",
    "  \"counterfactual_scenario\": \"Description of what happens without the intervention\",\n",
    "  \"outcome_without_intervention\": \"What happens to the observable outcome\",\n",
    "  \"confidence_adjustment\": -0.3 to +0.3 (adjustment to confidence based on this test),\n",
    "  \"rationale\": \"Explain the counterfactual reasoning (3-5 sentences)\"\n",
    "}}\n",
    "\n",
    "Return ONLY JSON, nothing else.\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = ollama.generate(model=model, prompt=prompt)\n",
    "        llm_response = response.get(\"response\", \"\").strip()\n",
    "        \n",
    "        import re\n",
    "        json_match = re.search(r\"\\{[^}]+\\}\", llm_response, re.DOTALL)\n",
    "        if json_match:\n",
    "            result = json.loads(json_match.group())\n",
    "        else:\n",
    "            result = {\n",
    "                \"test_result\": \"unclear\",\n",
    "                \"counterfactual_scenario\": \"Could not parse\",\n",
    "                \"outcome_without_intervention\": \"unclear\",\n",
    "                \"confidence_adjustment\": 0.0,\n",
    "                \"rationale\": llm_response\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"test_result\": result.get(\"test_result\", \"unclear\"),\n",
    "            \"counterfactual_scenario\": result.get(\"counterfactual_scenario\", \"\"),\n",
    "            \"outcome_without_intervention\": result.get(\"outcome_without_intervention\", \"\"),\n",
    "            \"confidence_adjustment\": result.get(\"confidence_adjustment\", 0.0),\n",
    "            \"rationale\": result.get(\"rationale\", \"\"),\n",
    "            \"raw_response\": llm_response\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"test_result\": \"error\",\n",
    "            \"counterfactual_scenario\": \"\",\n",
    "            \"outcome_without_intervention\": \"\",\n",
    "            \"confidence_adjustment\": 0.0,\n",
    "            \"rationale\": f\"Error: {str(e)}\",\n",
    "            \"raw_response\": \"\"\n",
    "        }\n",
    "\n",
    "print('✓ Forward and counterfactual reasoning functions defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 综合评估并做出最终决策"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Final decision function defined\n"
     ]
    }
   ],
   "source": [
    "def make_final_decision(\n",
    "    question: str,\n",
    "    observable_outcome: str,\n",
    "    choice_evaluations: List[Dict[str, Any]],\n",
    "    model: str\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    基于所有choice的正向和反事实推理结果做出最终决策\n",
    "    \n",
    "    Args:\n",
    "        question: 原始问题\n",
    "        observable_outcome: 观察对象\n",
    "        choice_evaluations: 所有choice的评估结果\n",
    "        model: LLM模型\n",
    "    \n",
    "    Returns:\n",
    "        最终决策\n",
    "    \"\"\"\n",
    "    # 构建评估摘要\n",
    "    eval_summary = f\"Observable Outcome: {observable_outcome}\\n\\n\"\n",
    "    \n",
    "    for eval_data in choice_evaluations:\n",
    "        choice = eval_data['choice']\n",
    "        forward = eval_data['forward_reasoning']\n",
    "        counterfactual = eval_data['counterfactual_reasoning']\n",
    "        \n",
    "        final_conf = forward['confidence'] + counterfactual.get('confidence_adjustment', 0)\n",
    "        final_conf = max(0.0, min(1.0, final_conf))  # Clamp to [0, 1]\n",
    "        \n",
    "        eval_summary += f\"CHOICE: {choice.upper()}\\n\"\n",
    "        eval_summary += f\"  Forward Confidence: {forward['confidence']:.2f}\\n\"\n",
    "        eval_summary += f\"  Path Strength: {forward['path_strength']}\\n\"\n",
    "        eval_summary += f\"  Counterfactual Test: {counterfactual['test_result']}\\n\"\n",
    "        eval_summary += f\"  Confidence Adjustment: {counterfactual.get('confidence_adjustment', 0):+.2f}\\n\"\n",
    "        eval_summary += f\"  Final Confidence: {final_conf:.2f}\\n\"\n",
    "        eval_summary += f\"  Forward Rationale: {forward['rationale'][:150]}...\\n\"\n",
    "        eval_summary += f\"  Counterfactual Rationale: {counterfactual['rationale'][:150]}...\\n\\n\"\n",
    "    \n",
    "    prompt = f\"\"\"You are a causal reasoning expert. Make a FINAL DECISION based on forward and counterfactual reasoning for all three choices.\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "EVALUATION SUMMARY:\n",
    "{eval_summary}\n",
    "\n",
    "DECISION CRITERIA (in priority order):\n",
    "1. **Counterfactual Test Result**: Choices that PASS the test are strongly preferred\n",
    "   - \"pass\" means the causal relationship is validated\n",
    "   - \"fail\" means the causal relationship is questionable\n",
    "   - \"unclear\" means insufficient information\n",
    "\n",
    "2. **Final Confidence Score**: After counterfactual adjustment\n",
    "   - Choose the option with HIGHEST final confidence\n",
    "   - But heavily weight counterfactual test results\n",
    "\n",
    "3. **Path Strength**: Prefer \"strong\" > \"moderate\" > \"weak\" > \"none\"\n",
    "\n",
    "SPECIAL RULES:\n",
    "- If \"no_effect\" PASSES counterfactual test with confidence > 0.6 → STRONGLY prefer it\n",
    "- If all choices have weak path strength and low confidence → default to \"no_effect\"\n",
    "- If a choice FAILS counterfactual test → significantly lower its priority\n",
    "\n",
    "Return in JSON format:\n",
    "{{\n",
    "  \"final_answer\": \"more|less|no_effect\",\n",
    "  \"confidence\": 0.0-1.0,\n",
    "  \"reasoning\": \"Explain your decision considering both forward and counterfactual reasoning (3-5 sentences)\",\n",
    "  \"decision_basis\": \"counterfactual_test|highest_confidence|path_strength|default_no_effect\"\n",
    "}}\n",
    "\n",
    "Return ONLY JSON, nothing else.\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = ollama.generate(model=model, prompt=prompt)\n",
    "        llm_response = response.get(\"response\", \"\").strip()\n",
    "        \n",
    "        import re\n",
    "        json_match = re.search(r\"\\{[^}]+\\}\", llm_response, re.DOTALL)\n",
    "        if json_match:\n",
    "            result = json.loads(json_match.group())\n",
    "        else:\n",
    "            # Fallback: 选择通过反事实测试且置信度最高的选项\n",
    "            best_choice = None\n",
    "            best_score = -1\n",
    "            for eval_data in choice_evaluations:\n",
    "                forward = eval_data['forward_reasoning']\n",
    "                counterfactual = eval_data['counterfactual_reasoning']\n",
    "                final_conf = forward['confidence'] + counterfactual.get('confidence_adjustment', 0)\n",
    "                \n",
    "                score = final_conf\n",
    "                if counterfactual['test_result'] == 'pass':\n",
    "                    score += 0.5  # Boost for passing counterfactual test\n",
    "                \n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_choice = eval_data['choice']\n",
    "            \n",
    "            result = {\n",
    "                \"final_answer\": best_choice or \"no_effect\",\n",
    "                \"confidence\": best_score,\n",
    "                \"reasoning\": \"Fallback decision based on scores\",\n",
    "                \"decision_basis\": \"highest_confidence\"\n",
    "            }\n",
    "        \n",
    "        final_answer = result.get(\"final_answer\", \"\").strip().lower()\n",
    "        if final_answer not in [\"more\", \"less\", \"no_effect\"]:\n",
    "            # Fallback\n",
    "            best_choice = max(choice_evaluations, \n",
    "                            key=lambda x: x['forward_reasoning']['confidence'] + \n",
    "                                        x['counterfactual_reasoning'].get('confidence_adjustment', 0))\n",
    "            final_answer = best_choice['choice']\n",
    "        \n",
    "        return {\n",
    "            \"final_answer\": final_answer,\n",
    "            \"confidence\": result.get(\"confidence\", 0.0),\n",
    "            \"reasoning\": result.get(\"reasoning\", \"\"),\n",
    "            \"decision_basis\": result.get(\"decision_basis\", \"highest_confidence\"),\n",
    "            \"raw_response\": llm_response\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Error fallback\n",
    "        best_choice = max(choice_evaluations, \n",
    "                        key=lambda x: x['forward_reasoning']['confidence'] + \n",
    "                                    x['counterfactual_reasoning'].get('confidence_adjustment', 0))\n",
    "        return {\n",
    "            \"final_answer\": best_choice['choice'],\n",
    "            \"confidence\": 0.5,\n",
    "            \"reasoning\": f\"Error fallback: {str(e)}\",\n",
    "            \"decision_basis\": \"error_fallback\",\n",
    "            \"raw_response\": \"\"\n",
    "        }\n",
    "\n",
    "print('✓ Final decision function defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Main prediction function (V2) defined\n",
      "\n",
      "============================================================\n",
      "Running Choice Reasoning with Observable Outcome Integration\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Processing Sample 1/5\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Question: suppose getting a storm over the coast from the ocean happens, how will it affect MORE erosion by the ocean.\n",
      "============================================================\n",
      "\n",
      "[Step 1] Parsing question structure...\n",
      "  Intervention: getting a storm over the coast from the ocean happens\n",
      "  Target: erosion by the ocean\n",
      "\n",
      "[Step 2] Building causal chain with observable outcome identification...\n",
      "[17:47:20] \n",
      "============================================================\n",
      "[17:47:20] STEP 0: Identify Observable Outcome\n",
      "[17:47:20] ============================================================\n",
      "[17:47:22] \n",
      "LLM Response:\n",
      "```json\n",
      "{\n",
      "  \"observable_outcome\": \"increased rate of shoreline erosion\",\n",
      "  \"reasoning\": \"Storms are a known factor contributing to coastal erosion. The question implies a causal relationship between the storm and a measurable increase in the physical process of erosion along the coastline.\"\n",
      "}\n",
      "```\n",
      "[17:47:22] \n",
      "✅ Observable Outcome: increased rate of shoreline erosion\n",
      "[17:47:22]    Reasoning: Storms are a known factor contributing to coastal erosion. The question implies a causal relationship between the storm and a measurable increase in the physical process of erosion along the coastline...\n",
      "[17:47:22] \n",
      "============================================================\n",
      "[17:47:22] STEP 1: Extract Seed Entities\n",
      "[17:47:22] ============================================================\n",
      "[17:47:22] \n",
      "LLM Response:\n",
      "storm\n",
      "coast\n",
      "ocean\n",
      "erosion\n",
      "shoreline\n",
      "[17:47:29] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"storm\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"wave energy\", \n",
      "    \"description\": \"Storms generate larger waves with higher kinetic energy.\",\n",
      "    \"confidence\": 0.92\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"wave energy\",\n",
      "    \"relation\": \"causes\",\n",
      "    \"tail\": \"coastal erosion\",\n",
      "    \"description\": \"High-energy waves impacting the coast physically break down and remove sediment.\",\n",
      "    \"confidence\": 0.85\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"coast\",\n",
      "    \"relation\": \"exposes\",\n",
      "    \"tail\": \"shoreline rock\",\n",
      "    \"des...\n",
      "[17:47:29] Generated 3 relations (novel_entities=3)\n",
      "[17:47:36] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"wave energy\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"erosion\",\n",
      "    \"description\": \"Higher wave energy directly exerts greater force on the shoreline, leading to increased erosion.\",\n",
      "    \"confidence\": 0.92\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"storm\",\n",
      "    \"relation\": \"causes\",\n",
      "    \"tail\": \"increasedWaveEnergy\",\n",
      "    \"description\": \"Storms generate high winds and turbulent seas, directly resulting in increased wave energy.\",\n",
      "    \"confidence\": 0.85\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"increasedWaveEnergy\",\n",
      " ...\n",
      "[17:47:36] Generated 3 relations (novel_entities=2)\n",
      "[17:47:43] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"storm\",\n",
      "    \"relation\": \"produces\",\n",
      "    \"tail\": \"increasedWaveEnergy\",\n",
      "    \"description\": \"Storms generate strong winds and low atmospheric pressure which directly increase wave height and energy in the ocean.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"increasedWaveEnergy\",\n",
      "    \"relation\": \"causes\",\n",
      "    \"tail\": \"higherWaveImpactForce\",\n",
      "    \"description\": \"Waves with higher energy directly translate to a larger force upon impact with the shoreline.\",\n",
      "    \"confidence\": 0.92\n",
      "...\n",
      "[17:47:43] Generated 2 relations (novel_entities=2)\n",
      "[17:47:50] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"wave energy\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"higherWaveImpactForce\",\n",
      "    \"description\": \"Higher wave energy directly translates to a greater force exerted by waves upon impact with the shoreline.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"shoreline\",\n",
      "    \"relation\": \"experiences\",\n",
      "    \"tail\": \"higherWaveImpactForce\",\n",
      "    \"description\": \"The shoreline is directly subject to the force of waves impacting it.\",\n",
      "    \"confidence\": 0.98\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"higherWave...\n",
      "[17:47:50] Generated 3 relations (novel_entities=1)\n",
      "[17:47:58] LLM Response:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"head\": \"ocean\",\n",
      "    \"relation\": \"generates\",\n",
      "    \"tail\": \"tidalChanges\",\n",
      "    \"description\": \"The gravitational pull of the moon and sun on the ocean's water mass directly causes tidal changes.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"tidalChanges\",\n",
      "    \"relation\": \"causes\",\n",
      "    \"tail\": \"increasedWaveEnergy\",\n",
      "    \"description\": \"Tidal changes, particularly high tides, lead to larger waves as more water is drawn towards the shore and interacts with prevailing winds.\",\n",
      "    ...\n",
      "[17:47:58] Generated 3 relations (novel_entities=3)\n",
      "[17:48:06] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"tidalChanges\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"tidalRange\",\n",
      "    \"description\": \"Larger tidal changes result in a greater difference between high and low tides.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"tidalRange\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"waterDepthFluctuation\",\n",
      "    \"description\": \"A wider tidal range leads to a greater fluctuation in water depth along the shoreline.\",\n",
      "    \"confidence\": 0.88\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"waterDepthFluctuation\",\n",
      "    \"re...\n",
      "[17:48:06] Generated 3 relations (novel_entities=3)\n",
      "[17:48:13] LLM Response:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"head\": \"tidalChanges\",\n",
      "    \"relation\": \"produces\",\n",
      "    \"tail\": \"tidalRange\",\n",
      "    \"description\": \"Tidal changes directly result in the difference in height between high tide and low tide.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"tidalRange\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"waveHeight\",\n",
      "    \"description\": \"A larger tidal range (difference between high and low tides) can lead to higher waves, especially in coastal areas.\",\n",
      "    \"confidence\": 0.82\n",
      "  },\n",
      "  {\n",
      "    \"head...\n",
      "[17:48:13] Generated 3 relations (novel_entities=3)\n",
      "[17:48:22] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"higherWaveImpactForce\",\n",
      "    \"relation\": \"causes\",\n",
      "    \"tail\": \"shorelineRockDislodgement\",\n",
      "    \"description\": \"Increased force from waves directly dislodges shoreline rocks.\",\n",
      "    \"confidence\": 0.92\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"shorelineRockDislodgement\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"ErosionRateOfShorelineRocks\",\n",
      "    \"description\": \"Each dislodged rock contributes to the overall rate of shoreline erosion.\",\n",
      "    \"confidence\": 0.85\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"waveEnergy\",\n",
      "    \"r...\n",
      "[17:48:22] Generated 3 relations (novel_entities=3)\n",
      "[17:48:31] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"higherWaveImpactForce\",\n",
      "    \"relation\": \"causes\",\n",
      "    \"tail\": \"IncreasedStressOnShorelineRocks\",\n",
      "    \"description\": \"Higher force from waves directly increases the mechanical stress experienced by rocks along the shoreline.\",\n",
      "    \"confidence\": 0.92\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"IncreasedStressOnShorelineRocks\",\n",
      "    \"relation\": \"causes\",\n",
      "    \"tail\": \"shorelineRockDislodgement\",\n",
      "    \"description\": \"Beyond a certain stress threshold, the force of the waves will cause rocks to break apart...\n",
      "[17:48:31] Generated 5 relations (novel_entities=5)\n",
      "[17:48:40] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"WaveImpactForceAtShoreline\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"shoreline rock\",\n",
      "    \"description\": \"Direct force from waves striking the shoreline increases stress on individual rocks.\",\n",
      "    \"confidence\": 0.92\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"shoreline rock\",\n",
      "    \"relation\": \"experiences\",\n",
      "    \"tail\": \"IncreasedStressOnShorelineRocks\",\n",
      "    \"description\": \"The shoreline rock directly undergoes increased pressure and force due to wave impacts.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    ...\n",
      "[17:48:40] Generated 5 relations (novel_entities=1)\n",
      "[17:48:50] LLM Response:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"head\": \"WaveImpactForceAtShoreline\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"ErosionRateOfShorelineRocks\",\n",
      "    \"description\": \"Higher force of waves hitting the shoreline directly leads to increased erosion of rocks.\",\n",
      "    \"confidence\": 0.92\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"ErosionRateOfShorelineRocks\",\n",
      "    \"relation\": \"produces\",\n",
      "    \"tail\": \"shorelineRockDislodgement\",\n",
      "    \"description\": \"The process of erosion physically breaks and displaces rock fragments from the shoreline.\",\n",
      "    ...\n",
      "[17:48:50] Generated 3 relations (novel_entities=1)\n",
      "[17:49:00] LLM Response:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"head\": \"increasedWaveEnergy\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"WaveImpactForceAtShoreline\",\n",
      "    \"description\": \"Higher wave energy directly translates to a greater force exerted on the shoreline upon impact.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"WaveImpactForceAtShoreline\",\n",
      "    \"relation\": \"causes\",\n",
      "    \"tail\": \"VariableWaveImpactForce\",\n",
      "    \"description\": \"The force of waves hitting the shore varies depending on wave height, period, and angle. Increased wave...\n",
      "[17:49:00] Generated 5 relations (novel_entities=1)\n",
      "[17:49:09] LLM Response:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"head\": \"waveEnergy\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"WaveImpactForceAtShoreline\",\n",
      "    \"description\": \"Higher wave energy directly translates to a greater force exerted on the shoreline upon impact.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"WaveImpactForceAtShoreline\",\n",
      "    \"relation\": \"causes\",\n",
      "    \"tail\": \"VariableWaveImpactForce\",\n",
      "    \"description\": \"The force of waves hitting the shore varies depending on factors like wave energy, tide levels and shoreline top...\n",
      "[17:49:09] Generated 3 relations (novel_entities=1)\n",
      "[17:49:18] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"wave energy\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"WaveImpactForceAtShoreline\",\n",
      "    \"description\": \"Higher wave energy directly translates to a greater force exerted on the shoreline upon impact.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"WaveImpactForceAtShoreline\",\n",
      "    \"relation\": \"causes\",\n",
      "    \"tail\": \"WaterLevelFluctuationsDuringWaveImpact\",\n",
      "    \"description\": \"The force of waves hitting the shore directly causes fluctuations in water levels at the point of impact...\n",
      "[17:49:27] Fallback LLM Response:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"head\": \"WaveEnergy\",\n",
      "    \"relation\": \"causes\",\n",
      "    \"tail\": \"HydrodynamicForceOnShorelineRocks\",\n",
      "    \"description\": \"Wave energy directly translates into hydrodynamic forces acting on shoreline rocks.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"WaveEnergyConcentration\",\n",
      "    \"relation\": \"influences\",\n",
      "    \"tail\": \"WaveEnergy\",\n",
      "    \"description\": \"Factors like wave refraction and diffraction can concentrate wave energy in certain areas, increasing its intensity.\",\n",
      "    \"confiden...\n",
      "[17:49:27] Generated 4 relations (novel_entities=0)\n",
      "[17:49:34] Backfilled 5 missing relations among known entities\n",
      "[17:49:34] \n",
      "============================================================\n",
      "[17:49:34] FINAL STATISTICS\n",
      "[17:49:34] ============================================================\n",
      "[17:49:34] Total entities: 27 (seeds=5, expanded=22)\n",
      "[17:49:34] Total edges: 53\n",
      "[17:49:34] Causal chains: 10\n",
      "[17:49:34] \n",
      "Relation types:\n",
      "[17:49:34]   - increases: 23\n",
      "[17:49:34]   - causes: 20\n",
      "[17:49:34]   - experiences: 3\n",
      "[17:49:34]   - generates: 2\n",
      "[17:49:34]   - exposes: 1\n",
      "[17:49:34]   - canTrigger: 1\n",
      "[17:49:34]   - triggers: 1\n",
      "[17:49:34]   - is susceptible to: 1\n",
      "[17:49:34]   - contributes to: 1\n",
      "\n",
      "  Observable Outcome: increased rate of shoreline erosion\n",
      "  Reasoning: Storms are a known factor contributing to coastal erosion. The question implies a causal relationship between the storm and a measurable increase in t...\n",
      "  Seeds found: 5\n",
      "  Total edges: 53\n",
      "\n",
      "[Step 3] Formatting causal chains...\n",
      "  Causal Chains:\n",
      "      (No causal chains found)\n",
      "\n",
      "[Step 4] Evaluating each choice...\n",
      "\n",
      "  --- Evaluating: MORE ---\n",
      "    Forward reasoning...\n",
      "      Confidence: 0.00\n",
      "      Path Strength: none\n",
      "    Counterfactual reasoning...\n",
      "      Test Result: error\n",
      "      Confidence Adjustment: +0.00\n",
      "\n",
      "  --- Evaluating: LESS ---\n",
      "    Forward reasoning...\n",
      "      Confidence: 0.00\n",
      "      Path Strength: none\n",
      "    Counterfactual reasoning...\n",
      "      Test Result: error\n",
      "      Confidence Adjustment: +0.00\n",
      "\n",
      "  --- Evaluating: NO_EFFECT ---\n",
      "    Forward reasoning...\n",
      "      Confidence: 1.00\n",
      "      Path Strength: none\n",
      "    Counterfactual reasoning...\n",
      "      Test Result: fail\n",
      "      Confidence Adjustment: -0.20\n",
      "\n",
      "[Step 5] Making final decision...\n",
      "\n",
      "  Final Answer: MORE\n",
      "  Gold Answer: MORE\n",
      "  Result: ✓ CORRECT\n",
      "  Confidence: 0.87\n",
      "\n",
      "============================================================\n",
      "Processing Sample 2/5\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Question: suppose use less batter per pancake happens, how will it affect LESS babies.\n",
      "============================================================\n",
      "\n",
      "[Step 1] Parsing question structure...\n",
      "  Intervention: use less batter per pancake happens\n",
      "  Target: babies\n",
      "\n",
      "[Step 2] Building causal chain with observable outcome identification...\n",
      "[17:49:56] \n",
      "============================================================\n",
      "[17:49:56] STEP 0: Identify Observable Outcome\n",
      "[17:49:56] ============================================================\n",
      "[17:49:58] \n",
      "LLM Response:\n",
      "```json\n",
      "{\n",
      "  \"observable_outcome\": \"Number of babies born\",\n",
      "  \"reasoning\": \"The question connects a change in pancake batter usage (likely implying less food consumption) to an impact on 'babies'. The most direct and plausible interpretation is that this refers to the number of babies born, as food availability can influence birth rates.\" \n",
      "}\n",
      "```\n",
      "[17:49:58] \n",
      "✅ Observable Outcome: Number of babies born\n",
      "[17:49:58]    Reasoning: The question connects a change in pancake batter usage (likely implying less food consumption) to an impact on 'babies'. The most direct and plausible interpretation is that this refers to the number ...\n",
      "[17:49:58] \n",
      "============================================================\n",
      "[17:49:58] STEP 1: Extract Seed Entities\n",
      "[17:49:58] ============================================================\n",
      "[17:49:58] \n",
      "LLM Response:\n",
      "batter\n",
      "pancake\n",
      "babies\n",
      "[17:50:07] LLM Response:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"head\": \"batter\",\n",
      "    \"relation\": \"is used to make\",\n",
      "    \"tail\": \"pancakes\",\n",
      "    \"description\": \"Batter is a mixture used as the primary ingredient for making pancakes.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"pancakes\",\n",
      "    \"relation\": \"are consumed by\",\n",
      "    \"tail\": \"pregnant women\",\n",
      "    \"description\": \"Pregnant women may choose to consume pancakes as part of their diet.\",\n",
      "    \"confidence\": 0.78\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"pregnant women\",\n",
      "    \"relation\": \"require\",\n",
      "    \"tail\"...\n",
      "[17:50:07] Generated 1 relations (novel_entities=1)\n",
      "[17:50:15] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"pregnancies\",\n",
      "    \"relation\": \"produces\",\n",
      "    \"tail\": \"babies\",\n",
      "    \"description\": \"Successful pregnancies directly result in the birth of babies.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"fertility rate\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"pregnancies\",\n",
      "    \"description\": \"A higher fertility rate (births per woman) directly leads to more pregnancies.\",\n",
      "    \"confidence\": 0.88\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"access to healthcare\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"suc...\n",
      "[17:50:15] Generated 2 relations (novel_entities=2)\n",
      "[17:50:24] LLM Response:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"head\": \"batter\",\n",
      "    \"relation\": \"produces\",\n",
      "    \"tail\": \"pancake\",\n",
      "    \"description\": \"Mixing and cooking batter directly results in the formation of a pancake.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"pancake\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"breakfast_calorie_intake\",\n",
      "    \"description\": \"Eating a pancake directly contributes to an increase in calories consumed during breakfast.\",\n",
      "    \"confidence\": 0.85\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"breakfast_calorie_intake\",\n",
      "    \"re...\n",
      "[17:50:24] Generated 2 relations (novel_entities=1)\n",
      "[17:50:33] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"Infant Mortality Rate\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"Preterm Birth Prevalence\",\n",
      "    \"description\": \"Higher infant mortality rates are often associated with a higher prevalence of preterm births.\",\n",
      "    \"confidence\": 0.85\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"Preterm Birth Prevalence\",\n",
      "    \"relation\": \"causes\",\n",
      "    \"tail\": \"Low Birth Weight\",\n",
      "    \"description\": \"Babies born prematurely are more likely to have low birth weight, a significant risk factor for infant mortality.\",\n",
      "    \"...\n",
      "[17:50:42] Fallback LLM Response:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"head\": \"Infant Mortality Rate\",\n",
      "    \"relation\": \"increases with\",\n",
      "    \"tail\": \"Maternal Malnutrition\",\n",
      "    \"description\": \"Insufficient nutrition during pregnancy can lead to complications and higher risk of infant mortality.\",\n",
      "    \"confidence\": 0.85\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"Access to Prenatal Care\",\n",
      "    \"relation\": \"decreases\",\n",
      "    \"tail\": \"Infant Mortality Rate\",\n",
      "    \"description\": \"Regular prenatal checkups allow for early detection and management of potential health issues, r...\n",
      "[17:50:42] Generated 0 relations (novel_entities=0)\n",
      "[17:50:50] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"pancakes\",\n",
      "    \"relation\": \"causes\",\n",
      "    \"tail\": \"breakfast_calorie_intake\",\n",
      "    \"description\": \"Consuming pancakes contributes to the total calorie intake during breakfast.\",\n",
      "    \"confidence\": 0.85\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"breakfast_calorie_intake\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"blood_sugar_levels\",\n",
      "    \"description\": \"Consuming a high-calorie meal like pancakes leads to a rise in blood sugar.\",\n",
      "    \"confidence\": 0.92\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"blood_sugar_levels\",\n",
      "    \"r...\n",
      "[17:50:50] Generated 2 relations (novel_entities=1)\n",
      "[17:50:59] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"fertilization\",\n",
      "    \"relation\": \"causes\",\n",
      "    \"tail\": \"pregnancies\",\n",
      "    \"description\": \"The successful union of a sperm and egg cell initiates the biological processes leading to pregnancy.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"pregnancies\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"fetal_development_rate\",\n",
      "    \"description\": \"The physiological environment of a pregnancy supports and accelerates the growth and development of the fetus.\",\n",
      "    \"confidence\": 0.88\n",
      "  },\n",
      " ...\n",
      "[17:50:59] Generated 3 relations (novel_entities=3)\n",
      "[17:51:09] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"breakfast_calorie_intake\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"blood_sugar_levels\",\n",
      "    \"description\": \"Consuming calories at breakfast directly raises blood glucose levels.\",\n",
      "    \"confidence\": 0.92\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"blood_sugar_levels\",\n",
      "    \"relation\": \"affects\",\n",
      "    \"tail\": \"fetal_development_rate\",\n",
      "    \"description\": \"Maternal blood sugar levels directly influence nutrient availability for the fetus, affecting its growth rate.\",\n",
      "    \"confidence\": 0.85\n",
      "  },\n",
      "  {\n",
      "   ...\n",
      "[17:51:09] Generated 3 relations (novel_entities=2)\n",
      "[17:51:13] Backfilled 3 missing relations among known entities\n",
      "[17:51:13] \n",
      "============================================================\n",
      "[17:51:13] FINAL STATISTICS\n",
      "[17:51:13] ============================================================\n",
      "[17:51:13] Total entities: 13 (seeds=3, expanded=10)\n",
      "[17:51:13] Total edges: 16\n",
      "[17:51:13] Causal chains: 10\n",
      "[17:51:13] \n",
      "Relation types:\n",
      "[17:51:13]   - increases: 4\n",
      "[17:51:13]   - produces: 3\n",
      "[17:51:13]   - causes: 3\n",
      "[17:51:13]   - is used to make: 1\n",
      "[17:51:13]   - decreases: 1\n",
      "[17:51:13]   - correlates_with: 1\n",
      "[17:51:13]   - affects: 1\n",
      "[17:51:13]   - is made from: 1\n",
      "[17:51:13]   - supports: 1\n",
      "\n",
      "  Observable Outcome: Number of babies born\n",
      "  Reasoning: The question connects a change in pancake batter usage (likely implying less food consumption) to an impact on 'babies'. The most direct and plausible...\n",
      "  Seeds found: 3\n",
      "  Total edges: 16\n",
      "\n",
      "[Step 3] Formatting causal chains...\n",
      "  Causal Chains:\n",
      "      (No causal chains found)\n",
      "\n",
      "[Step 4] Evaluating each choice...\n",
      "\n",
      "  --- Evaluating: MORE ---\n",
      "    Forward reasoning...\n",
      "      Confidence: 0.00\n",
      "      Path Strength: none\n",
      "    Counterfactual reasoning...\n",
      "      Test Result: fail\n",
      "      Confidence Adjustment: -0.20\n",
      "\n",
      "  --- Evaluating: LESS ---\n",
      "    Forward reasoning...\n",
      "      Confidence: 0.00\n",
      "      Path Strength: none\n",
      "    Counterfactual reasoning...\n",
      "      Test Result: fail\n",
      "      Confidence Adjustment: -0.20\n",
      "\n",
      "  --- Evaluating: NO_EFFECT ---\n",
      "    Forward reasoning...\n",
      "      Confidence: 1.00\n",
      "      Path Strength: none\n",
      "    Counterfactual reasoning...\n",
      "      Test Result: pass\n",
      "      Confidence Adjustment: +0.10\n",
      "\n",
      "[Step 5] Making final decision...\n",
      "\n",
      "  Final Answer: NO_EFFECT\n",
      "  Gold Answer: NO_EFFECT\n",
      "  Result: ✓ CORRECT\n",
      "  Confidence: 1.00\n",
      "\n",
      "============================================================\n",
      "Processing Sample 3/5\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Question: suppose Having a stomach bug happens, how will it affect MORE vegetables.\n",
      "============================================================\n",
      "\n",
      "[Step 1] Parsing question structure...\n",
      "  Intervention: Having a stomach bug happens\n",
      "  Target: vegetables\n",
      "\n",
      "[Step 2] Building causal chain with observable outcome identification...\n",
      "[17:51:34] \n",
      "============================================================\n",
      "[17:51:34] STEP 0: Identify Observable Outcome\n",
      "[17:51:34] ============================================================\n",
      "[17:51:36] \n",
      "LLM Response:\n",
      "```json\n",
      "{\n",
      "  \"observable_outcome\": \"Eating fewer vegetables\",\n",
      "  \"reasoning\": \"A stomach bug typically leads to nausea, vomiting, and diarrhea. These symptoms would likely make someone less inclined to eat vegetables or any other food.\" \n",
      "}\n",
      "```\n",
      "[17:51:36] \n",
      "✅ Observable Outcome: Eating fewer vegetables\n",
      "[17:51:36]    Reasoning: A stomach bug typically leads to nausea, vomiting, and diarrhea. These symptoms would likely make someone less inclined to eat vegetables or any other food....\n",
      "[17:51:36] \n",
      "============================================================\n",
      "[17:51:36] STEP 1: Extract Seed Entities\n",
      "[17:51:36] ============================================================\n",
      "[17:51:36] \n",
      "LLM Response:\n",
      "stomach bug\n",
      "vegetables \n",
      "appetite \n",
      "digestion \n",
      "nutrients\n",
      "[17:51:44] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"vegetables\",\n",
      "    \"relation\": \"provide\",\n",
      "    \"tail\": \"nutrients\",\n",
      "    \"description\": \"Vegetables are a source of essential nutrients.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"nutrients\",\n",
      "    \"relation\": \"affect\",\n",
      "    \"tail\": \"appetite\",\n",
      "    \"description\": \"Certain nutrients can influence feelings of fullness and satiety, affecting appetite.\",\n",
      "    \"confidence\": 0.78\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"vegetables\",\n",
      "    \"relation\": \"increase\",\n",
      "    \"tail\": \"fiber intake\",\n",
      "    \"description\"...\n",
      "[17:51:44] Generated 3 relations (novel_entities=1)\n",
      "[17:51:56] LLM Response:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"head\": \"vegetables\",\n",
      "    \"relation\": \"provides\",\n",
      "    \"tail\": \"nutrients\",\n",
      "    \"description\": \"Vegetables are a source of essential nutrients.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"nutrients\",\n",
      "    \"relation\": \"influences\",\n",
      "    \"tail\": \"appetite\",\n",
      "    \"description\": \"Adequate nutrient intake helps regulate appetite signals.\",\n",
      "    \"confidence\": 0.88\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"nutrients\",\n",
      "    \"relation\": \"affect\",\n",
      "    \"tail\": \"bioavailability\",\n",
      "    \"description\": \"Nutrient typ...\n",
      "[17:51:56] Generated 2 relations (novel_entities=2)\n",
      "[17:52:04] LLM Response:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"head\": \"fiber intake\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"digestion time\",\n",
      "    \"description\": \"Dietary fiber adds bulk to stool and slows down the digestive process.\",\n",
      "    \"confidence\": 0.85\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"digestion time\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"satiety\",\n",
      "    \"description\": \"Longer digestion time leads to prolonged feelings of fullness.\",\n",
      "    \"confidence\": 0.78\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"satiety\",\n",
      "    \"relation\": \"decreases\",\n",
      "    \"tail\": \"appetite\",...\n",
      "[17:52:04] Generated 4 relations (novel_entities=4)\n",
      "[17:52:13] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"nutrient_levels\",\n",
      "    \"relation\": \"affects\",\n",
      "    \"tail\": \"satiety_hormones\",\n",
      "    \"description\": \"Specific nutrient levels in the blood trigger the release of satiety hormones.\",\n",
      "    \"confidence\": 0.85\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"satiety_hormones\",\n",
      "    \"relation\": \"reduces\",\n",
      "    \"tail\": \"appetite\",\n",
      "    \"description\": \"Satiety hormones signal the brain that the body is full, leading to a decrease in appetite.\",\n",
      "    \"confidence\": 0.92\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"fiber_intake\",\n",
      "    \"relation\"...\n",
      "[17:52:13] Generated 3 relations (novel_entities=3)\n",
      "[17:52:21] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"stomach bug\",\n",
      "    \"relation\": \"causes\",\n",
      "    \"tail\": \"nausea\",\n",
      "    \"description\": \"Stomach bugs often directly cause feelings of nausea.\",\n",
      "    \"confidence\": 0.92\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"nausea\",\n",
      "    \"relation\": \"reduces\",\n",
      "    \"tail\": \"appetite\",\n",
      "    \"description\": \"Experiencing nausea directly decreases one's desire to eat.\",\n",
      "    \"confidence\": 0.85\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"reduced appetite\",\n",
      "    \"relation\": \"leads_to\",\n",
      "    \"tail\": \"decreased food_consumption\",\n",
      "    \"description\": \"A ...\n",
      "[17:52:21] Generated 3 relations (novel_entities=3)\n",
      "[17:52:30] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"nutrient_release\",\n",
      "    \"relation\": \"causes\",\n",
      "    \"tail\": \"satiety_hormones\",\n",
      "    \"description\": \"Digestion of nutrients releases hormones that signal satiety to the brain.\",\n",
      "    \"confidence\": 0.92\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"satiety_hormones\",\n",
      "    \"relation\": \"triggers\",\n",
      "    \"tail\": \"satiety\",\n",
      "    \"description\": \"Satiety hormones act on receptors in the brain, leading to a feeling of fullness and satisfaction.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"fiber intake\",\n",
      "    \"relati...\n",
      "[17:52:30] Generated 4 relations (novel_entities=1)\n",
      "[17:52:39] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"intestinal_inflammation\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"intestinal_permeability\",\n",
      "    \"description\": \"Inflammation in the intestines directly leads to increased permeability of the intestinal lining.\",\n",
      "    \"confidence\": 0.85\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"intestinal_permeability\",\n",
      "    \"relation\": \"causes\",\n",
      "    \"tail\": \"leaky_gut_syndrome\",\n",
      "    \"description\": \"Increased intestinal permeability allows substances to pass through the gut lining that normally wouldn't, leading t...\n",
      "[17:52:39] Generated 3 relations (novel_entities=3)\n",
      "[17:52:48] LLM Response:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"head\": \"food_consumption\",\n",
      "    \"relation\": \"produces\",\n",
      "    \"tail\": \"nutrient_levels\",\n",
      "    \"description\": \"Eating food introduces nutrients into the body, directly affecting nutrient levels.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"nutrient_levels\",\n",
      "    \"relation\": \"triggers\",\n",
      "    \"tail\": \"satiety_hormones_release\",\n",
      "    \"description\": \"Sufficient nutrient levels in the bloodstream stimulate the release of satiety hormones.\",\n",
      "    \"confidence\": 0.87\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"nu...\n",
      "[17:52:48] Generated 5 relations (novel_entities=4)\n",
      "[17:52:57] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"intestinal_inflammation\",\n",
      "    \"relation\": \"causes\",\n",
      "    \"tail\": \"nausea\",\n",
      "    \"description\": \"Inflammation in the intestines can directly irritate the stomach lining and trigger nausea.\",\n",
      "    \"confidence\": 0.75\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"nausea\",\n",
      "    \"relation\": \"triggers\",\n",
      "    \"tail\": \"reduced_food_consumption\",\n",
      "    \"description\": \"The feeling of nausea directly leads to a decreased desire and ability to eat.\",\n",
      "    \"confidence\": 0.92\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"nausea\",\n",
      "    \"relation\": ...\n",
      "[17:52:57] Generated 5 relations (novel_entities=4)\n",
      "[17:53:11] LLM Response:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"head\": \"nutrient_levels\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"bioavailability\",\n",
      "    \"description\": \"Higher nutrient levels in food generally lead to increased bioavailability of those nutrients.\",\n",
      "    \"confidence\": 0.85\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"bioavailability\",\n",
      "    \"relation\": \"triggers\",\n",
      "    \"tail\": \"nutrient_absorption_rate\",\n",
      "    \"description\": \"The degree to which a nutrient is bioavailable directly influences how quickly it is absorbed by the body.\",\n",
      "    \"confidence\": ...\n",
      "[17:53:11] Generated 3 relations (novel_entities=2)\n",
      "[17:53:20] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"fiber intake\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"satiety_hormones_release\",\n",
      "    \"description\": \"Dietary fiber promotes the release of satiety hormones like GLP-1 and PYY.\",\n",
      "    \"confidence\": 0.85\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"satiety_hormones_release\",\n",
      "    \"relation\": \"triggers\",\n",
      "    \"tail\": \"early_satiation_signal\",\n",
      "    \"description\": \"Increased release of satiety hormones sends a signal to the brain indicating fullness.\",\n",
      "    \"confidence\": 0.92\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"early_sa...\n",
      "[17:53:20] Generated 4 relations (novel_entities=3)\n",
      "[17:53:30] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"food_consumption\",\n",
      "    \"relation\": \"triggers\",\n",
      "    \"tail\": \"satiety_hormones_release\",\n",
      "    \"description\": \"Eating food initiates the release of satiety hormones.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"satiety_hormones_release\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"blood_satiety_hormone_concentration\",\n",
      "    \"description\": \"The release of satiety hormones directly increases their concentration in the bloodstream.\",\n",
      "    \"confidence\": 0.98\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"blood_s...\n",
      "[17:53:30] Generated 4 relations (novel_entities=3)\n",
      "[17:53:39] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"food_consumption\",\n",
      "    \"relation\": \"triggers\",\n",
      "    \"tail\": \"nutrient_release\",\n",
      "    \"description\": \"Eating food initiates the process of mechanical and chemical breakdown in the digestive system, leading to nutrient release.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"nutrient_release\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"intestinal_nutrient_concentration\",\n",
      "    \"description\": \"The breakdown of food releases nutrients, directly increasing their concentration within the ...\n",
      "[17:53:39] Generated 5 relations (novel_entities=4)\n",
      "[17:53:49] LLM Response:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"head\": \"fiber intake\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"digestion time\",\n",
      "    \"description\": \"Dietary fiber adds bulk to food and slows down the digestive process.\",\n",
      "    \"confidence\": 0.85\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"digestion time\",\n",
      "    \"relation\": \"reduces\",\n",
      "    \"tail\": \"intestinal nutrient concentration\",\n",
      "    \"description\": \"Longer digestion time allows for more gradual release of nutrients into the intestines.\",\n",
      "    \"confidence\": 0.92\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"digestion time...\n",
      "[17:53:49] Generated 3 relations (novel_entities=1)\n",
      "[17:53:58] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"food_consumption\",\n",
      "    \"relation\": \"triggers\",\n",
      "    \"tail\": \"intestinal nutrient concentration\",\n",
      "    \"description\": \"Food consumption introduces nutrients into the digestive system, directly leading to an increase in intestinal nutrient concentration.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"intestinal nutrient concentration\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"nutrient_absorption_rate\",\n",
      "    \"description\": \"Higher concentrations of nutrients in the intestines creat...\n",
      "[17:53:58] Generated 5 relations (novel_entities=3)\n",
      "[17:54:04] Backfilled 4 missing relations among known entities\n",
      "[17:54:04] \n",
      "============================================================\n",
      "[17:54:04] FINAL STATISTICS\n",
      "[17:54:04] ============================================================\n",
      "[17:54:04] Total entities: 38 (seeds=5, expanded=33)\n",
      "[17:54:04] Total edges: 60\n",
      "[17:54:04] Causal chains: 10\n",
      "[17:54:04] \n",
      "Relation types:\n",
      "[17:54:04]   - increases: 18\n",
      "[17:54:04]   - triggers: 10\n",
      "[17:54:04]   - reduces: 6\n",
      "[17:54:04]   - causes: 6\n",
      "[17:54:04]   - decreases: 4\n",
      "[17:54:04]   - produces: 3\n",
      "[17:54:04]   - influences: 3\n",
      "[17:54:04]   - affect: 2\n",
      "[17:54:04]   - affects: 2\n",
      "[17:54:04]   - increase: 1\n",
      "[17:54:04]   - provide: 1\n",
      "[17:54:04]   - impact: 1\n",
      "[17:54:04]   - determines: 1\n",
      "[17:54:04]   - regulates: 1\n",
      "[17:54:04]   - influenced_by: 1\n",
      "\n",
      "  Observable Outcome: Eating fewer vegetables\n",
      "  Reasoning: A stomach bug typically leads to nausea, vomiting, and diarrhea. These symptoms would likely make someone less inclined to eat vegetables or any other...\n",
      "  Seeds found: 5\n",
      "  Total edges: 60\n",
      "\n",
      "[Step 3] Formatting causal chains...\n",
      "  Causal Chains:\n",
      "      (No causal chains found)\n",
      "\n",
      "[Step 4] Evaluating each choice...\n",
      "\n",
      "  --- Evaluating: MORE ---\n",
      "    Forward reasoning...\n",
      "      Confidence: 0.00\n",
      "      Path Strength: none\n",
      "    Counterfactual reasoning...\n",
      "      Test Result: pass\n",
      "      Confidence Adjustment: -0.10\n",
      "\n",
      "  --- Evaluating: LESS ---\n",
      "    Forward reasoning...\n",
      "      Confidence: 0.90\n",
      "      Path Strength: strong\n",
      "    Counterfactual reasoning...\n",
      "      Test Result: error\n",
      "      Confidence Adjustment: +0.00\n",
      "\n",
      "  --- Evaluating: NO_EFFECT ---\n",
      "    Forward reasoning...\n",
      "      Confidence: 1.00\n",
      "      Path Strength: none\n",
      "    Counterfactual reasoning...\n",
      "      Test Result: error\n",
      "      Confidence Adjustment: +0.00\n",
      "\n",
      "[Step 5] Making final decision...\n",
      "\n",
      "  Final Answer: LESS\n",
      "  Gold Answer: NO_EFFECT\n",
      "  Result: ✗ WRONG\n",
      "  Confidence: 0.90\n",
      "\n",
      "============================================================\n",
      "Processing Sample 4/5\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Question: suppose more caterpillar eats happens, how will it affect more toxins are in the liver.\n",
      "============================================================\n",
      "\n",
      "[Step 1] Parsing question structure...\n",
      "  Intervention: more caterpillar eats happens\n",
      "  Target: more toxins are in the liver\n",
      "\n",
      "[Step 2] Building causal chain with observable outcome identification...\n",
      "[17:54:26] \n",
      "============================================================\n",
      "[17:54:26] STEP 0: Identify Observable Outcome\n",
      "[17:54:26] ============================================================\n",
      "[17:54:28] \n",
      "LLM Response:\n",
      "```json\n",
      "{\n",
      "  \"observable_outcome\": \"the concentration of toxins in the liver\",\n",
      "  \"reasoning\": \"The question asks about the effect on 'more toxins are in the liver'. This implies a change in the amount or concentration of toxins within the liver tissue, which is a measurable biological outcome.\" \n",
      "}\n",
      "```\n",
      "[17:54:28] \n",
      "✅ Observable Outcome: the concentration of toxins in the liver\n",
      "[17:54:28]    Reasoning: The question asks about the effect on 'more toxins are in the liver'. This implies a change in the amount or concentration of toxins within the liver tissue, which is a measurable biological outcome....\n",
      "[17:54:28] \n",
      "============================================================\n",
      "[17:54:28] STEP 1: Extract Seed Entities\n",
      "[17:54:28] ============================================================\n",
      "[17:54:28] \n",
      "LLM Response:\n",
      "caterpillar\n",
      "eats\n",
      "toxins\n",
      "liver\n",
      "[17:54:37] LLM Response:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"head\": \"caterpillar\",\n",
      "    \"relation\": \"eats\",\n",
      "    \"tail\": \"leaves\",\n",
      "    \"description\": \"Caterpillars consume leaves as their primary food source.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"leaves\",\n",
      "    \"relation\": \"contain\",\n",
      "    \"tail\": \"toxins\",\n",
      "    \"description\": \"Certain plant species accumulate toxins within their leaves as a defense mechanism against herbivores.\",\n",
      "    \"confidence\": 0.88\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"caterpillar\",\n",
      "    \"relation\": \"accumulates\",\n",
      "    \"tail\": \"to...\n",
      "[17:54:37] Generated 4 relations (novel_entities=3)\n",
      "[17:54:45] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"caterpillar\",\n",
      "    \"relation\": \"eats\",\n",
      "    \"tail\": \"leaves\",\n",
      "    \"description\": \"Caterpillars consume leaves as their primary food source.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"leaves\",\n",
      "    \"relation\": \"contains\",\n",
      "    \"tail\": \"toxins\",\n",
      "    \"description\": \"Some plant species contain toxins within their leaves as a defense mechanism against herbivores.\",\n",
      "    \"confidence\": 0.88\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"eats\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"toxin_ingestion\",\n",
      "    \"d...\n",
      "[17:54:45] Generated 3 relations (novel_entities=3)\n",
      "[17:54:54] LLM Response:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"head\": \"toxin_ingestion\",\n",
      "    \"relation\": \"causes\",\n",
      "    \"tail\": \"liver_toxin_concentration\",\n",
      "    \"description\": \"Ingestion of toxins leads to their accumulation in the liver.\",\n",
      "    \"confidence\": 0.92\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"toxins\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"liver_cellular_stress\",\n",
      "    \"description\": \"Toxins directly induce stress within liver cells due to their chemical properties.\",\n",
      "    \"confidence\": 0.85\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"liver_cellular_stress\",\n",
      "    \"relat...\n",
      "[17:54:54] Generated 3 relations (novel_entities=3)\n",
      "[17:55:03] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"toxin_ingestion\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"liver_toxin_concentration\",\n",
      "    \"description\": \"Ingestion of toxins directly leads to a higher concentration of those toxins within the liver.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"liver_toxin_concentration\",\n",
      "    \"relation\": \"causes\",\n",
      "    \"tail\": \"liver_cellular_stress\",\n",
      "    \"description\": \"A high concentration of toxins within liver cells directly stresses those cells.\",\n",
      "    \"confidence\": 0.88\n",
      "  },\n",
      "  {\n",
      "    \"...\n",
      "[17:55:11] Fallback LLM Response:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"head\": \"Liver\",\n",
      "    \"relation\": \"experiences\",\n",
      "    \"tail\": \"Cellular Inflammation\",\n",
      "    \"description\": \"The liver experiences cellular inflammation as a result of toxin exposure.\",\n",
      "    \"confidence\": 0.8\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"Toxins\",\n",
      "    \"relation\": \"activate\",\n",
      "    \"tail\": \"Metabolic Stress Pathways\",\n",
      "    \"description\": \"Toxins ingested by the caterpillar activate metabolic stress pathways within the liver.\",\n",
      "    \"confidence\": 0.75\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"Cellular Inflammation\",...\n",
      "[17:55:11] Generated 3 relations (novel_entities=0)\n",
      "[17:55:20] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"liver_toxin_concentration\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"liver_cellular_stress\",\n",
      "    \"description\": \"Higher concentrations of toxins within liver cells directly lead to increased cellular stress.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"liver_cellular_stress\",\n",
      "    \"relation\": \"triggers\",\n",
      "    \"tail\": \"increased_reactive_oxygen_species\",\n",
      "    \"description\": \"Cellular stress in the liver directly activates pathways that increase the production of reactive oxygen...\n",
      "[17:55:20] Generated 2 relations (novel_entities=2)\n",
      "[17:55:29] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"toxin_ingestion\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"liver_toxin_concentration\",\n",
      "    \"description\": \"Ingesting toxins directly adds them to the liver, increasing their concentration.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"liver_toxin_concentration\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"increased_liver_cellular_stress\",\n",
      "    \"description\": \"Higher toxin levels in the liver directly strain its cells, causing increased stress.\",\n",
      "    \"confidence\": 0.88\n",
      "  },\n",
      "  {\n",
      "...\n",
      "[17:55:29] Generated 3 relations (novel_entities=2)\n",
      "[17:55:39] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"toxin_ingestion\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"liver_toxin_concentration\",\n",
      "    \"description\": \"Ingesting toxins directly leads to a higher concentration of those toxins within the liver.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"toxin_ingestion\",\n",
      "    \"relation\": \"causes\",\n",
      "    \"tail\": \"toxin_absorption\",\n",
      "    \"description\": \"The act of ingesting toxins initiates their absorption into the body, primarily through the digestive system.\",\n",
      "    \"confidence\": 0.88\n",
      "  }...\n",
      "[17:55:39] Generated 3 relations (novel_entities=2)\n",
      "[17:55:48] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"liver_toxin_concentration\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"liver_detoxification_rate\",\n",
      "    \"description\": \"A higher concentration of toxins in the liver directly triggers an increase in the rate at which the liver detoxifies.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"liver_detoxification_rate\",\n",
      "    \"relation\": \"decreases\",\n",
      "    \"tail\": \"liver_toxin_concentration\",\n",
      "    \"description\": \"As the liver works to detoxify, it directly reduces the concentration of toxins...\n",
      "[17:55:48] Generated 2 relations (novel_entities=2)\n",
      "[17:55:57] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"leaves\",\n",
      "    \"relation\": \"contains\",\n",
      "    \"tail\": \"toxin_concentration_in_leaves\",\n",
      "    \"description\": \"Leaves can naturally contain varying levels of toxins.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"toxin_concentration_in_leaves\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"toxin_ingestion\",\n",
      "    \"description\": \"Higher toxin concentration in leaves directly leads to increased ingestion of toxins when consumed.\",\n",
      "    \"confidence\": 0.88\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"toxin_ingestion\",\n",
      "...\n",
      "[17:55:57] Generated 3 relations (novel_entities=3)\n",
      "[17:56:11] LLM Response:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"head\": \"increased_liver_cellular_stress\",\n",
      "    \"relation\": \"causes\",\n",
      "    \"tail\": \"potential_liver_damage\",\n",
      "    \"description\": \"Prolonged or excessive cellular stress in the liver can lead to damage and dysfunction.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"potential_liver_damage\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"toxin_metabolite_concentration\",\n",
      "    \"description\": \"Damaged liver cells may be less efficient at metabolizing and eliminating toxins, leading to a build...\n",
      "[17:56:11] Generated 5 relations (novel_entities=3)\n",
      "[17:56:21] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"leaves_containing_toxins\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"toxin_concentration_in_leaves\",\n",
      "    \"description\": \"Leaves containing toxins have a higher concentration of toxins within their structure.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"toxin_concentration_in_leaves\",\n",
      "    \"relation\": \"causes\",\n",
      "    \"tail\": \"ToxinIngestionRate_Intermediate\",\n",
      "    \"description\": \"Higher toxin concentration in leaves directly leads to a higher rate of toxin ingestion when those le...\n",
      "[17:56:21] Generated 5 relations (novel_entities=4)\n",
      "[17:56:25] Backfilled 3 missing relations among known entities\n",
      "[17:56:25] \n",
      "============================================================\n",
      "[17:56:25] FINAL STATISTICS\n",
      "[17:56:25] ============================================================\n",
      "[17:56:25] Total entities: 22 (seeds=4, expanded=18)\n",
      "[17:56:25] Total edges: 39\n",
      "[17:56:25] Causal chains: 10\n",
      "[17:56:25] \n",
      "Relation types:\n",
      "[17:56:25]   - increases: 13\n",
      "[17:56:25]   - causes: 13\n",
      "[17:56:25]   - decreases: 4\n",
      "[17:56:25]   - triggers: 2\n",
      "[17:56:25]   - eats: 1\n",
      "[17:56:25]   - contain: 1\n",
      "[17:56:25]   - metabolize_slowly: 1\n",
      "[17:56:25]   - accumulates: 1\n",
      "[17:56:25]   - inhibits: 1\n",
      "[17:56:25]   - ingests: 1\n",
      "[17:56:25]   - contains: 1\n",
      "\n",
      "  Observable Outcome: the concentration of toxins in the liver\n",
      "  Reasoning: The question asks about the effect on 'more toxins are in the liver'. This implies a change in the amount or concentration of toxins within the liver ...\n",
      "  Seeds found: 4\n",
      "  Total edges: 39\n",
      "\n",
      "[Step 3] Formatting causal chains...\n",
      "  Causal Chains:\n",
      "      (No causal chains found)\n",
      "\n",
      "[Step 4] Evaluating each choice...\n",
      "\n",
      "  --- Evaluating: MORE ---\n",
      "    Forward reasoning...\n",
      "      Confidence: 0.00\n",
      "      Path Strength: none\n",
      "    Counterfactual reasoning...\n",
      "      Test Result: fail\n",
      "      Confidence Adjustment: -0.20\n",
      "\n",
      "  --- Evaluating: LESS ---\n",
      "    Forward reasoning...\n",
      "      Confidence: 0.00\n",
      "      Path Strength: none\n",
      "    Counterfactual reasoning...\n",
      "      Test Result: unclear\n",
      "      Confidence Adjustment: -0.15\n",
      "\n",
      "  --- Evaluating: NO_EFFECT ---\n",
      "    Forward reasoning...\n",
      "      Confidence: 1.00\n",
      "      Path Strength: none\n",
      "    Counterfactual reasoning...\n",
      "      Test Result: error\n",
      "      Confidence Adjustment: +0.00\n",
      "\n",
      "[Step 5] Making final decision...\n",
      "\n",
      "  Final Answer: NO_EFFECT\n",
      "  Gold Answer: NO_EFFECT\n",
      "  Result: ✓ CORRECT\n",
      "  Confidence: 1.00\n",
      "\n",
      "============================================================\n",
      "Processing Sample 5/5\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Question: suppose The plant is given a new contract for recycling items for another city happens, how will it affect LESS recyling.\n",
      "============================================================\n",
      "\n",
      "[Step 1] Parsing question structure...\n",
      "  Intervention: The plant is given a new contract for recycling items for another city happens\n",
      "  Target: recyling\n",
      "\n",
      "[Step 2] Building causal chain with observable outcome identification...\n",
      "[17:56:48] \n",
      "============================================================\n",
      "[17:56:48] STEP 0: Identify Observable Outcome\n",
      "[17:56:48] ============================================================\n",
      "[17:56:50] \n",
      "LLM Response:\n",
      "```json\n",
      "{\n",
      "  \"observable_outcome\": \"The amount of recycling processed by the plant\",\n",
      "  \"reasoning\": \"The question focuses on how a new recycling contract will affect 'recycling'. The most direct and measurable outcome related to this is the volume of recyclable materials processed by the plant.\" \n",
      "}\n",
      "```\n",
      "[17:56:50] \n",
      "✅ Observable Outcome: The amount of recycling processed by the plant\n",
      "[17:56:50]    Reasoning: The question focuses on how a new recycling contract will affect 'recycling'. The most direct and measurable outcome related to this is the volume of recyclable materials processed by the plant....\n",
      "[17:56:50] \n",
      "============================================================\n",
      "[17:56:50] STEP 1: Extract Seed Entities\n",
      "[17:56:50] ============================================================\n",
      "[17:56:51] \n",
      "LLM Response:\n",
      "plant\n",
      "contract\n",
      "items\n",
      "city\n",
      "recycling\n",
      "[17:56:59] LLM Response:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"head\": \"plant\",\n",
      "    \"relation\": \"processes\",\n",
      "    \"tail\": \"recyclable_materials\",\n",
      "    \"description\": \"Recycling plants directly process various recyclable materials.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"recyclable_materials\",\n",
      "    \"relation\": \"has_quantity\",\n",
      "    \"tail\": \"material_volume\",\n",
      "    \"description\": \"Recyclable materials have a quantifiable volume.\",\n",
      "    \"confidence\": 0.98\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"material_volume\",\n",
      "    \"relation\": \"influences\",\n",
      "    \"tail\": \"proces...\n",
      "[17:56:59] Generated 2 relations (novel_entities=2)\n",
      "[17:57:07] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"recyclable_materials\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"recycling\",\n",
      "    \"description\": \"The availability of recyclable materials directly increases the amount of recycling that can be processed.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"sorting_technology\",\n",
      "    \"relation\": \"enables\",\n",
      "    \"tail\": \"efficient_separation\",\n",
      "    \"description\": \"Sorting technology enables the efficient separation of different types of recyclable materials.\",\n",
      "    \"confidence\": 0.88\n",
      "  },\n",
      "...\n",
      "[17:57:07] Generated 3 relations (novel_entities=2)\n",
      "[17:57:16] LLM Response:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"head\": \"items\",\n",
      "    \"relation\": \"contain\",\n",
      "    \"tail\": \"recyclable_materials\",\n",
      "    \"description\": \"Items may contain materials suitable for recycling.\",\n",
      "    \"confidence\": 0.92\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"recyclable_materials\",\n",
      "    \"relation\": \"require\",\n",
      "    \"tail\": \"sorting_technology\",\n",
      "    \"description\": \"Recyclable materials need to be separated from non-recyclables using sorting technology.\",\n",
      "    \"confidence\": 0.85\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"sorting_technology\",\n",
      "    \"relation\": \"produ...\n",
      "[17:57:16] Generated 4 relations (novel_entities=2)\n",
      "[17:57:25] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"contract\",\n",
      "    \"relation\": \"enables\",\n",
      "    \"tail\": \"sorting_technology_purchase\",\n",
      "    \"description\": \"A contract for a specific sorting technology directly enables the acquisition and installation of that technology.\",\n",
      "    \"confidence\": 0.92\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"sorting_technology_purchase\",\n",
      "    \"relation\": \"generates\",\n",
      "    \"tail\": \"sorting_efficiency\",\n",
      "    \"description\": \"The purchase and implementation of sorting technologies directly leads to improved efficiency in separati...\n",
      "[17:57:25] Generated 2 relations (novel_entities=2)\n",
      "[17:57:33] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"city\",\n",
      "    \"relation\": \"sets\",\n",
      "    \"tail\": \"recycling_targets\",\n",
      "    \"description\": \"Cities establish specific goals for the amount of waste to be recycled.\",\n",
      "    \"confidence\": 0.92\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"recycling_targets\",\n",
      "    \"relation\": \"influences\",\n",
      "    \"tail\": \"sorting_technology_purchase\",\n",
      "    \"description\": \"Ambitious recycling targets incentivize cities to invest in better sorting technology.\",\n",
      "    \"confidence\": 0.85\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"sorting_technology_purchase\",\n",
      " ...\n",
      "[17:57:33] Generated 5 relations (novel_entities=1)\n",
      "[17:57:43] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"landfill_waste\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"unsorted_waste_volume\",\n",
      "    \"description\": \"Landfill waste directly contributes to the volume of waste that is not yet sorted for recycling.\",\n",
      "    \"confidence\": 0.92\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"unsorted_waste_volume\",\n",
      "    \"relation\": \"reduces\",\n",
      "    \"tail\": \"recyclable_material_availability\",\n",
      "    \"description\": \"A higher volume of unsorted waste means a smaller proportion of recyclable materials are easily accessible for proc...\n",
      "[17:57:43] Generated 3 relations (novel_entities=3)\n",
      "[17:57:52] LLM Response:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"head\": \"sorting_technology\",\n",
      "    \"relation\": \"enables\",\n",
      "    \"tail\": \"efficient_separation\",\n",
      "    \"description\": \"Sorting technology directly enables the efficient separation of recyclable materials from non-recyclable ones.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"efficient_separation\",\n",
      "    \"relation\": \"produces\",\n",
      "    \"tail\": \"separated_streams\",\n",
      "    \"description\": \"Efficient separation directly produces distinct streams of recyclable and non-recyclable materials.\",\n",
      "    \"...\n",
      "[17:57:52] Generated 2 relations (novel_entities=1)\n",
      "[17:58:01] LLM Response:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"head\": \"recycling_plant\",\n",
      "    \"relation\": \"processes\",\n",
      "    \"tail\": \"unsorted_waste_volume\",\n",
      "    \"description\": \"A recycling plant directly receives and processes unsorted waste.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"unsorted_waste_volume\",\n",
      "    \"relation\": \"determines\",\n",
      "    \"tail\": \"feedstock_composition\",\n",
      "    \"description\": \"The volume of unsorted waste directly determines the composition of materials fed into the recycling process.\",\n",
      "    \"confidence\": 0.88\n",
      "  },\n",
      "\n",
      "{\n",
      "  ...\n",
      "[17:58:01] Generated 3 relations (novel_entities=1)\n",
      "[17:58:11] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"recyclable_materials\",\n",
      "    \"relation\": \"determines\",\n",
      "    \"tail\": \"feedstock_composition\",\n",
      "    \"description\": \"The type and amount of recyclable materials directly determine the composition of the feedstock entering the recycling plant.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"feedstock_composition\",\n",
      "    \"relation\": \"influences\",\n",
      "    \"tail\": \"sorting_efficiency\",\n",
      "    \"description\": \"The mix of materials in the feedstock directly affects how efficiently they can be separat...\n",
      "[17:58:11] Generated 4 relations (novel_entities=2)\n",
      "[17:58:20] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"separated_streams\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"separated_streams_purity\",\n",
      "    \"description\": \"Higher quality separation directly leads to a greater proportion of pure recyclable materials in the separated streams.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"separated_streams_purity\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"potential_recycling_efficiency\",\n",
      "    \"description\": \"The purer the separated streams, the higher the potential efficiency of the recycli...\n",
      "[17:58:20] Generated 4 relations (novel_entities=2)\n",
      "[17:58:29] LLM Response:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"head\": \"efficient_separation\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"separated_streams_purity\",\n",
      "    \"description\": \"Efficient separation processes directly lead to higher purity of the separated material streams.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"separated_streams_purity\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"recyclable_material_stream_quality\",\n",
      "    \"description\": \"Higher purity of separated streams directly translates to improved quality of the recyclabl...\n",
      "[17:58:29] Generated 5 relations (novel_entities=3)\n",
      "[17:58:39] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"sorting_technology_purchase\",\n",
      "    \"relation\": \"triggers\",\n",
      "    \"tail\": \"new_sorting_technology_installation\",\n",
      "    \"description\": \"Purchasing sorting technology directly leads to the installation and implementation of that technology at a recycling plant.\",\n",
      "    \"confidence\": 0.95\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"new_sorting_technology_installation\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"sorting_efficiency\",\n",
      "    \"description\": \"Installing newer, more advanced sorting technology directly...\n",
      "[17:58:39] Generated 4 relations (novel_entities=3)\n",
      "[17:58:49] LLM Response:\n",
      "[\n",
      "  {\n",
      "    \"head\": \"recycling_targets\",\n",
      "    \"relation\": \"increases\",\n",
      "    \"tail\": \"target_feedstock_composition\",\n",
      "    \"description\": \"Higher recycling targets incentivize a larger proportion of recyclable materials in the incoming waste stream.\",\n",
      "    \"confidence\": 0.85\n",
      "  },\n",
      "  {\n",
      "    \"head\": \"target_feedstock_composition\",\n",
      "    \"relation\": \"causes\",\n",
      "    \"tail\": \"increased_recyclable_material_stream\",\n",
      "    \"description\": \"A feedstock with a higher proportion of recyclable materials directly leads to a ...\n",
      "[17:58:49] Generated 2 relations (novel_entities=1)\n",
      "[17:58:56] Backfilled 5 missing relations among known entities\n",
      "[17:58:56] \n",
      "============================================================\n",
      "[17:58:56] FINAL STATISTICS\n",
      "[17:58:56] ============================================================\n",
      "[17:58:56] Total entities: 27 (seeds=5, expanded=22)\n",
      "[17:58:56] Total edges: 48\n",
      "[17:58:56] Causal chains: 10\n",
      "[17:58:56] \n",
      "Relation types:\n",
      "[17:58:56]   - increases: 18\n",
      "[17:58:56]   - decreases: 4\n",
      "[17:58:56]   - enables: 3\n",
      "[17:58:56]   - influences: 3\n",
      "[17:58:56]   - processes: 2\n",
      "[17:58:56]   - utilizes: 2\n",
      "[17:58:56]   - reduces: 2\n",
      "[17:58:56]   - produces: 2\n",
      "[17:58:56]   - determines: 2\n",
      "[17:58:56]   - feed: 1\n",
      "[17:58:56]   - contain: 1\n",
      "[17:58:56]   - require: 1\n",
      "[17:58:56]   - specifies: 1\n",
      "[17:58:56]   - feeds_into: 1\n",
      "[17:58:56]   - sets: 1\n",
      "[17:58:56]   - results_in: 1\n",
      "[17:58:56]   - contains: 1\n",
      "[17:58:56]   - limits: 1\n",
      "[17:58:56]   - triggers: 1\n",
      "\n",
      "  Observable Outcome: The amount of recycling processed by the plant\n",
      "  Reasoning: The question focuses on how a new recycling contract will affect 'recycling'. The most direct and measurable outcome related to this is the volume of ...\n",
      "  Seeds found: 5\n",
      "  Total edges: 48\n",
      "\n",
      "[Step 3] Formatting causal chains...\n",
      "  Causal Chains:\n",
      "      (No causal chains found)\n",
      "\n",
      "[Step 4] Evaluating each choice...\n",
      "\n",
      "  --- Evaluating: MORE ---\n",
      "    Forward reasoning...\n",
      "      Confidence: 0.00\n",
      "      Path Strength: none\n",
      "    Counterfactual reasoning...\n",
      "      Test Result: pass\n",
      "      Confidence Adjustment: +0.20\n",
      "\n",
      "  --- Evaluating: LESS ---\n",
      "    Forward reasoning...\n",
      "      Confidence: 0.20\n",
      "      Path Strength: none\n",
      "    Counterfactual reasoning...\n",
      "      Test Result: pass\n",
      "      Confidence Adjustment: +0.20\n",
      "\n",
      "  --- Evaluating: NO_EFFECT ---\n",
      "    Forward reasoning...\n",
      "      Confidence: 1.00\n",
      "      Path Strength: none\n",
      "    Counterfactual reasoning...\n",
      "      Test Result: pass\n",
      "      Confidence Adjustment: +0.10\n",
      "\n",
      "[Step 5] Making final decision...\n",
      "\n",
      "  Final Answer: NO_EFFECT\n",
      "  Gold Answer: LESS\n",
      "  Result: ✗ WRONG\n",
      "  Confidence: 1.00\n",
      "\n",
      "============================================================\n",
      "All samples processed!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def predict_with_choice_reasoning_v2(\n",
    "    question: str,\n",
    "    gold_answer: str,\n",
    "    parser,\n",
    "    builder,\n",
    "    model: str,\n",
    "    confidence_threshold: float = 0.3,\n",
    "    print_details: bool = True\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    使用新的V2架构进行推理：observable outcome在seed extraction之前识别\n",
    "    \n",
    "    Args:\n",
    "        question: 输入问题\n",
    "        gold_answer: 正确答案\n",
    "        parser: 问题解析器\n",
    "        builder: 因果链构建器\n",
    "        model: LLM模型\n",
    "        confidence_threshold: 置信度阈值\n",
    "        print_details: 是否打印详细信息\n",
    "    \n",
    "    Returns:\n",
    "        推理结果\n",
    "    \"\"\"\n",
    "    if print_details:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Question:\", question)\n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    # Step 1: 解析问题结构\n",
    "    if print_details:\n",
    "        print(\"\\n[Step 1] Parsing question structure...\")\n",
    "    \n",
    "    question_structure = parser.parse_question_structure(question)\n",
    "    intervention = question_structure.get('intervention')\n",
    "    target_entity = question_structure.get('target_entity')\n",
    "    \n",
    "    if print_details:\n",
    "        print(f\"  Intervention: {intervention}\")\n",
    "        print(f\"  Target: {target_entity}\")\n",
    "    \n",
    "    # Step 2: 构建因果链（会自动识别observable outcome）\n",
    "    if print_details:\n",
    "        print(\"\\n[Step 2] Building causal chain with observable outcome identification...\")\n",
    "    \n",
    "    builder_result = builder.build_causal_chain(\n",
    "        question=question,\n",
    "        intervention=intervention,\n",
    "        target=target_entity\n",
    "    )\n",
    "    \n",
    "    # 获取observable outcome信息\n",
    "    observable_info = builder_result.get('observable_outcome', {})\n",
    "    observable_outcome = observable_info.get('observable_outcome', target_entity or 'unclear')\n",
    "    \n",
    "    if print_details:\n",
    "        print(f\"\\n  Observable Outcome: {observable_outcome}\")\n",
    "        print(f\"  Reasoning: {observable_info.get('reasoning', '')[:150]}...\")\n",
    "        print(f\"  Seeds found: {len(builder_result.get('seeds', []))}\")\n",
    "        print(f\"  Total edges: {len(builder_result.get('edges', []))}\")\n",
    "    \n",
    "    # Step 3: 获取格式化的因果链\n",
    "    if print_details:\n",
    "        print(\"\\n[Step 3] Formatting causal chains...\")\n",
    "    \n",
    "    causal_chains_text = builder.get_formatted_causal_chains(\n",
    "        result=builder_result,\n",
    "        intervention=intervention,\n",
    "        target=target_entity,\n",
    "        min_confidence=confidence_threshold,\n",
    "        max_paths=10\n",
    "    )\n",
    "    \n",
    "    if print_details:\n",
    "        print(\"  Causal Chains:\")\n",
    "        for line in causal_chains_text.split('\\n')[:5]:  # 只显示前5条\n",
    "            print(f\"    {line}\")\n",
    "        if len(causal_chains_text.split('\\n')) > 5:\n",
    "            print(f\"    ... and more\")\n",
    "    \n",
    "    # 统计高置信度关系\n",
    "    high_conf_relations = sum(\n",
    "        1 for edge in builder_result.get('edges', [])\n",
    "        if edge.get('confidence', 0) >= confidence_threshold\n",
    "    )\n",
    "    \n",
    "    # Step 4: 对每个choice进行评估\n",
    "    if print_details:\n",
    "        print(\"\\n[Step 4] Evaluating each choice...\")\n",
    "    \n",
    "    choice_evaluations = []\n",
    "    \n",
    "    for choice in ['more', 'less', 'no_effect']:\n",
    "        if print_details:\n",
    "            print(f\"\\n  --- Evaluating: {choice.upper()} ---\")\n",
    "        \n",
    "        # 4.1 正向推理（独立LLM调用）\n",
    "        if print_details:\n",
    "            print(f\"    Forward reasoning...\")\n",
    "        \n",
    "        forward_result = forward_reasoning(\n",
    "            question=question,\n",
    "            choice=choice,\n",
    "            observable_outcome=observable_outcome,\n",
    "            causal_chains_text=causal_chains_text,\n",
    "            question_structure=question_structure,\n",
    "            model=model\n",
    "        )\n",
    "        \n",
    "        if print_details:\n",
    "            print(f\"      Confidence: {forward_result['confidence']:.2f}\")\n",
    "            print(f\"      Path Strength: {forward_result['path_strength']}\")\n",
    "        \n",
    "        # 4.2 反事实推理（独立LLM调用）\n",
    "        if print_details:\n",
    "            print(f\"    Counterfactual reasoning...\")\n",
    "        \n",
    "        counterfactual_result = counterfactual_reasoning(\n",
    "            question=question,\n",
    "            choice=choice,\n",
    "            observable_outcome=observable_outcome,\n",
    "            causal_chains_text=causal_chains_text,\n",
    "            question_structure=question_structure,\n",
    "            model=model\n",
    "        )\n",
    "        \n",
    "        if print_details:\n",
    "            print(f\"      Test Result: {counterfactual_result['test_result']}\")\n",
    "            print(f\"      Confidence Adjustment: {counterfactual_result.get('confidence_adjustment', 0):+.2f}\")\n",
    "        \n",
    "        choice_evaluations.append({\n",
    "            'choice': choice,\n",
    "            'forward_reasoning': forward_result,\n",
    "            'counterfactual_reasoning': counterfactual_result\n",
    "        })\n",
    "    \n",
    "    # Step 5: 最终决策\n",
    "    if print_details:\n",
    "        print(\"\\n[Step 5] Making final decision...\")\n",
    "    \n",
    "    final_decision = make_final_decision(\n",
    "        question=question,\n",
    "        observable_outcome=observable_outcome,\n",
    "        choice_evaluations=choice_evaluations,\n",
    "        model=model\n",
    "    )\n",
    "    \n",
    "    prediction = final_decision['final_answer']\n",
    "    correct = (prediction == gold_answer)\n",
    "    \n",
    "    if print_details:\n",
    "        print(f\"\\n  Final Answer: {prediction.upper()}\")\n",
    "        print(f\"  Gold Answer: {gold_answer.upper()}\")\n",
    "        print(f\"  Result: {'✓ CORRECT' if correct else '✗ WRONG'}\")\n",
    "        print(f\"  Confidence: {final_decision['confidence']:.2f}\")\n",
    "    \n",
    "    return {\n",
    "        'question': question,\n",
    "        'gold': gold_answer,\n",
    "        'prediction': prediction,\n",
    "        'correct': correct,\n",
    "        'confidence': final_decision['confidence'],\n",
    "        'decision_basis': final_decision.get('decision_basis', 'unknown'),\n",
    "        'high_conf_relations': high_conf_relations,\n",
    "        'observable_outcome': observable_outcome,\n",
    "        'result': {\n",
    "            'observable_info': observable_info,\n",
    "            'choice_evaluations': choice_evaluations,\n",
    "            'final_decision': final_decision,\n",
    "            'builder_stats': {\n",
    "                'num_seeds': len(builder_result.get('seeds', [])),\n",
    "                'num_entities': len(builder_result.get('entities', [])),\n",
    "                'num_edges': len(builder_result.get('edges', [])),\n",
    "                'num_chains': len(builder_result.get('chains', []))\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "print('✓ Main prediction function (V2) defined')\n",
    "\n",
    "# 运行主推理循环\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Running Choice Reasoning with Observable Outcome Integration\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, sample in enumerate(SAMPLES, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing Sample {i}/{len(SAMPLES)}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        result = predict_with_choice_reasoning_v2(\n",
    "            question=sample['question'],\n",
    "            gold_answer=sample['gold'],\n",
    "            parser=PARSER,\n",
    "            builder=BUILDER,\n",
    "            model=MODEL,\n",
    "            confidence_threshold=CONFIDENCE_THRESHOLD,\n",
    "            print_details=PRINT_DETAILS\n",
    "        )\n",
    "        results.append(result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n⚠️ Error processing sample {i}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        # 添加错误结果\n",
    "        results.append({\n",
    "            'question': sample['question'],\n",
    "            'gold': sample['gold'],\n",
    "            'prediction': 'no_effect',  # 默认答案\n",
    "            'correct': False,\n",
    "            'confidence': 0.0,\n",
    "            'decision_basis': 'error',\n",
    "            'high_conf_relations': 0,\n",
    "            'observable_outcome': 'error',\n",
    "            'result': {'error': str(e)}\n",
    "        })\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"All samples processed!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结果汇总"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Overall Results\n",
      "============================================================\n",
      "Total Samples: 5\n",
      "Correct: 3\n",
      "Accuracy: 60.00%\n",
      "\n",
      "By Label:\n",
      "  more: 1/1 = 100.00%\n",
      "  less: 0/1 = 0.00%\n",
      "  no_effect: 2/3 = 66.67%\n",
      "\n",
      "By Decision Basis:\n",
      "  counterfactual_test: 2/3 = 66.67%\n",
      "  highest_confidence: 1/2 = 50.00%\n",
      "\n",
      "Confidence Analysis:\n",
      "  Average Confidence: 0.95\n",
      "  Correct Predictions: 0.96\n",
      "  Wrong Predictions: 0.95\n",
      "\n",
      "Average High-Confidence Relations: 43.2\n",
      "\n",
      "Observable Outcomes:\n",
      "  increased rate of shoreline erosion: 1/1 = 100.00%\n",
      "  Number of babies born: 1/1 = 100.00%\n",
      "  Eating fewer vegetables: 0/1 = 0.00%\n",
      "  the concentration of toxins in the liver: 1/1 = 100.00%\n",
      "  The amount of recycling processed by the plant: 0/1 = 0.00%\n"
     ]
    }
   ],
   "source": [
    "# 计算准确率\n",
    "total = len(results)\n",
    "correct = sum(1 for r in results if r['correct'])\n",
    "accuracy = correct / total if total > 0 else 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Overall Results\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total Samples: {total}\")\n",
    "print(f\"Correct: {correct}\")\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# 按标签统计\n",
    "print(\"\\nBy Label:\")\n",
    "for label in ['more', 'less', 'no_effect']:\n",
    "    label_results = [r for r in results if r['gold'] == label]\n",
    "    if label_results:\n",
    "        label_correct = sum(1 for r in label_results if r['correct'])\n",
    "        label_acc = label_correct / len(label_results)\n",
    "        print(f\"  {label}: {label_correct}/{len(label_results)} = {label_acc:.2%}\")\n",
    "\n",
    "# 按决策依据统计\n",
    "print(\"\\nBy Decision Basis:\")\n",
    "basis_counts = {}\n",
    "for r in results:\n",
    "    basis = r.get('decision_basis', 'unknown')\n",
    "    if basis not in basis_counts:\n",
    "        basis_counts[basis] = {'total': 0, 'correct': 0}\n",
    "    basis_counts[basis]['total'] += 1\n",
    "    if r['correct']:\n",
    "        basis_counts[basis]['correct'] += 1\n",
    "\n",
    "for basis, counts in basis_counts.items():\n",
    "    acc = counts['correct'] / counts['total'] if counts['total'] > 0 else 0\n",
    "    print(f\"  {basis}: {counts['correct']}/{counts['total']} = {acc:.2%}\")\n",
    "\n",
    "# 平均置信度\n",
    "avg_confidence = sum(r['confidence'] for r in results) / total if total > 0 else 0\n",
    "avg_confidence_correct = sum(r['confidence'] for r in results if r['correct']) / correct if correct > 0 else 0\n",
    "avg_confidence_wrong = sum(r['confidence'] for r in results if not r['correct']) / (total - correct) if (total - correct) > 0 else 0\n",
    "\n",
    "print(\"\\nConfidence Analysis:\")\n",
    "print(f\"  Average Confidence: {avg_confidence:.2f}\")\n",
    "print(f\"  Correct Predictions: {avg_confidence_correct:.2f}\")\n",
    "print(f\"  Wrong Predictions: {avg_confidence_wrong:.2f}\")\n",
    "\n",
    "# 高置信度关系统计\n",
    "avg_high_conf_rels = sum(r.get('high_conf_relations', 0) for r in results) / total if total > 0 else 0\n",
    "print(f\"\\nAverage High-Confidence Relations: {avg_high_conf_rels:.1f}\")\n",
    "\n",
    "# Observable Outcome统计\n",
    "print(\"\\nObservable Outcomes:\")\n",
    "outcomes = {}\n",
    "for r in results:\n",
    "    outcome = r.get('observable_outcome', 'unclear')\n",
    "    if outcome not in outcomes:\n",
    "        outcomes[outcome] = {'total': 0, 'correct': 0}\n",
    "    outcomes[outcome]['total'] += 1\n",
    "    if r['correct']:\n",
    "        outcomes[outcome]['correct'] += 1\n",
    "\n",
    "for outcome, counts in sorted(outcomes.items(), key=lambda x: x[1]['total'], reverse=True)[:10]:\n",
    "    acc = counts['correct'] / counts['total'] if counts['total'] > 0 else 0\n",
    "    print(f\"  {outcome[:50]}: {counts['correct']}/{counts['total']} = {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 详细结果查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "详细结果表格:\n",
      "                                                   问题      正确答案        预测 正确  置信度\n",
      "suppose getting a storm over the coast from the oc...      more      more  ✓ 0.87\n",
      "suppose use less batter per pancake happens, how w... no_effect no_effect  ✓ 1.00\n",
      "suppose Having a stomach bug happens, how will it ... no_effect      less  ✗ 0.90\n",
      "suppose more caterpillar eats happens, how will it... no_effect no_effect  ✓ 1.00\n",
      "suppose The plant is given a new contract for recy...      less no_effect  ✗ 1.00\n"
     ]
    }
   ],
   "source": [
    "# 创建结果DataFrame\n",
    "df_results = pd.DataFrame([{\n",
    "    '问题': r['question'][:50] + '...' if len(r['question']) > 50 else r['question'],\n",
    "    '正确答案': r['gold'],\n",
    "    '预测': r['prediction'],\n",
    "    '正确': '✓' if r['correct'] else '✗',\n",
    "    '置信度': f\"{r['confidence']:.2f}\"\n",
    "} for r in results])\n",
    "\n",
    "print(\"\\n详细结果表格:\")\n",
    "print(df_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看单个样本的完整推理过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Sample 1 - Complete Reasoning Process\n",
      "============================================================\n",
      "\n",
      "Question: suppose getting a storm over the coast from the ocean happens, how will it affect MORE erosion by the ocean.\n",
      "Gold Answer: more\n",
      "Prediction: more\n",
      "Result: ✓ Correct\n",
      "\n",
      "============================================================\n",
      "OBSERVABLE OUTCOME\n",
      "============================================================\n",
      "Identified: increased rate of shoreline erosion\n",
      "Reasoning: Storms are a known factor contributing to coastal erosion. The question implies a causal relationship between the storm and a measurable increase in the physical process of erosion along the coastline.\n",
      "\n",
      "============================================================\n",
      "CAUSAL GRAPH STATISTICS\n",
      "============================================================\n",
      "Seeds: 5\n",
      "Entities: 27\n",
      "Edges: 53\n",
      "Chains: 10\n",
      "High-Confidence Relations (≥0.3): 53\n",
      "\n",
      "------------------------------------------------------------\n",
      "CHOICE EVALUATIONS\n",
      "------------------------------------------------------------\n",
      "\n",
      "========================================\n",
      "CHOICE: MORE\n",
      "========================================\n",
      "\n",
      "  [Forward Reasoning]\n",
      "    Confidence: 0.00\n",
      "    Path Strength: none\n",
      "    Causal Path: \n",
      "    Rationale: There are no available causal chains provided to connect a storm over the coast to an increase in shoreline erosion. Without any causal evidence, we cannot support the claim that 'more' erosion would ...\n",
      "\n",
      "  [Counterfactual Reasoning]\n",
      "    Test Result: error\n",
      "    Confidence Adjustment: +0.00\n",
      "    Final Confidence: 0.00\n",
      "    Scenario: ...\n",
      "    Rationale: Error: Expecting value: line 5 column 28 (char 255)...\n",
      "\n",
      "========================================\n",
      "CHOICE: LESS\n",
      "========================================\n",
      "\n",
      "  [Forward Reasoning]\n",
      "    Confidence: 0.00\n",
      "    Path Strength: none\n",
      "    Causal Path: None found\n",
      "    Rationale: No causal chains were provided to connect a storm over the coast with erosion rates. Without any evidence of a causal relationship, we cannot confidently conclude that a storm would lead to LESS erosi...\n",
      "\n",
      "  [Counterfactual Reasoning]\n",
      "    Test Result: error\n",
      "    Confidence Adjustment: +0.00\n",
      "    Final Confidence: 0.00\n",
      "    Scenario: ...\n",
      "    Rationale: Error: Expecting value: line 5 column 28 (char 246)...\n",
      "\n",
      "========================================\n",
      "CHOICE: NO_EFFECT\n",
      "========================================\n",
      "\n",
      "  [Forward Reasoning]\n",
      "    Confidence: 1.00\n",
      "    Path Strength: none\n",
      "    Causal Path: None\n",
      "    Rationale: No causal chains connecting the intervention (getting a storm over the coast) and the observable outcome (increased rate of shoreline erosion) were provided. Without any plausible causal pathways, we ...\n",
      "\n",
      "  [Counterfactual Reasoning]\n",
      "    Test Result: fail\n",
      "    Confidence Adjustment: -0.20\n",
      "    Final Confidence: 0.80\n",
      "    Scenario: No storm occurs over the coast....\n",
      "    Rationale: Storms exacerbate erosion due to increased wave action and higher water levels. While erosion is a natural coastal process, storms significantly accelerate it. Removing the storm intervention would st...\n",
      "\n",
      "============================================================\n",
      "FINAL DECISION\n",
      "============================================================\n",
      "\n",
      "Answer: MORE\n",
      "Confidence: 0.87\n",
      "Decision Basis: counterfactual_test\n",
      "\n",
      "Reasoning:\n",
      "While no explicit causal chains were provided, the counterfactual test for 'MORE' erosion failed due to the established understanding that storms significantly accelerate erosion through increased wave action and higher water levels. Forward reasoning lacks sufficient evidence, but the counterfactual failure strongly suggests a causal link.\n"
     ]
    }
   ],
   "source": [
    "# 选择要查看的样本索引（0-based）\n",
    "SAMPLE_INDEX = 0\n",
    "\n",
    "if SAMPLE_INDEX < len(results):\n",
    "    sample_result = results[SAMPLE_INDEX]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Sample {SAMPLE_INDEX + 1} - Complete Reasoning Process\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nQuestion: {sample_result['question']}\")\n",
    "    print(f\"Gold Answer: {sample_result['gold']}\")\n",
    "    print(f\"Prediction: {sample_result['prediction']}\")\n",
    "    print(f\"Result: {'✓ Correct' if sample_result['correct'] else '✗ Wrong'}\")\n",
    "    \n",
    "    # Observable Outcome\n",
    "    observable_info = sample_result['result'].get('observable_info', {})\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"OBSERVABLE OUTCOME\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Identified: {observable_info.get('observable_outcome', 'unclear')}\")\n",
    "    print(f\"Reasoning: {observable_info.get('reasoning', 'N/A')}\")\n",
    "    \n",
    "    # Builder Stats\n",
    "    builder_stats = sample_result['result'].get('builder_stats', {})\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"CAUSAL GRAPH STATISTICS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Seeds: {builder_stats.get('num_seeds', 0)}\")\n",
    "    print(f\"Entities: {builder_stats.get('num_entities', 0)}\")\n",
    "    print(f\"Edges: {builder_stats.get('num_edges', 0)}\")\n",
    "    print(f\"Chains: {builder_stats.get('num_chains', 0)}\")\n",
    "    print(f\"High-Confidence Relations (≥{CONFIDENCE_THRESHOLD}): {sample_result.get('high_conf_relations', 0)}\")\n",
    "    \n",
    "    # Choice Evaluations\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"CHOICE EVALUATIONS\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    for eval_data in sample_result['result']['choice_evaluations']:\n",
    "        choice = eval_data['choice']\n",
    "        forward = eval_data['forward_reasoning']\n",
    "        counterfactual = eval_data['counterfactual_reasoning']\n",
    "        \n",
    "        final_conf = forward['confidence'] + counterfactual.get('confidence_adjustment', 0)\n",
    "        final_conf = max(0.0, min(1.0, final_conf))\n",
    "        \n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"CHOICE: {choice.upper()}\")\n",
    "        print(f\"{'='*40}\")\n",
    "        \n",
    "        print(f\"\\n  [Forward Reasoning]\")\n",
    "        print(f\"    Confidence: {forward['confidence']:.2f}\")\n",
    "        print(f\"    Path Strength: {forward['path_strength']}\")\n",
    "        print(f\"    Causal Path: {forward.get('causal_path', 'N/A')}\")\n",
    "        print(f\"    Rationale: {forward['rationale'][:200]}...\")\n",
    "        \n",
    "        if forward.get('supporting_evidence'):\n",
    "            print(f\"    Evidence:\")\n",
    "            for i, ev in enumerate(forward['supporting_evidence'][:3], 1):\n",
    "                print(f\"      {i}. {ev}\")\n",
    "        \n",
    "        print(f\"\\n  [Counterfactual Reasoning]\")\n",
    "        print(f\"    Test Result: {counterfactual['test_result']}\")\n",
    "        print(f\"    Confidence Adjustment: {counterfactual.get('confidence_adjustment', 0):+.2f}\")\n",
    "        print(f\"    Final Confidence: {final_conf:.2f}\")\n",
    "        print(f\"    Scenario: {counterfactual.get('counterfactual_scenario', 'N/A')[:150]}...\")\n",
    "        print(f\"    Rationale: {counterfactual['rationale'][:200]}...\")\n",
    "    \n",
    "    # Final Decision\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL DECISION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    final = sample_result['result']['final_decision']\n",
    "    print(f\"\\nAnswer: {final['final_answer'].upper()}\")\n",
    "    print(f\"Confidence: {final['confidence']:.2f}\")\n",
    "    print(f\"Decision Basis: {final.get('decision_basis', 'unknown')}\")\n",
    "    print(f\"\\nReasoning:\")\n",
    "    print(f\"{final['reasoning']}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Error: Sample index {SAMPLE_INDEX} out of range (0-{len(results)-1})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "结果已保存到: choice_reasoning_results_20251107_175918.json\n",
      "包含 5 个样本的完整推理过程\n"
     ]
    }
   ],
   "source": [
    "# 保存结果到JSON文件\n",
    "output_file = f'choice_reasoning_results_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json'\n",
    "\n",
    "export_data = {\n",
    "    'config': {\n",
    "        'num_samples': NUM_SAMPLES,\n",
    "        'model': MODEL,\n",
    "        'confidence_threshold': CONFIDENCE_THRESHOLD,\n",
    "        'max_expansion_depth': MAX_EXPANSION_DEPTH,\n",
    "        'max_neighbors_per_seed': MAX_NEIGHBORS_PER_SEED,\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    },\n",
    "    'summary': {\n",
    "        'total': total,\n",
    "        'correct': correct,\n",
    "        'accuracy': accuracy,\n",
    "        'avg_confidence': avg_confidence,\n",
    "        'avg_high_conf_relations': avg_high_conf_rels\n",
    "    },\n",
    "    'results': [{\n",
    "        'question': r['question'],\n",
    "        'gold': r['gold'],\n",
    "        'prediction': r['prediction'],\n",
    "        'correct': r['correct'],\n",
    "        'confidence': r['confidence'],\n",
    "        'decision_basis': r.get('decision_basis', 'unknown'),\n",
    "        'observable_outcome': r.get('observable_outcome', 'unclear'),\n",
    "        'high_conf_relations': r.get('high_conf_relations', 0),\n",
    "        'observable_info': r['result'].get('observable_info', {}),\n",
    "        'builder_stats': r['result'].get('builder_stats', {}),\n",
    "        'choice_evaluations': r['result'].get('choice_evaluations', []),\n",
    "        'final_decision': r['result'].get('final_decision', {})\n",
    "    } for r in results]\n",
    "}\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(export_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n结果已保存到: {output_file}\")\n",
    "print(f\"包含 {len(results)} 个样本的完整推理过程\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
