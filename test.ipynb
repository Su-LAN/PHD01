{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "07481451",
      "metadata": {},
      "source": [
        "# WIQA causal triple pipeline test\n",
        "\n",
        "本 Notebook 使用 Hugging Face 的 WIQA 数据集，串联本地 Ollama 生成三元组、语义排序（Top‑M 平均）、置信度融合筛选，以及最终的 more/less/no_effect 判定。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "80bf0cf5",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\兰苏\\.conda\\envs\\causal_test\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import sys, os, importlib, json\n",
        "sys.path.append(os.path.abspath(\"01\"))\n",
        "\n",
        "from datasets import load_dataset\n",
        "import ollama\n",
        "\n",
        "import semantic_ranker, triple_ranker, triple_selector, effect_decider, causal_triple_generator\n",
        "importlib.reload(semantic_ranker); importlib.reload(triple_ranker); importlib.reload(triple_selector); importlib.reload(effect_decider); importlib.reload(causal_triple_generator)\n",
        "\n",
        "MODEL = \"gemma2:27b\"\n",
        "CONFIDENCE_THRESHOLD = 0.7\n",
        "SPLIT = \"validation\"  # 或 'train'\n",
        "N_SAMPLES = 5\n",
        "NUM_VARIATIONS = 10\n",
        "TOP_M = 3\n",
        "KEEP_FRACTION = 0.5\n",
        "BACKEND = \"auto\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "85a8968f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6894"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds = load_dataset(\"allenai/wiqa\", split=SPLIT, trust_remote_code=True)\n",
        "len(ds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8a806b2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_question(ex):\n",
        "    # 兼容不同字段名\n",
        "    for key in [\"question\", \"question_stem\", \"query\", \"what_if\", \"question_text\"]:\n",
        "        if key in ex and ex[key]:\n",
        "            q = ex[key]\n",
        "            if isinstance(q, dict) and 'stem' in q:\n",
        "                q = q['stem']\n",
        "            return str(q)\n",
        "    return \"\"\n",
        "\n",
        "def get_label(ex):\n",
        "    for key in [\"answer_label\", \"label\", \"effect_label\"]:\n",
        "        if key in ex and ex[key] is not None:\n",
        "            return str(ex[key]).strip().lower()\n",
        "    return None\n",
        "\n",
        "def normalize_label(lbl):\n",
        "    mapping = {\"no effect\": \"no_effect\", \"no_effect\": \"no_effect\", \"more\": \"more\", \"less\": \"less\"}\n",
        "    return mapping.get(lbl, None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d1b51433",
      "metadata": {},
      "outputs": [],
      "source": [
        "from causal_triple_generator import generate_causal_triples\n",
        "from triple_ranker import rank_triples\n",
        "from triple_selector import select_triples\n",
        "from effect_decider import decide_effect\n",
        "\n",
        "def run_pipeline(question):\n",
        "    gen = generate_causal_triples(question, model=MODEL, confidence_threshold=CONFIDENCE_THRESHOLD)\n",
        "    ranked = rank_triples(gen, question, num_variations=NUM_VARIATIONS, backend=BACKEND, top_m=TOP_M)\n",
        "    selected = select_triples(ranked, keep_fraction=KEEP_FRACTION, weight_avg=0.7, weight_confidence=0.3)\n",
        "    decision = decide_effect(question, ranked, target=None, weight_avg=0.7, weight_confidence=0.3)\n",
        "    return {\"generated\": gen, \"ranked\": ranked, \"selected\": selected, \"decision\": decision}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e6066dc9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    \"i\": 0,\n",
            "    \"gold\": \"more\",\n",
            "    \"decision\": \"more\"\n",
            "  },\n",
            "  {\n",
            "    \"i\": 1,\n",
            "    \"gold\": \"more\",\n",
            "    \"decision\": \"less\"\n",
            "  },\n",
            "  {\n",
            "    \"i\": 2,\n",
            "    \"gold\": \"no_effect\",\n",
            "    \"decision\": \"more\"\n",
            "  },\n",
            "  {\n",
            "    \"i\": 3,\n",
            "    \"gold\": \"less\",\n",
            "    \"decision\": \"less\"\n",
            "  },\n",
            "  {\n",
            "    \"i\": 4,\n",
            "    \"gold\": \"no_effect\",\n",
            "    \"decision\": \"less\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "for i in range(min(N_SAMPLES, len(ds))):\n",
        "    ex = ds[i]\n",
        "    q = get_question(ex)\n",
        "    gold = normalize_label(get_label(ex))\n",
        "    try:\n",
        "        out = run_pipeline(q)\n",
        "        results.append({\"index\": i, \"question\": q, \"gold\": gold, **out})\n",
        "    except Exception as e:\n",
        "        print(f\"Pipeline failed on index {i}: {e}\")\n",
        "\n",
        "print(json.dumps([\n",
        "    {\"i\": r[\"index\"], \"gold\": r[\"gold\"], \"decision\": r[\"decision\"][\"decision\"]}\n",
        "    for r in results\n",
        "], ensure_ascii=False, indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d0168aac",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q: suppose the female is sterile happens, how will it affect LESS rabbits.\n",
            "Gold: more Decision: less\n",
            "Top ranked triples (avg_score):\n",
            "0.208 ('female sterility', 'reduces', 'fertility rate') conf=0.95\n",
            "0.086 ('fertility rate', 'reduces', 'rabbit population') conf=0.85\n"
          ]
        }
      ],
      "source": [
        "# 展示第一个样例的详细信息\n",
        "if results:\n",
        "    r0 = results[1]\n",
        "    print(\"Q:\", r0[\"question\"])\n",
        "    print(\"Gold:\", r0[\"gold\"], \"Decision:\", r0[\"decision\"][\"decision\"])\n",
        "    print(\"Top ranked triples (avg_score):\")\n",
        "    for item in r0[\"ranked\"][:5]:\n",
        "        print(f\"{item['avg_score']:.3f} {item['triple']} conf={item.get('confidence')}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "causal_test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
