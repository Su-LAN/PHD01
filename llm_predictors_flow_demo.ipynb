{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Predictors Flow Demo (Meta + Reflection)\n",
    "\n",
    "本 Notebook 仅打印关键流程：\n",
    "- 开头打印问题与正确答案\n",
    "- 不打印因果图三元组/构图细节\n",
    "- 打印大模型阶段A草案(analysis) 与 阶段B反思(reflection) 的原始输出\n",
    "- 打印最终纠偏后的结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import importlib\n",
    "import pandas as pd\n",
    "\n",
    "import question_parser, ego_expansion_builder\n",
    "importlib.reload(question_parser); importlib.reload(ego_expansion_builder)\n",
    "from question_parser import QuestionParser\n",
    "from ego_expansion_builder import EgoExpansionCausalBuilder\n",
    "\n",
    "# 使用静默反思版本，避免构图与内部过程打印\n",
    "from llm_predictors_quiet import (\n",
    "    predict_meta_informed_llm_reflective,\n",
    "    predict_combined_context_llm_reflective,\n",
    ")\n",
    "\n",
    "MODEL = 'gemma2:27b'\n",
    "# 轻量构图，尽量减少时延与噪音\n",
    "MAX_EXPANSION_DEPTH = 1\n",
    "MAX_NEIGHBORS_PER_SEED = 2\n",
    "MAX_RELATIONS_PER_ENTITY = 2\n",
    "\n",
    "PARSER = QuestionParser(model_name=MODEL)\n",
    "BUILDER = EgoExpansionCausalBuilder(\n",
    "    model_name=MODEL,\n",
    "    max_neighbors_per_seed=MAX_NEIGHBORS_PER_SEED,\n",
    "    max_expansion_depth=MAX_EXPANSION_DEPTH,\n",
    "    max_relations_per_entity=MAX_RELATIONS_PER_ENTITY,\n",
    ")\n",
    "print('Predictors flow demo ready.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(lbl):\n",
    "    m = {\n",
    "        'no effect': 'no_effect',\n",
    "        'no_effect': 'no_effect',\n",
    "        'more': 'more',\n",
    "        'less': 'less'\n",
    "    }\n",
    "    return m.get((lbl or '').strip().lower())\n",
    "\n",
    "def run_case(question: str, gold: str | None = None):\n",
    "    print('\n' + '='*80)\n",
    "    print('QUESTION:')\n",
    "    print(question)\n",
    "    if gold is not None:\n",
    "        print(f'GOLD: {norm(gold)}')\n",
    "    print('-'*80)\n",
    "\n",
    "    # Meta-informed reflective\n",
    "    r1 = predict_meta_informed_llm_reflective(question, PARSER, BUILDER, MODEL)\n",
    "    print('[Meta-Informed] Stage A - Draft (LLM raw):')\n",
    "    print(r1.get('raw', {}).get('analysis', ''))\n",
    "    print('[Meta-Informed] Stage B - Reflection (LLM raw):')\n",
    "    print(r1.get('raw', {}).get('reflection', ''))\n",
    "    print(f"[Meta-Informed] Final: {r1.get('final_answer')} | corrected={r1.get('corrected')} | source={r1.get('correction_source')}")\n",
    "    print('-'*80)\n",
    "\n",
    "    # Combined-context reflective\n",
    "    r2 = predict_combined_context_llm_reflective(question, PARSER, BUILDER, MODEL)\n",
    "    print('[Combined-Context] Stage A - Draft (LLM raw):')\n",
    "    print(r2.get('raw', {}).get('analysis', ''))\n",
    "    print('[Combined-Context] Stage B - Reflection (LLM raw):')\n",
    "    print(r2.get('raw', {}).get('reflection', ''))\n",
    "    print(f"[Combined-Context] Final: {r2.get('final_answer')} | corrected={r2.get('corrected')} | source={r2.get('correction_source')}")\n",
    "\n",
    "    return {\n",
    "        'question': question,\n",
    "        'gold': norm(gold) if gold else None,\n",
    "        'meta_final': norm(r1.get('final_answer')),\n",
    "        'meta_corrected': r1.get('corrected'),\n",
    "        'comb_final': norm(r2.get('final_answer')),\n",
    "        'comb_corrected': r2.get('corrected'),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例：使用三条自定义测试用例\n",
    "test_cases = [\n",
    "    {\n",
    "        'question': 'suppose the seedling is not eaten happens, how will it affect LESS trees?',\n",
    "        'ground_truth': 'less',\n",
    "        'description': 'Meta-level LESS question'\n",
    "    },\n",
    "    {\n",
    "        'question': 'suppose less oil delivered happens, how will it affect more paper available?',\n",
    "        'ground_truth': 'no_effect',\n",
    "        'description': 'no_effect causal question'\n",
    "    },\n",
    "    {\n",
    "        'question': 'ssuppose you inhale more air from the outside happens, how will it affect there will be less oxygen in your blood?',\n",
    "        'ground_truth': 'less',\n",
    "        'description': 'Meta-level MORE question'\n",
    "    }\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for case in test_cases:\n",
    "    rows.append(run_case(case['question'], case['ground_truth']))\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
