import ollama
import re
import json
from collections import defaultdict, deque
from typing import List, Dict, Set, Tuple, Optional
import networkx as nx

class CausalGraphBuilder:
    """æ„å»ºå› æœDAGçš„å®Œæ•´ç³»ç»Ÿ
    
    === å½“å‰ç½®ä¿¡åº¦è®¡ç®—ï¼ˆç®€åŒ–ç‰ˆï¼‰===
    
    1. Aç±»ä¸‰å…ƒç»„ (confidence = 1.0 å›ºå®š)
       - å®Œå…¨åŸºäºé—®é¢˜æ–‡æœ¬ä¸­çš„æ˜ç¡®å› æœå…³ç³»
       - ä¸¤ç«¯å®ä½“éƒ½åœ¨E_Qä¸­
       - æœ‰æ˜ç¡®çš„æ–‡æœ¬è¯æ®
    
    2. Bç±»ä¸‰å…ƒç»„ (confidence = LLMè¯„ä¼° 0.0-1.0)
       - ä¸€ç«¯å®ä½“åœ¨E_Qä¸­ï¼Œå¦ä¸€ç«¯æ˜¯LLMæ¨èçš„å¤–éƒ¨å®ä½“
       - é€šè¿‡LLMè¯„ä¼°åˆç†æ€§å¹¶è¿”å›ç½®ä¿¡åº¦
    
    3. Cç±»ä¸‰å…ƒç»„ (confidence = 0.5 å›ºå®š)
       - ä¸€ç«¯æ˜¯Bç±»æ–°å®ä½“ï¼Œå¦ä¸€ç«¯æ˜¯å…¨æ–°çš„æ¡¥æ¥å®ä½“
    
    === æœªæ¥è¯„åˆ†ç³»ç»Ÿï¼ˆå¾…å®ç°ï¼‰===
    
    å°†æ¥å¯é›†æˆæ›´å¤æ‚çš„è¯„åˆ†æœºåˆ¶ï¼š
    - s_text: NLIæ¨¡å‹éªŒè¯è¯æ®å¼ºåº¦ï¼ˆENTAIL/NEU/CONTRAï¼‰
    - s_prior: LLMè‡ªä¸€è‡´æ€§ï¼ˆå¤šæç¤ºã€å¤šé‡‡æ ·æŠ•ç¥¨ï¼‰
    - s_connect: å›¾ç®—æ³•è®¡ç®—ä¸E_Qçš„è¿é€šæ€§
    - s_iden: å¯è¯†åˆ«æ€§åŠ©ç›Šï¼ˆd-separationã€èƒŒé—¨/å‰é—¨æ£€æµ‹ï¼‰
    - s_dir: æ–¹å‘ç¨³å®šåº¦ï¼ˆå› æœè§¦å‘è¯ã€æ—¶åºã€åŒå‘æ‰“åˆ†ï¼‰
    
    é€šè¿‡ set_scorer() æ–¹æ³•å¯ä»¥æ³¨å…¥å¤–éƒ¨è¯„åˆ†å™¨ã€‚
    
    === çº¦æŸè¯´æ˜ ===
    
    Aç±»ï¼šhead âˆˆ E_Q AND tail âˆˆ E_Q
    Bç±»ï¼š(head âˆˆ E_Q AND tail âˆ‰ E_Q) OR (head âˆ‰ E_Q AND tail âˆˆ E_Q)
    Cç±»ï¼š(head âˆ‰ (E_Q âˆª B) AND tail âˆˆ B AND tail âˆ‰ E_Q)
    """
    
    def __init__(self, model_name="llama3.2"):
        self.model_name = model_name
        # è‹±æ–‡å› æœè§¦å‘è¯
        self.causal_triggers = [
            "because", "cause", "lead to", "result in", "due to", 
            "therefore", "thus", "consequently", "hence", "so",
            "trigger", "produce", "generate", "bring about", "give rise to",
            "contribute to", "lead", "result", "effect", "affect",
            "influence", "impact", "induce", "provoke", "stem from"
        ]
        
        # é¢„ç•™ï¼šå¤–éƒ¨è¯„åˆ†å™¨ï¼ˆNLIã€å› æœè¯†åˆ«ç­‰ï¼‰
        self.external_scorer = None
    
    def set_scorer(self, scorer):
        """è®¾ç½®å¤–éƒ¨è¯„åˆ†å™¨ï¼ˆä¸ºå°†æ¥çš„NLIã€å› æœè¯†åˆ«ç­‰é¢„ç•™æ¥å£ï¼‰
        
        è¯„åˆ†å™¨åº”è¯¥å®ç°ä»¥ä¸‹æ–¹æ³•ï¼š
        - scorer.compute_score(triple_class, question, triple) -> float
        - scorer.score_evidence(question, triple) -> s_text
        - scorer.score_consistency(question, triple) -> s_prior  
        - scorer.score_direction(triple) -> s_dir
        - scorer.score_connectivity(graph, triple, eq_entities) -> s_connect
        - scorer.score_identifiability(graph, triple) -> s_iden
        
        Example:
            class ExternalScorer:
                def compute_score(self, triple_class, question, triple):
                    s_text = self.score_evidence(question, triple)
                    s_prior = self.score_consistency(question, triple)
                    s_dir = self.score_direction(triple)
                    # ç»¼åˆè¯„åˆ†
                    return weighted_average([s_text, s_prior, s_dir])
        """
        self.external_scorer = scorer
    
    def _compute_confidence(self, triple_class: str, question: str = None, 
                           triple: Dict = None, verification: Dict = None) -> float:
        """è®¡ç®—ä¸‰å…ƒç»„çš„ç½®ä¿¡åº¦
        
        å½“å‰ç‰ˆæœ¬ï¼šç®€åŒ–è®¡ç®—
        - Aç±»: 1.0 (å›ºå®š)
        - Bç±»: LLMè¯„ä¼° (0.0-1.0) æˆ–ä½¿ç”¨å·²æœ‰verificationç»“æœ
        - Cç±»: 0.5 (å›ºå®š)
        
        æœªæ¥ç‰ˆæœ¬ï¼šå¯é›†æˆå¤–éƒ¨è¯„åˆ†å™¨
        - å¦‚æœè®¾ç½®äº† external_scorerï¼Œå°†è°ƒç”¨å…¶è¯„åˆ†æ–¹æ³•
        - ç»¼åˆ s_text, s_prior, s_connect, s_iden, s_dir
        
        Args:
            triple_class: 'A', 'B', or 'C'
            question: é—®é¢˜æ–‡æœ¬
            triple: ä¸‰å…ƒç»„å­—å…¸
            verification: å·²æœ‰çš„éªŒè¯ç»“æœï¼ˆç”¨äºBç±»ï¼Œé¿å…é‡å¤è°ƒç”¨LLMï¼‰
        """
        # å¦‚æœæœ‰å¤–éƒ¨è¯„åˆ†å™¨ï¼Œä½¿ç”¨å¤–éƒ¨è¯„åˆ†å™¨
        if self.external_scorer and triple:
            return self.external_scorer.compute_score(triple_class, question, triple)
        
        # å¦åˆ™ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
        if triple_class == 'A':
            return 1.0
        elif triple_class == 'C':
            return 0.5
        else:  # Bç±»
            # ä¼˜å…ˆä½¿ç”¨å·²æœ‰çš„verificationç»“æœï¼ˆé¿å…é‡å¤è°ƒç”¨LLMï¼‰
            if verification and 'confidence' in verification:
                return verification['confidence']
            # å¦‚æœæ²¡æœ‰verificationä½†æœ‰tripleï¼Œé‡æ–°éªŒè¯
            elif triple and question:
                verification_result = self._verify_triple_evidence_relaxed(
                    question, triple['head'], triple['tail'], 'causes'
                )
                return verification_result['confidence']
            # é»˜è®¤å€¼
            return 0.6
        
    def extract_entities(self, question: str) -> Set[str]:
        """æ­¥éª¤1ï¼šä»é—®é¢˜ä¸­æŠ½å–å®ä½“ï¼ˆE_Qï¼‰"""
        prompt = f"""Extract only entities from the question. 
An entity must be a noun or noun phrase that denotes an object, substance, place, organization, or named concept.
Do NOT include actions, events, properties, or adjectives.
Exclude gerunds/participles (words ending with â€œ-ingâ€) unless they are part of a well-known multi-word noun (e.g., â€œmachine learningâ€, â€œglobal warmingâ€) or followed by a head noun (e.g., â€œfreezing pointâ€). 
If a word can be a verb or a noun (e.g., â€œfreeze/freezingâ€), include it only when it functions as a noun with a head noun; otherwise exclude it.

Normalize to singular lemmas, remove duplicates, and keep multi-word noun phrases intact. 
Return ONLY the entity names, one per line, with no numbers, bullets, quotes, or explanations. 
If there are no entities, return nothing.

Question: {question}

Entities:"""
        
        response = ollama.generate(model=self.model_name, prompt=prompt)
        entities_text = response['response'].strip()
        
        # è§£æå®ä½“
        entities = set()
        for line in entities_text.split('\n'):
            # ç§»é™¤å„ç§æ ¼å¼ï¼šç¼–å·ã€bulletã€ç ´æŠ˜å·ç­‰
            entity = line.strip()
            
            # è·³è¿‡ç©ºè¡Œ
            if not entity or len(entity) < 2:
                continue
            
            # è·³è¿‡å¸¸è§çš„æç¤ºè¯å’Œæ ‡é¢˜
            if entity.lower() in ['entities:', 'entity list:', 'here is', 'here are', 'the entities are:', 'example output format:']:
                continue
            if entity.lower().startswith(('here', 'the following', 'entity', 'entities')):
                continue
            
            # ç§»é™¤å¼€å¤´çš„ç¼–å· (1. 2. 3. æˆ– 1) 2) 3))
            entity = re.sub(r'^\d+[\.)]\s*', '', entity)
            # ç§»é™¤bullet points
            entity = entity.lstrip('-â€¢*>').strip()
            # ç§»é™¤å¼•å·
            entity = entity.strip('"\'')
            
            if entity and len(entity) > 1:
                entities.add(entity)
        
        return entities
    
    def extract_causal_triggers(self, text: str) -> List[Dict]:
        """æŠ½å–å› æœè§¦å‘è¯åŠå…¶ä½ç½®"""
        triggers = []
        for trigger in self.causal_triggers:
            for match in re.finditer(trigger, text, re.IGNORECASE):
                triggers.append({
                    'trigger': trigger,
                    'start': match.start(),
                    'end': match.end()
                })
        return triggers
    
    def extract_class_a_triples(self, question: str, entities: Set[str]) -> List[Dict]:
        """æ­¥éª¤2ï¼šç”ŸæˆAç±»ä¸‰å…ƒç»„ï¼ˆå®Œå…¨æ¥è‡ªé—®é¢˜ï¼Œä¸”ä»…ä¿ç•™é¢˜å†…æ˜ç¡®æ–­è¨€çš„å› æœäº‹å®ï¼‰"""

        # ===== åŸºç¡€å‡†å¤‡ =====
        entities = set(entities)
        entity_lower_map = {e.lower(): e for e in entities}

        # å› æœç™½åå• & éå› æœé»‘åå•
        ALLOWED_REL = {"causes", "increases", "decreases", "prevents", "enables", "needed_for"}
        FORBIDDEN_REL = {"contains", "part_of", "has", "is_a", "located_in", "example_of", "equals", "correlates_with"}

        # çœŸæ­£â€œé—®å¥/è®¾é—®â€çš„è§¦å‘è¯ï¼ˆä¸è¦æŠŠ suppose/assume å½“é—®å¥ï¼‰
        QUERY_PATTERNS = (
            "how will", "how would", "how does", "does ",  # æ³¨æ„ `does ` åæœ‰ç©ºæ ¼ï¼Œé¿å…è¯¯ä¼¤
            "what happens if", "æœ‰æ²¡æœ‰å½±å“", "æ˜¯å¦", "affect", "impact"
        )

        import re
        triple_line_re = re.compile(r'^\s*(?P<head>.+?)\s*->\s*(?P<rel>.+?)\s*->\s*(?P<tail>.+?)\s*\|\s*(?P<ev>.+?)\s*$')
        scoped_entity_re = re.compile(r'^(?P<base>[^{]+?)(?:\{(?P<scope>[^}]+)\})?$')

        def _parse_scoped_name(name: str):
            m = scoped_entity_re.match(name.strip())
            if not m:
                return name.strip(), None
            base = m.group("base").strip()
            scope = (m.group("scope") or "").strip() or None
            return base, scope

        def _is_query_evidence(ev_text: str) -> bool:
            ev_low = ev_text.lower()
            return any(pat in ev_low for pat in QUERY_PATTERNS)

        def _normalize_relation(rel: str) -> str:
            return rel.strip().lower().replace(" ", "_")

        # å®½æ¾è¯æ®åŒ¹é…ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿã€æŠ˜å ç©ºç™½ã€å¯å»æ ‡ç‚¹ï¼‰
        def _normalize_txt(s: str) -> str:
            s = s.strip().lower()
            s = re.sub(r'\s+', ' ', s)
            s = re.sub(r'[^\w\s]', '', s)
            return s

        def _evidence_in_question(ev_text: str, q: str) -> bool:
            ev = ev_text.strip()
            if ev.startswith('"') and ev.endswith('"') and len(ev) >= 2:
                ev = ev[1:-1]
            return _normalize_txt(ev) in _normalize_txt(q)
        
        def _find_matching_entity(self, text: str, entities: Set[str], entity_lower_map: Dict[str, str]) -> Optional[str]:
            import re, difflib

            if not text:
                return None

            # å»æ‰å¯èƒ½çš„ä½œç”¨åŸŸæ ‡ç­¾ï¼š water{for=snow} -> water
            base = re.sub(r'\{[^}]*\}\s*$', '', text.strip()).strip()

            # 1) ç²¾ç¡®åŒ¹é…
            if base in entities:
                return base

            # 2) å°å†™åŒ¹é…
            low = base.lower()
            if low in entity_lower_map:
                return entity_lower_map[low]

            # 3) å­ä¸²/åŒ…å«åŒ¹é…ï¼ˆå®½æ¾ï¼‰
            for e in entities:
                el = e.lower()
                if low in el or el in low:
                    return e

            # 4) è¿‘ä¼¼åŒ¹é…ï¼ˆé¿å…è½»å¾®æ‹¼å†™å·®å¼‚ï¼‰
            candidates = difflib.get_close_matches(base, list(entities), n=1, cutoff=0.88)
            if candidates:
                return candidates[0]

            return None

        # ===== æ„é€  Prompt =====
        entities_str = ", ".join(sorted(entities))  # ä¿®æ­£ï¼šä¸è¦ç›´æ¥æ‰“å° set
        prompt = f"""You are a causal graph extractor.

Goal
- From the question text, extract ONLY causal facts that are explicitly asserted or unambiguously entailed by in-sentence constructions (light linguistic entailment).
- Build a question-specific causal graph using ONLY the provided base entities.
- Do NOT infer an answer or invent facts. Do NOT output correlations or structural facts.

Entity scope & disambiguation
- If the same surface word refers to different contexts/roles, add a scope in braces after the base entity, e.g., water{{in=cube}}, water{{for=snow}}, water{{role=precursor}}.
- The base name MUST be one of the allowed entities; scopes are free-form annotations.
- Never merge nodes with different scopes unless the text explicitly states they are the same.

Use ONLY these base entities:
{entities_str}

Causal relations (normalize to this closed set ONLY)
- causes, increases, decreases, prevents, enables, needed_for

Linguistic patterns â†’ relation mapping (must apply)
- "Y requires X", "Y needs X"                              â†’ needed_for(X, Y)
- "for Y to happen, X", "for Y to VERB, X", "to VERB, X"   â†’ needed_for(X, Y)
- "X leads to Y", "X results in Y", "X causes Y"           â†’ causes
- "more X â†’ more Y" / "less X â†’ less Y"                    â†’ increases / decreases
- "without X, Y cannot/does not happen"                    â†’ prevents(X, Y) or needed_for(X, Y) (choose the closer wording)
- "X allows/enables/permits Y"                             â†’ enables

Ignore NON-causal / structural patterns entirely
- has/have/contains, part_of, is_a, located_in, equals, example_of, correlates_with
- Structural links may be used only to craft scopes (e.g., water{{in=cube}}) but MUST NOT become causal triples.

Queries vs. facts
- Do NOT output triples for query forms or meta-questions:
  "how will X affect Y", "does X affect Y", "what happens if", "æ˜¯å¦", "æœ‰æ²¡æœ‰å½±å“", "å½±å“å—", "affect", "impact".
- Words like "suppose", "assume", or "let's say" DO NOT by themselves invalidate asserted/entailed causal statements in the same sentence. Keep extracting if a causal pattern is present.

Evidence
- For every triple, provide a minimal exact substring from the question that contains the trigger phrase; wrap it in double quotes.

If NO causal facts satisfy the above, output exactly:
NONE

Question:
{question}

Return in this EXACT format (one per line), no numbering, no extra text:
head_entity -> relation -> tail_entity | "evidence_text"

Examples (follow EXACTLY; base entity must be from the list; scopes allowed):

Example 1
Question: "For plants to grow, water is needed."
Entities: water, plants
Triples:
water -> needed_for -> plants | "For plants to grow, water is needed."

Example 2
Question: "Less salt leads to lower blood pressure."
Entities: salt, blood pressure
Triples:
salt -> decreases -> blood pressure | "Less salt leads to lower blood pressure."

Example 3
Question: "Suppose the tray has water. For snow to form, water must freeze."
Entities: tray, water, snow
Triples:
water{{for=snow}} -> needed_for -> snow | "For snow to form, water must freeze."

Triples:
"""

        # ===== ç”Ÿæˆä¸è§£æ =====
        try:
            response = ollama.generate(model=self.model_name, prompt=prompt)
            raw = response.get('response', '').strip()
            print(raw)
        except Exception as e:
            print(f"[extract_class_a_triples] LLM error: {e}")
            return []

        _idx = raw.lower().find("triples:")
        triples_text = raw[_idx + len("triples:"):] if _idx != -1 else raw
        triples_text = triples_text.strip()

        triples: List[Dict] = []
        if triples_text.lower() == "none":
            return triples

        for line in triples_text.splitlines():
            line = line.strip()
            if not line or "->" not in line or "|" not in line:
                continue

            m = triple_line_re.match(line)
            if not m:
                continue

            head_raw, rel_raw, tail_raw, ev_raw = m.group("head"), m.group("rel"), m.group("tail"), m.group("ev")

            # è¯æ®ä¸­è‹¥æ˜¯é—®å¥/è®¾é—®è§¦å‘ï¼Œåˆ™å¿½ç•¥
            if _is_query_evidence(ev_raw):
                continue

            rel = _normalize_relation(rel_raw)
            if rel in FORBIDDEN_REL:
                continue
            if rel not in ALLOWED_REL:
                continue

            head_base, head_scope = _parse_scoped_name(head_raw)
            tail_base, tail_scope = _parse_scoped_name(tail_raw)

            head_match = self._find_matching_entity(head_base, entities, entity_lower_map)
            tail_match = self._find_matching_entity(tail_base, entities, entity_lower_map)
            if not head_match or not tail_match:
                continue

            if head_match == tail_match and (not head_scope and not tail_scope):
                continue

            if not _evidence_in_question(ev_raw, question):
                continue

            triple = {
                "head": head_match,
                "head_scope": head_scope,
                "relation": rel,
                "tail": tail_match,
                "tail_scope": tail_scope,
                "evidence": ev_raw.strip(),
                "class": "A",
            }

            conf = self._compute_confidence("A", question, triple)
            ev_low = ev_raw.lower()
            if triple["head_scope"] and any(k in ev_low for k in ["for", "in", "into", "from", "to"]):
                conf = min(1.0, conf + 0.05)
            if triple["tail_scope"] and any(k in ev_low for k in ["for", "in", "into", "from", "to"]):
                conf = min(1.0, conf + 0.05)
            triple["confidence"] = conf

            triples.append(triple)

        return triples

    def expand_class_b_triples(self, question: str, eq_entities: Set[str],
                               existing_triples: List[Dict], k: int = 3, debug: bool = False) -> List[Dict]:
        """æ­¥éª¤3ï¼šæ‰©å±•Bç±»ä¸‰å…ƒç»„ï¼ˆé—®é¢˜å®ä½“ + å¤–éƒ¨å®ä½“ï¼‰
        çº¦æŸï¼šä¸¤ç«¯å¿…é¡»æ°å¥½ä¸€ä¸ªåœ¨E_Qä¸­ï¼›ä»…ä¿ç•™å› æœï¼ˆcausesï¼‰æ–¹å‘ï¼›è‡ªåŠ¨ä¿®æ­£LLMæ–¹å‘é”™è¯¯ã€‚
        """
        b_triples = []
        eq_entities_lower = {e.lower() for e in eq_entities}

        for entity in list(eq_entities)[:3]:
            prompt = f"""Task: Find NEW causal relationships for "{entity}"

Question: {question}

Already identified entities (DO NOT USE): {', '.join(eq_entities)}

Find NEW entities (NOT in the above list) in TWO categories:

â”â”â” CATEGORY 1: CAUSES â”â”â”
What NEW entities CAUSE "{entity}"?
Arrow direction: NEW_ENTITY -> causes -> {entity}

Format exactly:
X -> causes -> {entity}

â”â”â” CATEGORY 2: EFFECTS â”â”â”
What NEW entities are CAUSED BY "{entity}"?
Arrow direction: {entity} -> causes -> NEW_ENTITY

Format exactly:
{entity} -> causes -> Y

Return exactly {k} lines for CAUSES and {k} lines for EFFECTS (total {k*2}), no bullets, no numbering.
"""
            response = ollama.generate(model=self.model_name, prompt=prompt)
            candidates_text = response['response'].strip()

            if debug:
                print(f"\n[DEBUG] Bç±»å€™é€‰ for '{entity}':\n{candidates_text}")

            count = 0
            for raw_line in candidates_text.split('\n'):
                if count >= k * 2:
                    break
                line = raw_line.strip().strip('*').strip('-').strip()
                if '->' not in line:
                    continue

                try:
                    parts = [p.strip() for p in line.split('->')]
                    if len(parts) < 3:
                        continue
                    left, rel_word, right = parts[0].strip('"\' '), parts[1].lower(), parts[2].strip('"\' ')
                    # åªæ¥å— causes
                    if "cause" not in rel_word:
                        continue

                    left_in_eq = left.lower() in eq_entities_lower
                    right_in_eq = right.lower() in eq_entities_lower

                    # åˆ¤åˆ«å®é™…æ–¹å‘ï¼ˆæœŸæœ›ï¼šä¸€ç«¯æ˜¯ E_Qï¼Œå¦ä¸€ç«¯æ˜¯æ–°å®ä½“ï¼‰
                    if left_in_eq and not right_in_eq:
                        # EFFECT: entity -> causes -> NEW
                        head, tail = left, right
                        actual_direction = 'effect'
                    elif not left_in_eq and right_in_eq:
                        # CAUSE: NEW -> causes -> entity
                        head, tail = left, right
                        actual_direction = 'cause'
                    elif not left_in_eq and not right_in_eq:
                        # ä¸¤ç«¯éƒ½ä¸åœ¨E_Qï¼Œå°è¯•æ¨¡ç³Šé æ‹¢ entity
                        if entity.lower() in right.lower():
                            head, tail = left, entity
                            actual_direction = 'cause'
                        elif entity.lower() in left.lower():
                            head, tail = entity, right
                            actual_direction = 'effect'
                        else:
                            continue
                    else:
                        # ä¸¤ç«¯éƒ½åœ¨E_Qï¼Œè¿™æ˜¯Aç±»
                        continue

                    # é‡æ–°è§„èŒƒï¼šæˆ‘ä»¬æœ€ç»ˆç»Ÿä¸€ relation ä¸º "causes"
                    verification = self._verify_triple_evidence_relaxed(
                        question, head, tail, actual_direction, debug=debug
                    )
                    if debug:
                        print(f"    å€™é€‰: {head} -> causes -> {tail} | verify={verification['is_valid']}, conf={verification['confidence']:.2f}")

                    if not verification['is_valid']:
                        continue

                    # Bç±»çº¦æŸï¼šæ°å¥½ä¸€ç«¯åœ¨E_Q
                    head_in_eq = head.lower() in eq_entities_lower
                    tail_in_eq = tail.lower() in eq_entities_lower
                    if (head_in_eq ^ tail_in_eq) is False:
                        if debug:
                            print("    âŒ ä¸æ»¡è¶³Bç±»çº¦æŸï¼ˆä¸¤ç«¯éƒ½åœ¨æˆ–éƒ½ä¸åœ¨ E_Qï¼‰")
                        continue

                    triple = {
                        'head': head,
                        'relation': 'causes',
                        'tail': tail,
                        'evidence': verification['evidence'],
                        'class': 'B',
                        'confidence': self._compute_confidence('B', question, None, verification=verification)
                    }
                    b_triples.append(triple)
                    count += 1

                except Exception as e:
                    if debug:
                        print(f"    è§£æé”™è¯¯: {e}")
                    continue

        # å»æ–¹å‘å†²çª
        b_triples = self._check_direction_consistency(existing_triples + b_triples)
        # åªä¿ç•™ B ç±»
        b_triples = [t for t in b_triples if t.get('class') == 'B']
        return b_triples
    
    def expand_class_c_triples(self, question: str, eq_entities: Set[str],
                               b_entities: Set[str], existing_triples: List[Dict],
                               max_path_length: int = 2, debug: bool = False) -> List[Dict]:
        """æ­¥éª¤4ï¼šæ‰©å±•Cç±»ä¸‰å…ƒç»„ï¼ˆæ¡¥æ¥å®ä½“ï¼‰
        
        çº¦æŸï¼šä¸‰å…ƒç»„çš„å®ä½“æœ‰ä¸€ä¸ªåœ¨Bç±»æ–°å¢çš„å®ä½“ä¸­ï¼ˆä¸åœ¨Aç±»/E_Qä¸­ï¼‰ï¼Œå¦ä¸€ä¸ªæ˜¯å…¨æ–°çš„æ¡¥æ¥å®ä½“
        """
        c_triples = []
        
        if not b_entities:
            if debug:
                print("[DEBUG] æ²¡æœ‰Bç±»å®ä½“ï¼Œè·³è¿‡Cç±»æ‰©å±•")
            return c_triples
        
        # ğŸ”§ æ¸…ç†æ‰€æœ‰å®ä½“åç§°ä¸­çš„markdownç¬¦å·
        b_entities_clean = {e.strip('*').strip() for e in b_entities}
        
        # æ”¶é›†å·²çŸ¥å®ä½“
        eq_entities_lower = {e.lower() for e in eq_entities}
        all_known_entities = eq_entities.union(b_entities_clean)
        all_known_lower = {e.lower() for e in all_known_entities}
        
        if debug:
            print(f"\n[DEBUG] Cç±»æ‰©å±•:")
            print(f"  Bç±»å®ä½“ï¼ˆæ¸…ç†åï¼‰: {b_entities_clean}")
            print(f"  å·²çŸ¥å®ä½“æ€»æ•°: {len(all_known_entities)}")
        
        # æ‰©å±•å‰4ä¸ªBç±»å®ä½“ï¼ˆå¢åŠ æ•°é‡ï¼‰
        for idx, b_entity in enumerate(list(b_entities_clean)[:4], 1):
            # ã€å…³é”®ã€‘ç¡®ä¿b_entityç¡®å®æ˜¯Bç±»æ–°å¢çš„ï¼ˆä¸åœ¨E_Qä¸­ï¼‰
            if b_entity.lower() in eq_entities_lower:
                if debug:
                    print(f"\n  [{idx}] è·³è¿‡ '{b_entity}': åœ¨E_Qä¸­")
                continue
            
            if debug:
                print(f"\n  [{idx}] ä¸ºBç±»å®ä½“ '{b_entity}' å¯»æ‰¾æ¡¥æ¥æ¦‚å¿µ...")
            
            prompt = f"""Based on the question context, propose 2 NEW bridging concepts that connect "{b_entity}" to the causal chain. These should be intermediate concepts that are NOT already mentioned.

Question: {question}

Target entity: "{b_entity}" (from extended reasoning)

Already known entities (DO NOT USE): {', '.join(all_known_entities)}

Propose NEW bridging concepts that:
1. Have a causal relationship with "{b_entity}"
2. Help connect the causal chain
3. Are NOT in the known entities list above

Format: new_bridge_concept -> relation -> "{b_entity}"

Example:
Industrial activity -> contributes to -> Greenhouse gas emissions
Environmental policy -> influences -> Deforestation

Return only triples with NEW concepts, one per line:"""
            
            response = ollama.generate(model=self.model_name, prompt=prompt)
            candidates_text = response['response'].strip()
            
            if debug:
                print(f"  LLMå“åº”:\n{candidates_text}")
            
            found_any = False
            for line in candidates_text.split('\n')[:3]:  # å¢åŠ åˆ°3è¡Œ
                line = line.strip()
                if '->' in line:
                    try:
                        parts = [p.strip() for p in line.split('->')]
                        if len(parts) >= 3:
                            # ğŸ”§ æ¸…ç†markdownç¬¦å·
                            bridge_entity = parts[0].strip('"\'*').strip()
                            relation = parts[1].strip('*').strip()
                            target = parts[2].strip('"\'*').strip()
                            
                            if debug:
                                print(f"\n    è§£æ: {bridge_entity} -> {relation} -> {target}")
                            
                            # ã€å…³é”®çº¦æŸ1ã€‘ç¡®ä¿bridge_entityæ˜¯å…¨æ–°çš„ï¼ˆä¸åœ¨E_Qå’ŒBç±»ä¸­ï¼‰
                            if bridge_entity.lower() in all_known_lower:
                                if debug:
                                    print(f"      âŒ è·³è¿‡ï¼š'{bridge_entity}' å·²åœ¨å·²çŸ¥å®ä½“ä¸­")
                                continue
                            
                            # ã€å…³é”®çº¦æŸ2ã€‘ç¡®ä¿targetæ˜¯Bç±»å®ä½“ï¼ˆä¸åœ¨E_Qä¸­ï¼‰
                            target_in_b = target.lower() in {e.lower() for e in b_entities_clean}
                            target_in_eq = target.lower() in eq_entities_lower
                            
                            # å¦‚æœtargetè§£æä¸å¯¹ï¼Œç”¨å½“å‰çš„b_entity
                            if not target_in_b or target_in_eq:
                                if debug:
                                    print(f"      ç›®æ ‡å®ä½“ä¸åŒ¹é…ï¼Œä½¿ç”¨å½“å‰Bç±»å®ä½“: {b_entity}")
                                target = b_entity
                            
                            # è·¯å¾„é•¿åº¦æ£€æŸ¥ï¼ˆæš‚æ—¶æ”¾å®½ï¼‰
                            # temp_graph = self._build_temp_graph(existing_triples + c_triples)
                            # path_ok = self._check_path_length(temp_graph, bridge_entity, 
                            #                           eq_entities, max_path_length)
                            path_ok = True  # æš‚æ—¶è·³è¿‡è·¯å¾„æ£€æŸ¥ï¼Œå…ˆçœ‹èƒ½ä¸èƒ½ç”Ÿæˆ
                            
                            if debug:
                                print(f"      è·¯å¾„æ£€æŸ¥: {path_ok}")
                            
                            if path_ok:
                                # ã€æœ€ç»ˆéªŒè¯ã€‘ç¡®ä¿Cç±»çº¦æŸï¼š
                                # - headæ˜¯æ–°çš„æ¡¥æ¥å®ä½“ï¼ˆä¸åœ¨E_Qå’ŒBä¸­ï¼‰
                                # - tailæ˜¯Bç±»å®ä½“ï¼ˆåœ¨Bä¸­ä½†ä¸åœ¨E_Qä¸­ï¼‰
                                head_is_new = bridge_entity.lower() not in all_known_lower
                                tail_is_b_class = (target.lower() in {e.lower() for e in b_entities_clean} and 
                                                  target.lower() not in eq_entities_lower)
                                
                                if debug:
                                    print(f"      éªŒè¯Cç±»çº¦æŸ:")
                                    print(f"        head_is_new ({bridge_entity}): {head_is_new}")
                                    print(f"        tail_is_b_class ({target}): {tail_is_b_class}")
                                
                                if head_is_new and tail_is_b_class:
                                    triple = {
                                        'head': bridge_entity,
                                        'relation': relation,
                                        'tail': target,
                                        'evidence': f"Bridging concept connecting to {target}",
                                        'class': 'C'
                                    }
                                    # ä½¿ç”¨ç»Ÿä¸€çš„ç½®ä¿¡åº¦è®¡ç®—
                                    triple['confidence'] = self._compute_confidence('C', question, triple)
                                    c_triples.append(triple)
                                    found_any = True
                                    
                                    # æ›´æ–°å·²çŸ¥å®ä½“
                                    all_known_entities.add(bridge_entity)
                                    all_known_lower.add(bridge_entity.lower())
                                    
                                    if debug:
                                        print(f"      âœ… æ·»åŠ Cç±»ä¸‰å…ƒç»„: {bridge_entity} -> {target}")
                                else:
                                    if debug:
                                        print(f"      âŒ ä¸æ»¡è¶³Cç±»çº¦æŸ")
                    except Exception as e:
                        if debug:
                            print(f"      âŒ è§£æé”™è¯¯: {e}")
                        continue
            
            if debug and not found_any:
                print(f"    è¯¥Bç±»å®ä½“æœªç”ŸæˆCç±»ä¸‰å…ƒç»„")
        
        return c_triples
    
    def _verify_triple_evidence(self, question: str, entity1: str, 
                                entity2: str, direction: str) -> Dict:
        """éªŒè¯ä¸‰å…ƒç»„çš„è¯æ®ï¼ˆä¸¥æ ¼ç‰ˆæœ¬ï¼Œç”¨äºAç±»ï¼‰"""
        prompt = f"""Determine whether the following causal relationship is entailed or supported by the question text.

Question: {question}

Causal relationship: "{entity1}" {direction} "{entity2}"

Please answer:
1. Is it entailed (Yes/No)
2. Confidence level (0.0-1.0)
3. Supporting evidence (quote from the question)

Format:
Entailed: Yes/No
Confidence: 0.8
Evidence: ..."""
        
        response = ollama.generate(model=self.model_name, prompt=prompt)
        result_text = response['response'].strip()
        
        is_valid = "yes" in result_text.lower().split('\n')[0]
        
        # è§£æç½®ä¿¡åº¦
        confidence = 0.5
        for line in result_text.split('\n'):
            if 'confidence' in line.lower():
                try:
                    confidence = float(re.findall(r'0\.\d+|1\.0', line)[0])
                except:
                    pass
        
        # æå–è¯æ®
        evidence = ""
        for line in result_text.split('\n'):
            if 'evidence' in line.lower():
                evidence = line.split(':', 1)[1].strip() if ':' in line else ""
                break
        
        return {
            'is_valid': is_valid and confidence > 0.5,
            'confidence': confidence,
            'evidence': evidence
        }
    
    def _verify_triple_evidence_relaxed(self, question: str, entity1: str, 
                                        entity2: str, direction: str, debug: bool = False) -> Dict:
        """éªŒè¯ä¸‰å…ƒç»„çš„åˆç†æ€§ï¼ˆå®½æ¾ç‰ˆæœ¬ï¼Œç”¨äºB/Cç±» - å…è®¸å¤–éƒ¨æ¨ç†ï¼‰"""
        prompt = f"""Based on the question context and common sense, determine if the following causal relationship is reasonable and relevant.

Question context: {question}

Proposed causal relationship: "{entity1}" {direction} "{entity2}"

The entity "{entity1}" may NOT appear directly in the question - that's OK. Judge based on:
1. Is this relationship logically reasonable given the question context?
2. Does it help explain or expand the causal chain in the question?

Please answer:
1. Is it reasonable (Yes/No)
2. Confidence level (0.0-1.0)
3. Brief reasoning

Format:
Reasonable: Yes/No
Confidence: 0.7
Reasoning: ..."""
        
        response = ollama.generate(model=self.model_name, prompt=prompt)
        result_text = response['response'].strip()
        
        if debug:
            print(f"\n[DEBUG] éªŒè¯ '{entity1}' {direction} '{entity2}':")
            print(f"LLMå“åº”:\n{result_text}\n")
        
        # å®½æ¾çš„åˆ¤æ–­ï¼šåªè¦ä¸æ˜¯æ˜ç¡®çš„"No"å°±æ¥å—
        first_line = result_text.lower().split('\n')[0] if result_text else ""
        is_valid = "yes" in first_line or "reasonable" in first_line
        
        # å¦‚æœç¬¬ä¸€è¡Œæ²¡æœ‰æ˜ç¡®ç­”æ¡ˆï¼Œæ£€æŸ¥æ•´ä¸ªå“åº”
        if not is_valid:
            is_valid = "yes" in result_text.lower() and "no" not in first_line
        
        # è§£æç½®ä¿¡åº¦ï¼ˆBç±»çš„é»˜è®¤ç½®ä¿¡åº¦ç¨ä½ï¼‰
        confidence = 0.6  # é»˜è®¤å€¼
        for line in result_text.split('\n'):
            if 'confidence' in line.lower():
                try:
                    # å°è¯•æå–æ•°å­—
                    numbers = re.findall(r'0\.\d+|1\.0|1', line)
                    if numbers:
                        confidence = float(numbers[0])
                except:
                    pass
        
        # æå–æ¨ç†
        reasoning = ""
        for line in result_text.split('\n'):
            if 'reasoning' in line.lower():
                reasoning = line.split(':', 1)[1].strip() if ':' in line else ""
                break
        
        if not reasoning:
            # å¦‚æœæ²¡æ‰¾åˆ°Reasoningè¡Œï¼Œä½¿ç”¨æ•´ä¸ªå“åº”çš„ååŠéƒ¨åˆ†
            lines = result_text.split('\n')
            if len(lines) > 2:
                reasoning = ' '.join(lines[2:])
        
        # ğŸ”§ é™ä½é˜ˆå€¼ï¼šä»0.4é™åˆ°0.3ï¼Œæ›´å®¹æ˜“æ¥å—
        final_is_valid = is_valid and confidence > 0.3
        
        if debug:
            print(f"è§£æç»“æœ: is_valid={is_valid}, confidence={confidence}, final={final_is_valid}")
        
        return {
            'is_valid': final_is_valid,
            'confidence': confidence,
            'evidence': reasoning or f"External reasoning: {entity1} {direction} {entity2}"
        }
    
    def _check_direction_consistency(self, triples: List[Dict]) -> List[Dict]:
        """æ£€æŸ¥æ–¹å‘ä¸€è‡´æ€§ï¼Œè§£å†³å†²çª"""
        # æ„å»ºå®ä½“å¯¹çš„æ–¹å‘æ˜ å°„
        direction_map = defaultdict(list)
        
        for triple in triples:
            key = tuple(sorted([triple['head'], triple['tail']]))
            direction_map[key].append(triple)
        
        # æ£€æŸ¥å†²çª
        consistent_triples = []
        for key, candidates in direction_map.items():
            if len(candidates) == 1:
                consistent_triples.append(candidates[0])
            else:
                # æœ‰å†²çªï¼Œä¿ç•™ç½®ä¿¡åº¦æœ€é«˜çš„
                best = max(candidates, key=lambda x: x.get('confidence', 0.5))
                consistent_triples.append(best)
        
        return consistent_triples
    
    def _build_temp_graph(self, triples: List[Dict]) -> nx.DiGraph:
        """æ„å»ºä¸´æ—¶å›¾ç”¨äºè·¯å¾„åˆ†æ"""
        G = nx.DiGraph()
        for triple in triples:
            G.add_edge(triple['head'], triple['tail'], 
                      relation=triple['relation'])
        return G
    
    def _check_path_length(self, graph: nx.DiGraph, node: str, 
                          target_nodes: Set[str], max_length: int) -> bool:
        """æ£€æŸ¥èŠ‚ç‚¹åˆ°ç›®æ ‡èŠ‚ç‚¹çš„æœ€çŸ­è·¯å¾„"""
        if node in target_nodes:
            return True
        
        for target in target_nodes:
            if target in graph:
                try:
                    path_length = nx.shortest_path_length(
                        graph.to_undirected(), node, target
                    )
                    if path_length <= max_length:
                        return True
                except nx.NetworkXNoPath:
                    continue
        
        return False
    
    def build_dag(self, triples: List[Dict]) -> nx.DiGraph:
        """æ­¥éª¤6ï¼šæ„å»ºDAGå¹¶å¤„ç†ç¯"""
        G = nx.DiGraph()
        
        # æŒ‰ç±»åˆ«å’Œç½®ä¿¡åº¦æ’åº
        class_priority = {'A': 3, 'B': 2, 'C': 1}
        sorted_triples = sorted(
            triples, 
            key=lambda x: (class_priority[x['class']], x.get('confidence', 0.5)),
            reverse=True
        )
        
        for triple in sorted_triples:
            G.add_edge(
                triple['head'], 
                triple['tail'],
                relation=triple['relation'],
                evidence=triple['evidence'],
                class_type=triple['class'],
                confidence=triple.get('confidence', 0.5)
            )
            
            # æ£€æŸ¥æ˜¯å¦å½¢æˆç¯
            if not nx.is_directed_acyclic_graph(G):
                # æ‰¾åˆ°ç¯å¹¶åˆ é™¤æœ€ä½åˆ†çš„è¾¹
                cycles = list(nx.simple_cycles(G))
                if cycles:
                    cycle = cycles[0]
                    # åˆ é™¤ç¯ä¸­ç½®ä¿¡åº¦æœ€ä½çš„è¾¹
                    min_edge = None
                    min_conf = float('inf')
                    for i in range(len(cycle)):
                        u, v = cycle[i], cycle[(i+1) % len(cycle)]
                        if G.has_edge(u, v):
                            conf = G[u][v].get('confidence', 0.5)
                            if conf < min_conf:
                                min_conf = conf
                                min_edge = (u, v)
                    
                    if min_edge:
                        G.remove_edge(*min_edge)
        
        return G
    
    def visualize_graph(self, G: nx.DiGraph) -> str:
        """å¯è§†åŒ–å›¾ç»“æ„ï¼ˆæ–‡æœ¬å½¢å¼ï¼‰"""
        output = ["=== Causal Relationship Graph ===\n"]
        output.append(f"Nodes: {G.number_of_nodes()}")
        output.append(f"Edges: {G.number_of_edges()}\n")
        
        for u, v, data in G.edges(data=True):
            output.append(
                f"{u} --[{data.get('relation', 'relation')}]--> {v} "
                f"(Class: {data.get('class_type', 'N/A')}, "
                f"Confidence: {data.get('confidence', 0.5):.2f})"
            )
        
        return '\n'.join(output)
    
    def process_question(self, question: str, choices: List[str] = None, debug: bool = False) -> Dict:
        """å®Œæ•´å¤„ç†æµç¨‹"""
        print("Step 1: Extracting entities...")
        eq_entities = self.extract_entities(question)
        print(f"Found {len(eq_entities)} entities: {eq_entities}\n")
        
        print("Step 2: Extracting Class A triples...")
        a_triples = self.extract_class_a_triples(question, eq_entities)
        print(f"Found {len(a_triples)} Class A triples\n")
        
        print("Step 3: Expanding Class B triples...")
        b_triples = self.expand_class_b_triples(question, eq_entities, a_triples, k=2, debug=debug)
        
        # æ”¶é›†Bç±»æ–°å¢çš„å®ä½“ï¼ˆä¸åœ¨E_Qä¸­çš„å®ä½“ï¼‰
        eq_entities_lower = {e.lower() for e in eq_entities}
        b_entities = set()
        for t in b_triples:
            # æ£€æŸ¥headæ˜¯å¦æ˜¯æ–°å®ä½“
            if t['head'].lower() not in eq_entities_lower:
                b_entities.add(t['head'])
            # æ£€æŸ¥tailæ˜¯å¦æ˜¯æ–°å®ä½“
            if t['tail'].lower() not in eq_entities_lower:
                b_entities.add(t['tail'])
        
        print(f"Found {len(b_triples)} Class B triples, added {len(b_entities)} new entities")
        if b_entities:
            print(f"New entities: {b_entities}\n")
        else:
            print()
        
        print("Step 4: Expanding Class C triples...")
        c_triples = self.expand_class_c_triples(
            question, eq_entities, b_entities, a_triples + b_triples, max_path_length=2, debug=debug
        )
        print(f"Found {len(c_triples)} Class C triples\n")
        
        print("Step 5: Building DAG...")
        all_triples = a_triples + b_triples + c_triples
        graph = self.build_dag(all_triples)
        
        return {
            'entities': eq_entities,
            'b_entities': b_entities,  # æ·»åŠ Bç±»æ–°å®ä½“ä¿¡æ¯
            'triples': {
                'A': a_triples,
                'B': b_triples,
                'C': c_triples
            },
            'graph': graph,
            'visualization': self.visualize_graph(graph)
        }


# ===== ä½¿ç”¨ç¤ºä¾‹ =====
if __name__ == "__main__":
    # ç¤ºä¾‹é—®é¢˜ï¼ˆè‹±æ–‡ï¼‰
    question = """Climate change leads to increased extreme weather events. These extreme weather 
    events damage crop growth, thus affecting food production. Reduced food production leads to 
    price increases, ultimately impacting people's quality of life."""
    
    # åˆ›å»ºæ„å»ºå™¨
    builder = CausalGraphBuilder(model_name="gemma2:27b")
    
    # å¤„ç†é—®é¢˜
    result = builder.process_question(question)
    
    # è¾“å‡ºç»“æœ
    print("\n" + "="*60)
    print(result['visualization'])
    print("\n" + "="*60)
    print(f"\nTotal: {len(result['triples']['A'])} Class A, "
          f"{len(result['triples']['B'])} Class B, "
          f"{len(result['triples']['C'])} Class C triples")