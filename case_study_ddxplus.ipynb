{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Case Study: CoT vs DDXPlusCausalBuilder\n",
        "\n",
        "使用数据集 `DDXPlus_CausalQA_multistep_meta.jsonl`，对比两种方法在同一批样本上的表现：\n",
        "\n",
        "- **CoT baseline**：单次调用 LLM，输出 A/B/C。\n",
        "- **DDXPlusCausalBuilder**：多步构建因果图（BFS + bridge/seed）→ 抽取路径 → 让 LLM 根据图和路径做最终判断。\n",
        "\n",
        "说明：本 notebook 默认只跑少量样本做 case study（避免耗时太长）。你可以在配置区修改 `CASE_INDICES` 或 `NUM_CASES`。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import contextlib\n",
        "import io\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List, Optional\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from DDXPlusCausalBuilder import DDXPlusCausalBuilder\n",
        "\n",
        "DATA_PATH = Path(\"DDXPlus_CausalQA_multistep_meta.jsonl\")\n",
        "MODEL_NAME = os.environ.get(\"WIQA_MODEL_NAME\", os.environ.get(\"OLLAMA_MODEL\", \"llama3.1:8b\"))\n",
        "\n",
        "# 这些参数会显著影响 DDXPlusCausalBuilder 的速度/效果；case study 建议先用偏小配置。\n",
        "BUILDER_PARAMS = {\n",
        "    \"bfs_max_depth\": 4,\n",
        "    \"bfs_max_relations_per_node\": 5,\n",
        "    \"bfs_max_nodes\": 50,\n",
        "    \"bfs_beam_width\": 8,\n",
        "    \"bridge_max_bridge_nodes\": 3,\n",
        "    \"seed_max_parents\": 6,\n",
        "    \"chain_max_path_length\": 5,\n",
        "}\n",
        "\n",
        "# case 选择：如果 CASE_INDICES 为空，则按规则自动挑 NUM_CASES 个样本。\n",
        "NUM_CASES = 5\n",
        "CASE_INDICES: List[int] = []  # e.g. [0, 1, 2, 10, 42]\n",
        "\n",
        "VERBOSE_BUILDER = False  # True 会把 Builder 的 debug print 直接输出到 notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_jsonl(path: Path) -> List[Dict[str, Any]]:\n",
        "    rows: List[Dict[str, Any]] = []\n",
        "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            rows.append(json.loads(line))\n",
        "    return rows\n",
        "\n",
        "\n",
        "if not DATA_PATH.exists():\n",
        "    raise FileNotFoundError(f\"Dataset not found: {DATA_PATH.resolve()}\")\n",
        "\n",
        "rows = load_jsonl(DATA_PATH)\n",
        "print(\"Loaded rows:\", len(rows))\n",
        "rows[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ollama 预检查（可选）\n",
        "try:\n",
        "    import ollama\n",
        "\n",
        "    info = ollama.list()\n",
        "    print(\"Ollama OK\")\n",
        "    # 不同版本的 ollama-python 返回结构可能略有差异，这里直接打印一小段。\n",
        "    print(str(info)[:500])\n",
        "except Exception as e:\n",
        "    print(\"Ollama not reachable (skip if you only want to read the notebook):\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ollama\n",
        "\n",
        "ANSWER_LABEL_TO_CHOICE = {\"more\": \"A\", \"less\": \"B\", \"no_effect\": \"C\", \"no effect\": \"C\", \"no_change\": \"C\"}\n",
        "CHOICE_TO_ANSWER_LABEL = {\"A\": \"more\", \"B\": \"less\", \"C\": \"no_effect\"}\n",
        "\n",
        "\n",
        "def normalize_label(label: str) -> str:\n",
        "    return (label or \"\").strip().lower().replace(\" \", \"_\")\n",
        "\n",
        "\n",
        "def extract_choice_from_text(text: str) -> Optional[str]:\n",
        "    if not text:\n",
        "        return None\n",
        "\n",
        "    m = re.search(r\"(?:final answer|answer)\\s*[:\\-]?\\s*([ABC])\\b\", text, flags=re.IGNORECASE)\n",
        "    if m:\n",
        "        return m.group(1).upper()\n",
        "\n",
        "    last_line = text.strip().splitlines()[-1].strip()\n",
        "    if re.fullmatch(r\"[ABC]\", last_line, flags=re.IGNORECASE):\n",
        "        return last_line.upper()\n",
        "\n",
        "    m2 = re.search(\n",
        "        r\"(?:final answer|answer)\\s*[:\\-]?\\s*(more|less|no[_ ]effect|no[_ ]change|no effect)\\b\",\n",
        "        text,\n",
        "        flags=re.IGNORECASE,\n",
        "    )\n",
        "    if m2:\n",
        "        return ANSWER_LABEL_TO_CHOICE.get(normalize_label(m2.group(1)))\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def build_ddxplus_prompt(question_stem: str) -> str:\n",
        "    return (\n",
        "        f\"Question: {question_stem}\\n\"\n",
        "        \"Choice A: more\\n\"\n",
        "        \"Choice B: less\\n\"\n",
        "        \"Choice C: no effect\\n\"\n",
        "    )\n",
        "\n",
        "\n",
        "def _ollama_chat(model: str, prompt: str, *, temperature: float, num_predict: int, seed: int) -> str:\n",
        "    resp = ollama.chat(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        options={\"temperature\": float(temperature), \"num_predict\": int(num_predict), \"seed\": int(seed)},\n",
        "    )\n",
        "    return str((resp.get(\"message\") or {}).get(\"content\", \"\"))\n",
        "\n",
        "\n",
        "def _force_extract_choice(model: str, question_prompt: str, reasoning_text: str, *, seed: int) -> str:\n",
        "    extractor_prompt = (\n",
        "        \"You are an answer extractor.\\n\"\n",
        "        \"Given the question and a model's reasoning, output ONLY one letter: A, B, or C.\\n\\n\"\n",
        "        f\"{question_prompt}\\n\"\n",
        "        \"Reasoning:\\n\"\n",
        "        f\"{reasoning_text}\\n\\n\"\n",
        "        \"Output:\"\n",
        "    )\n",
        "    out = _ollama_chat(model, extractor_prompt, temperature=0.0, num_predict=8, seed=seed)\n",
        "    return extract_choice_from_text(out) or \"\"\n",
        "\n",
        "\n",
        "def run_cot_case(datapoint: Dict[str, Any], *, model_name: str, seed: int) -> Dict[str, Any]:\n",
        "    question_prompt = build_ddxplus_prompt(str(datapoint.get(\"question_stem\", \"\")))\n",
        "    prompt = (\n",
        "        \"[CoT]\\n\"\n",
        "        \"Guidance: Use chain-of-thought with a minimal causal graph.\\n\"\n",
        "        \"1) Construct a minimal causal graph.\\n\"\n",
        "        \"2) Reason briefly how changing the cause affects the outcome.\\n\"\n",
        "        \"3) Choose the best option.\\n\\n\"\n",
        "        f\"{question_prompt}\\n\\n\"\n",
        "        \"Output format:\\n\"\n",
        "        \"Causal graph: <comma-separated edges>\\n\"\n",
        "        \"Reasoning: <1-4 sentences>\\n\"\n",
        "        \"Final answer: <A|B|C>\\n\"\n",
        "    )\n",
        "    out = _ollama_chat(model_name, prompt, temperature=0.0, num_predict=512, seed=seed)\n",
        "    choice = extract_choice_from_text(out)\n",
        "    if choice is None:\n",
        "        choice = _force_extract_choice(model_name, question_prompt, out, seed=seed + 10_000)\n",
        "    pred_label = CHOICE_TO_ANSWER_LABEL.get(choice or \"\", \"\")\n",
        "    gold_label = normalize_label(str(datapoint.get(\"answer_label\", \"\")))\n",
        "    pred_norm = normalize_label(pred_label)\n",
        "    is_correct = bool(pred_norm) and pred_norm == gold_label\n",
        "    return {\n",
        "        \"method\": \"CoT\",\n",
        "        \"choice\": choice or \"\",\n",
        "        \"pred_label\": pred_label,\n",
        "        \"is_correct\": bool(is_correct),\n",
        "        \"raw_output\": out,\n",
        "    }\n",
        "\n",
        "\n",
        "def run_builder_case(datapoint: Dict[str, Any], *, model_name: str, params: Dict[str, Any], verbose: bool) -> Dict[str, Any]:\n",
        "    builder = DDXPlusCausalBuilder(datapoint, model_name=model_name)\n",
        "\n",
        "    buf = io.StringIO()\n",
        "    ctx = contextlib.nullcontext() if verbose else contextlib.redirect_stdout(buf)\n",
        "    try:\n",
        "        with ctx:\n",
        "            info = builder.extract_start_entity()\n",
        "            start = str(info.get(\"cause_event\") or datapoint.get(\"cause_event\") or \"\").strip()\n",
        "            target = str(info.get(\"outcome_base\") or datapoint.get(\"outcome_base\") or \"\").strip()\n",
        "\n",
        "            bfs = builder.expand_toward_target(\n",
        "                start_X=start,\n",
        "                target_Y=target,\n",
        "                max_depth=int(params.get(\"bfs_max_depth\", 4)),\n",
        "                max_relations_per_node=int(params.get(\"bfs_max_relations_per_node\", 5)),\n",
        "                max_nodes=int(params.get(\"bfs_max_nodes\", 50)),\n",
        "                beam_width=int(params.get(\"bfs_beam_width\", 8)),\n",
        "            )\n",
        "            try:\n",
        "                builder.last_node_rel_to_target = bfs.get(\"node_rel_to_target\", {}) if isinstance(bfs, dict) else {}\n",
        "            except Exception:\n",
        "                builder.last_node_rel_to_target = {}\n",
        "\n",
        "            triples = list((bfs or {}).get(\"triples\", []) or [])\n",
        "            close_hits = list((bfs or {}).get(\"close_hits\", []) or [])\n",
        "\n",
        "            # Step 3: bridge close hits (optional)\n",
        "            max_bridge = int(params.get(\"bridge_max_bridge_nodes\", 0) or 0)\n",
        "            if close_hits and max_bridge > 0:\n",
        "                triples = builder.bridge_close_hits(triples=triples, close_hits=close_hits, Y=target, max_bridge_nodes=max_bridge)\n",
        "\n",
        "            # Step 3: seed target parents (optional)\n",
        "            max_parents = int(params.get(\"seed_max_parents\", 0) or 0)\n",
        "            if max_parents > 0:\n",
        "                seed_edges = builder.find_target_parents(target, max_parents=max_parents)\n",
        "                existing = set()\n",
        "                for e in triples:\n",
        "                    if isinstance(e, dict):\n",
        "                        existing.add((e.get(\"head\", \"\"), e.get(\"relation\", \"\"), e.get(\"tail\", \"\")))\n",
        "                    elif isinstance(e, (list, tuple)) and len(e) >= 3:\n",
        "                        existing.add((e[0], e[1], e[2]))\n",
        "                for e in seed_edges or []:\n",
        "                    key = (e.get(\"head\", \"\"), e.get(\"relation\", \"\"), e.get(\"tail\", \"\"))\n",
        "                    if key in existing:\n",
        "                        continue\n",
        "                    triples.append(e)\n",
        "                    existing.add(key)\n",
        "\n",
        "            # Step 3: extract causal chain\n",
        "            chain_result = builder.get_causal_chain(\n",
        "                triples,\n",
        "                start_X=start,\n",
        "                target_Y=target,\n",
        "                max_path_length=int(params.get(\"chain_max_path_length\", 5)),\n",
        "            )\n",
        "\n",
        "            # Fallback: if no path, try using exact_target close-hit node as alternative target (same as pipeline).\n",
        "            if (chain_result.get(\"num_paths\", 0) or 0) == 0 and close_hits:\n",
        "                best_alt = None\n",
        "                for hit in close_hits:\n",
        "                    bfs_eq = str(hit.get(\"bfs_equivalence\") or \"\").strip().lower()\n",
        "                    if bfs_eq != \"exact_target\":\n",
        "                        continue\n",
        "                    alt_target = str(hit.get(\"node\") or \"\").strip()\n",
        "                    if not alt_target:\n",
        "                        continue\n",
        "                    alt_chain = builder.get_causal_chain(\n",
        "                        triples,\n",
        "                        start_X=start,\n",
        "                        target_Y=alt_target,\n",
        "                        max_path_length=int(params.get(\"chain_max_path_length\", 5)),\n",
        "                    )\n",
        "                    if (alt_chain.get(\"num_paths\", 0) or 0) <= 0:\n",
        "                        continue\n",
        "                    alt_chain[\"mapped_target\"] = alt_target\n",
        "                    alt_chain[\"original_target\"] = target\n",
        "                    if best_alt is None:\n",
        "                        best_alt = alt_chain\n",
        "                        continue\n",
        "                    cur_len = best_alt.get(\"shortest_path_length\")\n",
        "                    new_len = alt_chain.get(\"shortest_path_length\")\n",
        "                    if cur_len is None or (new_len is not None and new_len < cur_len):\n",
        "                        best_alt = alt_chain\n",
        "                if best_alt is not None:\n",
        "                    chain_result = best_alt\n",
        "\n",
        "            description = builder.causal_chain_to_text(chain_result, bfs)\n",
        "            reasoning = builder.reason_with_description(description, chain_result=chain_result)\n",
        "\n",
        "        pred_label = str(reasoning.get(\"predicted_answer\", \"\") or \"\")\n",
        "        pred_choice = str(reasoning.get(\"predicted_choice\", \"\") or \"\")\n",
        "        gold_label = normalize_label(str(datapoint.get(\"answer_label\", \"\")))\n",
        "        pred_norm = normalize_label(pred_label)\n",
        "        is_correct = bool(pred_norm) and pred_norm == gold_label\n",
        "\n",
        "        return {\n",
        "            \"method\": \"DDXPlusCausalBuilder\",\n",
        "            \"choice\": pred_choice,\n",
        "            \"pred_label\": pred_label,\n",
        "            \"is_correct\": bool(is_correct),\n",
        "            \"description\": description,\n",
        "            \"reasoning\": str(reasoning.get(\"reasoning\", \"\") or \"\"),\n",
        "            \"num_triples\": int(len((bfs or {}).get(\"triples\", []) or [])),\n",
        "            \"num_visited\": int(len((bfs or {}).get(\"visited\", []) or [])),\n",
        "            \"num_paths\": int(chain_result.get(\"num_paths\", 0) or 0),\n",
        "            \"debug_log\": buf.getvalue(),\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"method\": \"DDXPlusCausalBuilder\",\n",
        "            \"choice\": \"\",\n",
        "            \"pred_label\": \"\",\n",
        "            \"is_correct\": False,\n",
        "            \"description\": \"\",\n",
        "            \"reasoning\": \"\",\n",
        "            \"num_triples\": 0,\n",
        "            \"num_visited\": 0,\n",
        "            \"num_paths\": 0,\n",
        "            \"debug_log\": buf.getvalue() + f\"\\nERROR: {e}\",\n",
        "            \"error\": str(e),\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def auto_pick_cases(rows: List[Dict[str, Any]], k: int) -> List[int]:\n",
        "    # 优先挑一些更“有难度/有反直觉”的 case：包含 not / less probability 等关键词。\n",
        "    idxs: List[int] = []\n",
        "    for i, r in enumerate(rows):\n",
        "        q = str(r.get(\"question_stem\", \"\")).lower()\n",
        "        if \" not \" in q or \"less probability\" in q:\n",
        "            idxs.append(i)\n",
        "    if len(idxs) < k:\n",
        "        idxs = list(range(min(k, len(rows))))\n",
        "    return idxs[:k]\n",
        "\n",
        "\n",
        "case_indices = CASE_INDICES or auto_pick_cases(rows, NUM_CASES)\n",
        "case_indices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "runs: List[Dict[str, Any]] = []\n",
        "\n",
        "for idx in case_indices:\n",
        "    dp = rows[idx]\n",
        "    gold_label = normalize_label(str(dp.get(\"answer_label\", \"\")))\n",
        "    gold_choice = str(dp.get(\"answer_label_as_choice\", \"\"))\n",
        "\n",
        "    cot = run_cot_case(dp, model_name=MODEL_NAME, seed=42 + idx)\n",
        "    builder = run_builder_case(dp, model_name=MODEL_NAME, params=BUILDER_PARAMS, verbose=VERBOSE_BUILDER)\n",
        "\n",
        "    runs.append(\n",
        "        {\n",
        "            \"idx\": idx,\n",
        "            \"question\": dp.get(\"question_stem\", \"\"),\n",
        "            \"gold_label\": gold_label,\n",
        "            \"gold_choice\": gold_choice,\n",
        "            \"cot_choice\": cot.get(\"choice\", \"\"),\n",
        "            \"cot_pred\": normalize_label(str(cot.get(\"pred_label\", \"\"))),\n",
        "            \"cot_correct\": bool(cot.get(\"is_correct\", False)),\n",
        "            \"cot_raw_output\": cot.get(\"raw_output\", \"\"),\n",
        "            \"builder_choice\": builder.get(\"choice\", \"\"),\n",
        "            \"builder_pred\": normalize_label(str(builder.get(\"pred_label\", \"\"))),\n",
        "            \"builder_correct\": bool(builder.get(\"is_correct\", False)),\n",
        "            \"builder_num_triples\": int(builder.get(\"num_triples\", 0)),\n",
        "            \"builder_num_paths\": int(builder.get(\"num_paths\", 0)),\n",
        "            \"builder_description\": builder.get(\"description\", \"\"),\n",
        "            \"builder_reasoning\": builder.get(\"reasoning\", \"\"),\n",
        "            \"builder_debug_log\": builder.get(\"debug_log\", \"\"),\n",
        "            \"builder_error\": builder.get(\"error\", \"\"),\n",
        "        }\n",
        "    )\n",
        "\n",
        "df = pd.DataFrame(runs)\n",
        "summary_cols = [\n",
        "    \"idx\",\n",
        "    \"gold_label\",\n",
        "    \"gold_choice\",\n",
        "    \"cot_choice\",\n",
        "    \"cot_pred\",\n",
        "    \"cot_correct\",\n",
        "    \"builder_choice\",\n",
        "    \"builder_pred\",\n",
        "    \"builder_correct\",\n",
        "    \"builder_num_triples\",\n",
        "    \"builder_num_paths\",\n",
        "]\n",
        "df[summary_cols]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _acc(flag_series: pd.Series) -> float:\n",
        "    if flag_series.empty:\n",
        "        return 0.0\n",
        "    return float(flag_series.mean())\n",
        "\n",
        "\n",
        "print(\"CoT accuracy (case subset):\", _acc(df[\"cot_correct\"]))\n",
        "print(\"DDXPlusCausalBuilder accuracy (case subset):\", _acc(df[\"builder_correct\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 逐条对比（详细输出）\n",
        "\n",
        "下面会把每条样本的：题目、gold、CoT 原始输出、Builder 的 description + reasoning 都打印出来，方便做定性分析。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for r in runs:\n",
        "    idx = int(r.get(\"idx\", -1))\n",
        "    print(\"=\" * 100)\n",
        "    print(f\"IDX={idx} | gold={r.get('gold_label', '')} ({r.get('gold_choice', '')})\")\n",
        "    print(\"Question:\")\n",
        "    print(r.get(\"question\", \"\"))\n",
        "\n",
        "    print(\"\\n[CoT] pred=\", r.get(\"cot_pred\", \"\"), \"choice=\", r.get(\"cot_choice\", \"\"), \"correct=\", r.get(\"cot_correct\", False))\n",
        "    print(\"-\" * 100)\n",
        "    print(r.get(\"cot_raw_output\", \"\"))\n",
        "\n",
        "    print(\"\\n[DDXPlusCausalBuilder] pred=\", r.get(\"builder_pred\", \"\"), \"choice=\", r.get(\"builder_choice\", \"\"), \"correct=\", r.get(\"builder_correct\", False))\n",
        "    print(f\"triples={r.get('builder_num_triples', 0)} paths={r.get('builder_num_paths', 0)}\")\n",
        "    print(\"-\" * 100)\n",
        "    print(\"[Description]\")\n",
        "    print(r.get(\"builder_description\", \"\"))\n",
        "    print(\"\\n[Reasoning]\")\n",
        "    print(r.get(\"builder_reasoning\", \"\"))\n",
        "\n",
        "    if (not VERBOSE_BUILDER) and r.get(\"builder_debug_log\"):\n",
        "        print(\"\\n[Builder debug log] (captured)\")\n",
        "        print(str(r.get(\"builder_debug_log\"))[:2000])\n",
        "\n",
        "    if r.get(\"builder_error\"):\n",
        "        print(\"\\n[Builder error]\")\n",
        "        print(r.get(\"builder_error\"))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
