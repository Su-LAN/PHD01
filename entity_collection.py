"""
ç®€åŒ–ç‰ˆå› æœå›¾æ„å»ºå™¨ - å»æ‰ç½®ä¿¡åº¦éªŒè¯ï¼Œåªä¿ç•™å®ä½“æœé›†
åŒ…å«å®Œæ•´çš„LLMè¾“å…¥è¾“å‡ºæ—¥å¿—
"""

import ollama
import re
import json
from typing import List, Dict, Set
from datetime import datetime
import networkx as nx

class SimplifiedCausalGraphBuilder:
    """ç®€åŒ–ç‰ˆå› æœå›¾æ„å»ºå™¨ - ä¸“æ³¨äºå®ä½“æœé›†"""
    
    def __init__(self, model_name="gemma2:27b", log_file="causal_build_log.txt"):
        self.model_name = model_name
        self.log_file = log_file
        self.log_entries = []
        
        # åˆå§‹åŒ–æ—¥å¿—
        self._log_header()
    
    def _log_header(self):
        """å†™å…¥æ—¥å¿—å¤´"""
        header = f"""
{'='*80}
å› æœå›¾æ„å»ºæ—¥å¿—
æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
æ¨¡å‹: {self.model_name}
{'='*80}
"""
        self.log_entries.append(header)
        print(header)
    
    def _log_llm_call(self, step: str, prompt: str, response: str):
        """è®°å½•LLMè°ƒç”¨"""
        log = f"""
{'â”€'*80}
æ­¥éª¤: {step}
{'â”€'*80}

ã€LLMè¾“å…¥ Promptã€‘
{prompt}

ã€LLMè¾“å‡º Responseã€‘
{response}

{'â”€'*80}
"""
        self.log_entries.append(log)
        print(log)
    
    def save_log(self):
        """ä¿å­˜æ—¥å¿—åˆ°æ–‡ä»¶"""
        with open(self.log_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(self.log_entries))
        print(f"\nâœ… æ—¥å¿—å·²ä¿å­˜åˆ°: {self.log_file}")
    
    def extract_entities(self, question: str) -> Set[str]:
        """æ­¥éª¤1ï¼šæŠ½å–å®ä½“"""
        prompt = f"""Extract all important entities (nouns, noun phrases, concepts) from the following question.

Question: {question}

Return ONLY entity names, one per line, no numbers or bullets.

Entities:"""
        
        response = ollama.generate(model=self.model_name, prompt=prompt)
        response_text = response['response'].strip()
        
        self._log_llm_call("Step 1: Extract Entities (E_Q)", prompt, response_text)
        
        # è§£æå®ä½“
        entities = set()
        for line in response_text.split('\n'):
            entity = line.strip()
            
            # æ¸…ç†
            if not entity or len(entity) < 2:
                continue
            if entity.lower().startswith(('here', 'entity', 'entities')):
                continue
            
            # ç§»é™¤ç¼–å·ã€ç¬¦å·
            entity = re.sub(r'^\d+[\.)]\s*', '', entity)
            entity = entity.lstrip('-â€¢*>').strip().strip('"\'*').strip()
            
            if entity and len(entity) > 1:
                entities.add(entity)
        
        print(f"\nâœ… æŠ½å–åˆ° {len(entities)} ä¸ªå®ä½“: {entities}\n")
        return entities
    
    def extract_class_a_triples(self, question: str, entities: Set[str]) -> List[Dict]:
        """æ­¥éª¤2ï¼šAç±»ä¸‰å…ƒç»„ï¼ˆå®Œå…¨æ¥è‡ªé—®é¢˜ï¼‰"""
        prompt = f"""Analyze causal relationships in the question. Only use these entities.

Question: {question}

Entities: {', '.join(entities)}

Format: head -> relation -> tail | evidence

Return triples only:"""
        
        response = ollama.generate(model=self.model_name, prompt=prompt)
        response_text = response['response'].strip()
        
        self._log_llm_call("Step 2: Extract Class A Triples", prompt, response_text)
        
        # è§£æAç±»ä¸‰å…ƒç»„
        a_triples = []
        entity_lower_map = {e.lower(): e for e in entities}
        
        for line in response_text.split('\n'):
            line = line.strip()
            if '->' not in line:
                continue
            
            if '|' in line:
                triple_part, evidence = line.split('|', 1)
            else:
                triple_part = line
                evidence = "From question text"
            
            parts = [p.strip() for p in triple_part.split('->')]
            if len(parts) >= 3:
                head = parts[0].strip('"\'*').strip()
                relation = parts[1].strip('"\'*').strip()
                tail = parts[2].strip('"\'*').strip()
                
                # ç®€å•åŒ¹é…
                head_match = self._find_entity(head, entities, entity_lower_map)
                tail_match = self._find_entity(tail, entities, entity_lower_map)
                
                if head_match and tail_match:
                    a_triples.append({
                        'head': head_match,
                        'relation': relation,
                        'tail': tail_match,
                        'evidence': evidence.strip(),
                        'class': 'A'
                    })
        
        print(f"âœ… æ‰¾åˆ° {len(a_triples)} ä¸ªAç±»ä¸‰å…ƒç»„")
        for t in a_triples:
            print(f"   {t['head']} --[{t['relation']}]--> {t['tail']}")
        print()
        
        return a_triples
    
    def _find_entity(self, text: str, entities: Set[str], entity_lower_map: Dict[str, str]) -> str:
        """æŸ¥æ‰¾åŒ¹é…çš„å®ä½“"""
        text = text.strip('"\'*').strip()
        
        # ç²¾ç¡®åŒ¹é…
        if text in entities:
            return text
        
        # å°å†™åŒ¹é…
        if text.lower() in entity_lower_map:
            return entity_lower_map[text.lower()]
        
        # éƒ¨åˆ†åŒ¹é…
        for entity in entities:
            if text.lower() in entity.lower() or entity.lower() in text.lower():
                return entity
        
        return None
    
    def expand_class_b_triples(self, question: str, eq_entities: Set[str], k: int = 5) -> List[Dict]:
        """æ­¥éª¤3ï¼šBç±»ä¸‰å…ƒç»„ï¼ˆé—®é¢˜å®ä½“ + å¤–éƒ¨å®ä½“ï¼‰"""
        b_triples = []
        eq_entities_lower = {e.lower() for e in eq_entities}
        
        # å¯¹æ¯ä¸ªE_Qå®ä½“æ‰©å±•
        for entity in list(eq_entities)[:3]:
            prompt = f"""Propose {k} NEW external entities related to "{entity}" (NOT in this list: {', '.join(eq_entities)}).

Question: {question}

Format: new_entity -> direction(cause/effect) -> {entity}

Return {k} triples:"""
            
            response = ollama.generate(model=self.model_name, prompt=prompt)
            response_text = response['response'].strip()
            
            self._log_llm_call(f"Step 3: Expand B-class for '{entity}'", prompt, response_text)
            
            # è§£æ
            for line in response_text.split('\n')[:k]:
                line = line.strip()
                if '->' not in line:
                    continue
                
                parts = [p.strip() for p in line.split('->')]
                if len(parts) >= 3:
                    entity1 = parts[0].strip('"\'*').strip()
                    direction = parts[1].lower()
                    entity2 = parts[2].strip('"\'*').strip()
                    
                    # åˆ¤æ–­å“ªä¸ªæ˜¯æ–°å®ä½“
                    entity1_in_eq = entity1.lower() in eq_entities_lower
                    entity2_in_eq = entity2.lower() in eq_entities_lower
                    
                    # ç¡®å®šheadå’Œtail
                    if entity1_in_eq and not entity2_in_eq:
                        # entity1åœ¨E_Qï¼Œentity2æ˜¯æ–°çš„ (EFFECT)
                        head, tail = entity1, entity2
                        external = entity2
                    elif not entity1_in_eq and entity2_in_eq:
                        # entity1æ˜¯æ–°çš„ï¼Œentity2åœ¨E_Q (CAUSE)
                        head, tail = entity1, entity2
                        external = entity1
                    elif not entity1_in_eq and not entity2_in_eq:
                        # å°è¯•åŒ¹é…å½“å‰entity
                        if entity.lower() in entity2.lower():
                            head, tail = entity1, entity
                            external = entity1
                        elif entity.lower() in entity1.lower():
                            head, tail = entity, entity2
                            external = entity2
                        else:
                            continue
                    else:
                        # ä¸¤ä¸ªéƒ½åœ¨E_Qä¸­
                        continue
                    
                    # éªŒè¯Bç±»çº¦æŸ
                    head_in_eq = head.lower() in eq_entities_lower
                    tail_in_eq = tail.lower() in eq_entities_lower
                    
                    if (head_in_eq and not tail_in_eq) or (not head_in_eq and tail_in_eq):
                        b_triples.append({
                            'head': head,
                            'relation': 'causes',
                            'tail': tail,
                            'external_entity': external,
                            'class': 'B'
                        })
        
        print(f"âœ… æ‰¾åˆ° {len(b_triples)} ä¸ªBç±»ä¸‰å…ƒç»„")
        for t in b_triples:
            print(f"   {t['head']} --> {t['tail']} (æ–°å®ä½“: {t['external_entity']})")
        print()
        
        return b_triples
    
    def expand_class_c_triples(self, question: str, eq_entities: Set[str], 
                               b_entities: Set[str], k: int = 3) -> List[Dict]:
        """æ­¥éª¤4ï¼šCç±»ä¸‰å…ƒç»„ï¼ˆæ¡¥æ¥å®ä½“ï¼‰"""
        c_triples = []
        
        if not b_entities:
            print("âš ï¸ æ²¡æœ‰Bç±»å®ä½“ï¼Œè·³è¿‡Cç±»æ‰©å±•\n")
            return c_triples
        
        # æ¸…ç†Bç±»å®ä½“
        b_entities_clean = {e.strip('*').strip() for e in b_entities}
        eq_entities_lower = {e.lower() for e in eq_entities}
        all_known = eq_entities.union(b_entities_clean)
        all_known_lower = {e.lower() for e in all_known}
        
        # å¯¹æ¯ä¸ªBç±»å®ä½“æ‰©å±•
        for b_entity in list(b_entities_clean)[:4]:
            # ç¡®ä¿æ˜¯çœŸæ­£çš„Bç±»å®ä½“
            if b_entity.lower() in eq_entities_lower:
                continue
            
            prompt = f"""Propose {k} NEW bridging concepts for "{b_entity}" (NOT in: {', '.join(all_known)}).

Question: {question}

Format: new_bridge -> relation -> {b_entity}

Return {k} triples:"""
            
            response = ollama.generate(model=self.model_name, prompt=prompt)
            response_text = response['response'].strip()
            
            self._log_llm_call(f"Step 4: Expand C-class for '{b_entity}'", prompt, response_text)
            
            # è§£æ
            for line in response_text.split('\n')[:k]:
                line = line.strip()
                if '->' not in line:
                    continue
                
                parts = [p.strip() for p in line.split('->')]
                if len(parts) >= 3:
                    bridge = parts[0].strip('"\'*').strip()
                    relation = parts[1].strip('"\'*').strip()
                    target = parts[2].strip('"\'*').strip()
                    
                    # æ£€æŸ¥bridgeæ˜¯å¦æ˜¯æ–°å®ä½“
                    if bridge.lower() in all_known_lower:
                        continue
                    
                    # æ£€æŸ¥targetæ˜¯å¦æ˜¯Bç±»å®ä½“
                    target_in_b = target.lower() in {e.lower() for e in b_entities_clean}
                    target_in_eq = target.lower() in eq_entities_lower
                    
                    if not target_in_b or target_in_eq:
                        target = b_entity
                    
                    # éªŒè¯Cç±»çº¦æŸ
                    head_is_new = bridge.lower() not in all_known_lower
                    tail_is_b = (target.lower() in {e.lower() for e in b_entities_clean} and
                                target.lower() not in eq_entities_lower)
                    
                    if head_is_new and tail_is_b:
                        c_triples.append({
                            'head': bridge,
                            'relation': relation,
                            'tail': target,
                            'class': 'C'
                        })
                        
                        # æ›´æ–°å·²çŸ¥å®ä½“
                        all_known.add(bridge)
                        all_known_lower.add(bridge.lower())
        
        print(f"âœ… æ‰¾åˆ° {len(c_triples)} ä¸ªCç±»ä¸‰å…ƒç»„")
        for t in c_triples:
            print(f"   {t['head']} --[{t['relation']}]--> {t['tail']}")
        print()
        
        return c_triples
    
    def build_graph(self, triples: List[Dict]) -> nx.DiGraph:
        """æ„å»ºå›¾"""
        G = nx.DiGraph()
        for triple in triples:
            G.add_edge(
                triple['head'],
                triple['tail'],
                relation=triple.get('relation', 'causes'),
                class_type=triple['class']
            )
        return G
    
    def visualize(self, G: nx.DiGraph) -> str:
        """å¯è§†åŒ–"""
        output = ["\n" + "="*60]
        output.append("å› æœå…³ç³»å›¾")
        output.append("="*60)
        output.append(f"èŠ‚ç‚¹: {G.number_of_nodes()}")
        output.append(f"è¾¹: {G.number_of_edges()}\n")
        
        for u, v, data in G.edges(data=True):
            output.append(
                f"{u} --[{data.get('relation', '?')}]--> {v} "
                f"(Class: {data.get('class_type', '?')})"
            )
        
        output.append("="*60)
        return '\n'.join(output)
    
    def process(self, question: str):
        """å®Œæ•´æµç¨‹"""
        print("\n" + "="*80)
        print("å¼€å§‹å¤„ç†...")
        print("="*80 + "\n")
        
        # Step 1: æŠ½å–å®ä½“
        print("â–¶ Step 1: æŠ½å–å®ä½“ (E_Q)")
        eq_entities = self.extract_entities(question)
        
        # Step 2: Aç±»ä¸‰å…ƒç»„
        print("â–¶ Step 2: Aç±»ä¸‰å…ƒç»„")
        a_triples = self.extract_class_a_triples(question, eq_entities)
        
        # Step 3: Bç±»ä¸‰å…ƒç»„
        print("â–¶ Step 3: Bç±»ä¸‰å…ƒç»„")
        b_triples = self.expand_class_b_triples(question, eq_entities, k=5)
        
        # æ”¶é›†Bç±»æ–°å®ä½“
        eq_entities_lower = {e.lower() for e in eq_entities}
        b_entities = set()
        for t in b_triples:
            if 'external_entity' in t:
                if t['external_entity'].lower() not in eq_entities_lower:
                    b_entities.add(t['external_entity'])
        
        print(f"ğŸ“Š Bç±»æ–°å¢å®ä½“: {b_entities}\n")
        
        # Step 4: Cç±»ä¸‰å…ƒç»„
        print("â–¶ Step 4: Cç±»ä¸‰å…ƒç»„")
        c_triples = self.expand_class_c_triples(question, eq_entities, b_entities, k=3)
        
        # æ„å»ºå›¾
        all_triples = a_triples + b_triples + c_triples
        graph = self.build_graph(all_triples)
        
        # å¯è§†åŒ–
        viz = self.visualize(graph)
        print(viz)
        
        # ç»Ÿè®¡
        print("\n" + "="*80)
        print("ç»Ÿè®¡ä¿¡æ¯")
        print("="*80)
        print(f"E_Qå®ä½“æ•°: {len(eq_entities)}")
        print(f"Aç±»ä¸‰å…ƒç»„: {len(a_triples)}")
        print(f"Bç±»ä¸‰å…ƒç»„: {len(b_triples)} (æ–°å¢ {len(b_entities)} ä¸ªå®ä½“)")
        print(f"Cç±»ä¸‰å…ƒç»„: {len(c_triples)}")
        print(f"æ€»èŠ‚ç‚¹æ•°: {graph.number_of_nodes()}")
        print(f"æ€»è¾¹æ•°: {graph.number_of_edges()}")
        print("="*80 + "\n")
        
        # ä¿å­˜æ—¥å¿—
        self.save_log()
        
        return {
            'entities': eq_entities,
            'b_entities': b_entities,
            'triples': {
                'A': a_triples,
                'B': b_triples,
                'C': c_triples
            },
            'graph': graph
        }


# ===== ä½¿ç”¨ç¤ºä¾‹ =====
if __name__ == "__main__":
    question = """Climate change leads to increased extreme weather events. These extreme weather 
    events damage crop growth, thus affecting food production. Reduced food production leads to 
    price increases, ultimately impacting people's quality of life."""
    
    # åˆ›å»ºæ„å»ºå™¨
    builder = SimplifiedCausalGraphBuilder(
        model_name="gemma2:27b",
        log_file="causal_build_log.txt"
    )
    
    # å¤„ç†
    result = builder.process(question)
    
    print("\nâœ… å®Œæˆï¼æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶: causal_build_log.txt")