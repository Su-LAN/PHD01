{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDXPlus Multistep QA — LLM Rewrite/Test (Ollama → OpenAI)\n",
    "\n",
    "This notebook rewrites `question_stem` into a consistent **\"Suppose X happens, how will it affect Y?\"** style.\n",
    "\n",
    "- First test uses **Ollama** via its OpenAI-compatible endpoint: `http://localhost:11434/v1`.\n",
    "- Later you can switch to **OpenAI** by changing `BASE_URL` to `https://api.openai.com/v1` and setting `OPENAI_API_KEY`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input/output\n",
    "INPUT_JSONL = 'DDXPlus_CausalQA_multistep.jsonl'\n",
    "OUTPUT_JSONL = 'DDXPlus_CausalQA_multistep_rewritten.jsonl'\n",
    "\n",
    "# OpenAI-compatible endpoint\n",
    "# - Ollama: http://localhost:11434/v1\n",
    "# - OpenAI: https://api.openai.com/v1\n",
    "BASE_URL = os.environ.get('OPENAI_BASE_URL', 'http://localhost:11434/v1')\n",
    "API_KEY = os.environ.get('OPENAI_API_KEY', 'ollama')\n",
    "\n",
    "# Model name\n",
    "# - Ollama example: llama3.1:8b\n",
    "# - OpenAI example: gpt-4o-mini\n",
    "MODEL = os.environ.get('OPENAI_MODEL', 'llama3.1:8b')\n",
    "\n",
    "# Rewrite settings\n",
    "TEMPERATURE = 0.7\n",
    "MAX_TOKENS = 120\n",
    "TIMEOUT_S = 60\n",
    "\n",
    "# For quick testing\n",
    "N_TEST = 5\n",
    "MAX_REWRITE = 0  # 0 = all rows\n",
    "\n",
    "print('BASE_URL:', BASE_URL)\n",
    "print('MODEL:', MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(path: str) -> List[Dict[str, Any]]:\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            rows.append(json.loads(line))\n",
    "    return rows\n",
    "\n",
    "\n",
    "rows = load_jsonl(INPUT_JSONL)\n",
    "print('rows:', len(rows))\n",
    "print('keys:', sorted(rows[0].keys()) if rows else [])\n",
    "print('sample question_stem:', rows[0].get('question_stem', '') if rows else '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. OpenAI-compatible `chat.completions` call\n",
    "\n",
    "This works for both Ollama and OpenAI by only changing `BASE_URL` + `API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_completions(\n",
    "    *,\n",
    "    base_url: str,\n",
    "    api_key: str,\n",
    "    model: str,\n",
    "    messages: List[Dict[str, str]],\n",
    "    temperature: float = 0.7,\n",
    "    max_tokens: int = 256,\n",
    "    timeout_s: int = 60,\n",
    ") -> str:\n",
    "    url = base_url.rstrip('/') + '/chat/completions'\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {api_key}',\n",
    "    }\n",
    "    payload = {\n",
    "        'model': model,\n",
    "        'messages': messages,\n",
    "        'temperature': float(temperature),\n",
    "        'max_tokens': int(max_tokens),\n",
    "    }\n",
    "    r = requests.post(url, headers=headers, json=payload, timeout=timeout_s)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    return data['choices'][0]['message']['content']\n",
    "\n",
    "\n",
    "# Quick connectivity test (should print model output)\n",
    "test_out = chat_completions(\n",
    "    base_url=BASE_URL,\n",
    "    api_key=API_KEY,\n",
    "    model=MODEL,\n",
    "    messages=[{'role': 'user', 'content': 'Reply with exactly: OK'}],\n",
    "    temperature=0.0,\n",
    "    max_tokens=8,\n",
    "    timeout_s=TIMEOUT_S,\n",
    ")\n",
    "print('connectivity:', test_out.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Rewrite `question_stem` (LLM)\n",
    "\n",
    "We use `cause_event` + `outcome_base` (+ optional `outcome_polarity`) as the *meaning anchor*.\n",
    "\n",
    "Important: the rewritten question must **NOT** state the answer direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outcome_base_to_phrase(outcome_base: str, outcome_polarity: Optional[str] = None) -> str:\n",
    "    ob = (outcome_base or '').strip()\n",
    "    if not ob:\n",
    "        return 'the outcome'\n",
    "    lower = ob.lower()\n",
    "    if lower.endswith(' probability'):\n",
    "        name = ob[: -len(' probability')].strip()\n",
    "        pol = (outcome_polarity or '').strip().lower()\n",
    "        if pol in ('more', 'less'):\n",
    "            return f'the {pol} probability of {name}'\n",
    "        return f'the probability of {name}'\n",
    "    if lower.endswith(' rate'):\n",
    "        name = ob[: -len(' rate')].strip()\n",
    "        return f'the rate of {name}'\n",
    "    return ob\n",
    "\n",
    "\n",
    "def build_base_question(cause_event: str, outcome_base: str, outcome_polarity: Optional[str] = None) -> str:\n",
    "    x = (cause_event or '').strip().rstrip('.')\n",
    "    y = outcome_base_to_phrase(outcome_base, outcome_polarity=outcome_polarity)\n",
    "    if not x:\n",
    "        x = 'the situation described above'\n",
    "    return f'Suppose {x} happens, how will this affect {y}?'\n",
    "\n",
    "\n",
    "def rewrite_question_stem(item: Dict[str, Any]) -> str:\n",
    "    base_q = build_base_question(\n",
    "        item.get('cause_event', ''),\n",
    "        item.get('outcome_base', ''),\n",
    "        outcome_polarity=item.get('outcome_polarity'),\n",
    "    )\n",
    "    system = 'You rewrite causal questions into fluent English without changing meaning.'\n",
    "    user = f\"\"\"Rewrite the following question into ONE grammatical English question.\n",
    "\n",
    "Rules:\n",
    "- Preserve meaning: same cause event X and same outcome target Y (including any MORE/LESS outcome meta).\n",
    "- DO NOT state the direction of effect for Y (do not say increase/decrease, more/less likely, etc.).\n",
    "- If Y contains the words 'more' or 'less', they must ONLY appear as part of the outcome target phrase.\n",
    "- Output ONLY the rewritten question sentence.\n",
    "- Must be ONE sentence and end with a '?'.\n",
    "- Must start with the word \"Suppose\".\n",
    "\n",
    "Question:\n",
    "{base_q}\n",
    "\"\"\"\n",
    "    out = chat_completions(\n",
    "        base_url=BASE_URL,\n",
    "        api_key=API_KEY,\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': system},\n",
    "            {'role': 'user', 'content': user},\n",
    "        ],\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        timeout_s=TIMEOUT_S,\n",
    "    )\n",
    "    q = out.strip().splitlines()[0].strip()\n",
    "    if not q.endswith('?'):\n",
    "        q = q.rstrip('.') + '?'\n",
    "    return q\n",
    "\n",
    "\n",
    "def rewrite_item(item: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    new_item = dict(item)\n",
    "    new_item['question_stem_original'] = item.get('question_stem', '')\n",
    "    new_item['question_stem'] = rewrite_question_stem(item)\n",
    "    return new_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Quick test (Ollama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, item in enumerate(rows[:N_TEST]):\n",
    "    rewritten = rewrite_item(item)\n",
    "    print(f'\\n--- sample {i} ---')\n",
    "    print('original:', rewritten['question_stem_original'])\n",
    "    print('rewritten:', rewritten['question_stem'])\n",
    "    time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Rewrite and save JSONL (optional)\n",
    "\n",
    "Set `MAX_REWRITE=0` to rewrite all rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_jsonl(items: List[Dict[str, Any]], path: str) -> None:\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        for obj in items:\n",
    "            f.write(json.dumps(obj, ensure_ascii=False) + '\\n')\n",
    "\n",
    "\n",
    "n = len(rows) if MAX_REWRITE == 0 else min(len(rows), MAX_REWRITE)\n",
    "out_rows: List[Dict[str, Any]] = []\n",
    "for i in range(n):\n",
    "    out_rows.append(rewrite_item(rows[i]))\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print('rewritten', i + 1, '/', n)\n",
    "    time.sleep(0.1)\n",
    "\n",
    "write_jsonl(out_rows, OUTPUT_JSONL)\n",
    "print('saved to:', OUTPUT_JSONL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
